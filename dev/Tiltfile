# Config
config_yaml=read_yaml('config.yaml')

# Vars
everest_namespace = 'everest-system'
everest_monitoring_namespace = 'everest-monitoring'
pxc_operator_version = os.getenv('PXC_OPERATOR_VERSION', '1.15.0')
print('Using PXC operator version: %s' % pxc_operator_version)
psmdb_operator_version = os.getenv('PSMDB_OPERATOR_VERSION', '1.18.0')
print('Using PSMDB operator version: %s' % psmdb_operator_version)
pg_operator_version = os.getenv('PG_OPERATOR_VERSION', '2.5.0')
print('Using PG operator version: %s' % pg_operator_version)

# External resources set up
# uncomment the settings below and insert your k8s context & registry names
# to get your current context name run `kubectl config view`
#allow_k8s_contexts("gke_percona-everest_europe-west1-c_everest-dev")
#default_registry("us-central1-docker.pkg.dev/percona-everest/quickstart-docker-repo")


# Check for required env vars
backend_dir = os.getenv('EVEREST_BACKEND_DIR')
if not backend_dir:
  backend_dir = '..'
backend_dir = os.path.abspath(backend_dir)
if not os.path.exists(backend_dir):
  fail('Backend dir does not exist: %s' % backend_dir)
print('Using backend dir: %s' % backend_dir)

frontend_dir = os.getenv('EVEREST_FRONTEND_DIR')
if not frontend_dir:
  frontend_dir = '../ui'
frontend_dir = os.path.abspath(frontend_dir)
if not os.path.exists(frontend_dir):
  fail('Frontend dir does not exist: %s' % frontend_dir)
print('Using frontend dir: %s' % frontend_dir)

cli_dir = os.getenv('EVEREST_CLI_DIR')
if not cli_dir:
  cli_dir = '..'
cli_dir = os.path.abspath(cli_dir)
if not os.path.exists(cli_dir):
  fail('cli dir does not exist: %s' % cli_dir)
print('Using cli dir: %s' % cli_dir)

operator_dir = os.getenv('EVEREST_OPERATOR_DIR')
if not operator_dir:
  fail('EVEREST_OPERATOR_DIR must be set')
operator_dir = os.path.abspath(operator_dir)
if not os.path.exists(operator_dir):
  fail('Operator dir does not exist: %s' % operator_dir)
print('Using operator dir: %s' % operator_dir)

everest_chart_dir = os.getenv('EVEREST_CHART_DIR')
if not everest_chart_dir:
  fail('EVEREST_CHART_DIR must be set')
everest_chart_dir = os.path.abspath(everest_chart_dir)
if not os.path.exists(everest_chart_dir):
  fail('Chart dir does not exist: %s' % everest_chart_dir)
print('Using chart dir: %s' % everest_chart_dir)

watch_settings(
    ignore=[
        '%s/**/*.tgz' % everest_chart_dir,
        '%s/**/*tmpcharts*' % everest_chart_dir,
    ]
)

# Ensure operator's kustomize is installed
local('[ -x %s/bin/kustomize ] || make -C %s kustomize' % (operator_dir, operator_dir), quiet=True)

# Ensure frontend repo is initialized
local('make -C %s init' % (frontend_dir), quiet=True)
# Ensure backend repo is initialized
local('make -C %s init' % (backend_dir), quiet=True)

# Build helm dependencies
local('HELM=%s/bin/helm make -C %s deps' % (backend_dir, everest_chart_dir), quiet=True)


# Create namespaces
load('ext://namespace', 'namespace_create', 'namespace_inject')
namespace_create(everest_namespace)
k8s_resource(
  objects=[
    '%s:namespace' % everest_namespace
  ],
  new_name='everest-namespace',
)
namespaces = sorted([namespace['name'] for namespace in config_yaml['namespaces']])
for namespace in namespaces:
  namespace_create(namespace)
k8s_resource(
  objects=[
    '%s:namespace' % namespace for namespace in namespaces
  ],
  new_name='namespaces',
)

for namespace in namespaces:
  local_resource('update-label-%s' % namespace, 
  cmd='kubectl label namespace %s --overwrite app.kubernetes.io/managed-by=everest' % namespace, 
  resource_deps = [
    'namespaces',
  ])

#################################
## Install DB engine operators ##
#################################

# PXC
pxc_operator_bundle_yaml = local(['curl', '-s', 'https://raw.githubusercontent.com/percona/percona-xtradb-cluster-operator/v%s/deploy/bundle.yaml' % pxc_operator_version], quiet=True)
pxc_namespaces = [namespace['name'] for namespace in config_yaml['namespaces'] if 'pxc' in namespace['operators']]
# We keep track of the CRD objects separately from the operator deployment so
# that we can make the deployment depend on the CRDs to avoid tilt thinking
# that there are conflicts with multiple CRDs.
if pxc_namespaces:
  k8s_resource(
    objects=[
      # The CRDs don't really get installed in a namespace, but since each
      # operator install is tied to a namespace, tilt uses a namespace to track
      # the install so we need to include one object per CRD per namespace.
      '%s:%s' % (crd, namespace) for namespace in pxc_namespaces for crd in [
              'perconaxtradbclusterbackups.pxc.percona.com:customresourcedefinition',
              'perconaxtradbclusterrestores.pxc.percona.com:customresourcedefinition',
              'perconaxtradbclusters.pxc.percona.com:customresourcedefinition'
          ]
    ],
    resource_deps = [
      'namespaces',
    ],
    new_name='pxc-crds',
    labels=["db-operators"]
  )
for namespace in pxc_namespaces:
  k8s_yaml(namespace_inject(pxc_operator_bundle_yaml, namespace))
  k8s_resource(
    workload='percona-xtradb-cluster-operator%s' % (':deployment:' + namespace if len(pxc_namespaces) > 1 else ''),
    objects=[
      'percona-xtradb-cluster-operator:serviceaccount:%s' % namespace,
      'percona-xtradb-cluster-operator:role:%s' % namespace,
      'service-account-percona-xtradb-cluster-operator:rolebinding:%s' % namespace,
    ],
    resource_deps = [
      'namespaces',
      'pxc-crds',
    ],
    new_name='pxc:%s' % namespace,
    labels=["db-operators"]
  )

# PSMDB
psmdb_operator_bundle_yaml = local(['curl', '-s', 'https://raw.githubusercontent.com/percona/percona-server-mongodb-operator/v%s/deploy/bundle.yaml' % psmdb_operator_version], quiet=True)
psmdb_namespaces = [namespace['name'] for namespace in config_yaml['namespaces'] if 'psmdb' in namespace['operators']]
# We keep track of the CRD objects separately from the operator deployment so
# that we can make the deployment depend on the CRDs to avoid tilt thinking
# that there are conflicts with multiple CRDs.
if psmdb_namespaces:
  k8s_resource(
    objects=[
      # The CRDs don't really get installed in a namespace, but since each
      # operator install is tied to a namespace, tilt uses a namespace to track
      # the install so we need to include one object per CRD per namespace.
      '%s:%s' % (crd, namespace) for namespace in psmdb_namespaces for crd in [
        'perconaservermongodbbackups.psmdb.percona.com:customresourcedefinition',
        'perconaservermongodbrestores.psmdb.percona.com:customresourcedefinition',
        'perconaservermongodbs.psmdb.percona.com:customresourcedefinition',
      ]
    ],
    resource_deps = [
      'namespaces',
    ],
    new_name='psmdb-crds',
    labels=["db-operators"]
  )
for namespace in psmdb_namespaces:
  k8s_yaml(namespace_inject(psmdb_operator_bundle_yaml, namespace))
  k8s_resource(
    workload='percona-server-mongodb-operator%s' % (':deployment:' + namespace if len(psmdb_namespaces) > 1 else ''),
    objects=[
      'percona-server-mongodb-operator:serviceaccount:%s' % namespace,
      'percona-server-mongodb-operator:role:%s' % namespace,
      'service-account-percona-server-mongodb-operator:rolebinding:%s' % namespace,
    ],
    resource_deps = [
      'namespaces',
      'psmdb-crds',
    ],
    new_name='psmdb:%s' % namespace,
    labels=["db-operators"]
  )

# PG
pg_operator_bundle_yaml = local(['curl', '-s', 'https://raw.githubusercontent.com/percona/percona-postgresql-operator/v%s/deploy/bundle.yaml' % pg_operator_version], quiet=True)
pg_namespaces = [namespace['name'] for namespace in config_yaml['namespaces'] if 'pg' in namespace['operators']]
# We keep track of the CRD objects separately from the operator deployment so
# that we can make the deployment depend on the CRDs to avoid tilt thinking
# that there are conflicts with multiple CRDs.
if pg_namespaces:
 k8s_resource(
   objects=[
     # The CRDs don't really get installed in a namespace, but since each
     # operator install is tied to a namespace, tilt uses a namespace to track
     # the install so we need to include one object per CRD per namespace.
     '%s:%s' % (crd, namespace) for namespace in pg_namespaces for crd in [
       'perconapgbackups.pgv2.percona.com:customresourcedefinition',
       'perconapgclusters.pgv2.percona.com:customresourcedefinition',
       'perconapgrestores.pgv2.percona.com:customresourcedefinition',
       'postgresclusters.postgres-operator.crunchydata.com:customresourcedefinition',
       'crunchybridgeclusters.postgres-operator.crunchydata.com:customresourcedefinition',
       'perconapgupgrades.pgv2.percona.com:customresourcedefinition',
       'pgadmins.postgres-operator.crunchydata.com:customresourcedefinition',
       'pgupgrades.postgres-operator.crunchydata.com:customresourcedefinition'
     ]
   ],
   resource_deps = [
     'namespaces',
   ],
   new_name='pg-crds',
   labels=["db-operators"]
 )
for namespace in pg_namespaces:
  k8s_yaml(namespace_inject(pg_operator_bundle_yaml, namespace))
  k8s_resource(
    workload='percona-postgresql-operator%s' % (':deployment:' + namespace if len(pg_namespaces) > 1 else ''),
    objects=[
      'percona-postgresql-operator:serviceaccount:%s' % namespace,
      'percona-postgresql-operator:role:%s' % namespace,
      'percona-postgresql-operator:rolebinding:%s' % namespace,
    ],
    resource_deps = [
      'namespaces',
      'pg-crds',
    ],
    new_name='pg:%s' % namespace,
    labels=["db-operators"]
  )

################################
### Deploy Everest Helm chart ##
################################

# First apply the CRDs since we will not apply them in the helm chart.
everest_crds = kustomize('%s/config/crd' % operator_dir)
k8s_yaml(everest_crds)

everest_yaml = helm(
    everest_chart_dir,
    name='everest',
    namespace=everest_namespace,
    skip_crds=True,
    set=[
        'dbNamespace.enabled=false',
        'upgrade.preflightChecks=false',
        'olm.install=false',
        'createMonitoringResources=false',
        'monitoring.crds.enabled=true',
        'monitoring.crds.plain=false',
        'server.initialAdminPassword=admin',
    ],
)
# we don't need the catalog source
everest_catalog_source_yaml, everest_yaml = filter_yaml(everest_yaml, kind='CatalogSource', name='everest-catalog')
k8s_yaml(everest_yaml)

#################################
####### Monitoring stack ########
#################################

k8s_resource(
  objects=[
    '%s:namespace' % everest_monitoring_namespace
  ],
  new_name='everest-monitoring-namespace',
)
k8s_resource(
    workload='kube-state-metrics',
    objects=[
        'kube-state-metrics:serviceaccount:%s' % everest_monitoring_namespace,
        'kube-state-metrics:clusterrole',
        'kube-state-metrics:clusterrolebinding',
        'customresource-config-ksm:configmap'
    ],
    resource_deps = [
      'everest-monitoring-namespace',
    ],
    new_name='kube-state-metrics-deploy',
    labels=["everest-monitoring"]
)
k8s_resource(
    objects = [
        'vlogs.operator.victoriametrics.com:customresourcedefinition',
        'vmagents.operator.victoriametrics.com:customresourcedefinition',
        'vmalertmanagerconfigs.operator.victoriametrics.com:customresourcedefinition',
        'vmalertmanagers.operator.victoriametrics.com:customresourcedefinition',
        'vmalerts.operator.victoriametrics.com:customresourcedefinition',
        'vmauths.operator.victoriametrics.com:customresourcedefinition',
        'vmclusters.operator.victoriametrics.com:customresourcedefinition',
        'vmnodescrapes.operator.victoriametrics.com:customresourcedefinition',
        'vmpodscrapes.operator.victoriametrics.com:customresourcedefinition',
        'vmprobes.operator.victoriametrics.com:customresourcedefinition',
        'vmrules.operator.victoriametrics.com:customresourcedefinition',
        'vmscrapeconfigs.operator.victoriametrics.com:customresourcedefinition',
        'vmservicescrapes.operator.victoriametrics.com:customresourcedefinition',
        'vmsingles.operator.victoriametrics.com:customresourcedefinition',
        'vmstaticscrapes.operator.victoriametrics.com:customresourcedefinition',
        'vmusers.operator.victoriametrics.com:customresourcedefinition',

    ],
    new_name='vm-crds',
    labels=["everest-monitoring"]
)
k8s_resource(
    workload='vm-operator',
    objects = [
        'vm-operator:serviceaccount',
        'vm-operator:role',
        'vm-operator:clusterrole',
        "victoriametrics\\:admin:clusterrole",
        "victoriametrics\\:view:clusterrole",
        'vm-operator:clusterrolebinding',
        'vm-operator:rolebinding'

    ],
    resource_deps = [
      'everest-monitoring-namespace',
      'vm-crds',
    ],
    new_name='vm-operator-deploy',
    labels=["everest-monitoring"]
)

################################
####### Everest operator #######
################################

# Generate the Everest operator manifests
local_resource(
  'operator-gen-manifests',
  'make -C %s fmt manifests generate' % operator_dir,
  deps=['%s/api' % operator_dir],
  ignore=['%s/api/*/zz_generated.deepcopy.go' % operator_dir],
  labels=["everest-operator"]
)

# Build the Everest operator manager locally to take advantage of the go cache
local_resource(
  'operator-build',
  'make -C %s fmt; CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -C %s -o ./bin/manager ./cmd/main.go' % (operator_dir, operator_dir),
  deps=['%s/api' % operator_dir, '%s/internal' % operator_dir, '%s/cmd/main.go' % operator_dir],
  labels=["everest-operator"]
)

# Live update the Everest operator manager without generating a new pod
load('ext://restart_process', 'docker_build_with_restart')
docker_build_with_restart('perconalab/everest-operator',
  context='%s' % operator_dir,
  dockerfile='./everest-operator.Dockerfile',
  entrypoint='/home/tilt/manager --system-namespace=%s --monitoring-namespace=%s' % (everest_namespace, everest_monitoring_namespace),
  only=['%s/bin/manager' % operator_dir],
  live_update=[
    sync('%s/bin/manager' % operator_dir, '/home/tilt/manager'),
  ]
)

k8s_resource(
    objects=[
        'backupstorages.everest.percona.com:customresourcedefinition',
        'databaseclusterbackups.everest.percona.com:customresourcedefinition',
        'databaseclusterrestores.everest.percona.com:customresourcedefinition',
        'databaseclusters.everest.percona.com:customresourcedefinition',
        'databaseengines.everest.percona.com:customresourcedefinition',
        'monitoringconfigs.everest.percona.com:customresourcedefinition',
    ],
    new_name='everest-crds',
    labels=["everest-operator"]
)
k8s_resource(
    workload='everest-operator',
    objects=[
    'everest-operator-controller-manager:serviceaccount:%s' % everest_namespace,
    'everest-operator-leader-election-role:role:%s' % everest_namespace,
    'everest-operator-local:rolebinding:%s' % everest_namespace,
    'everest-operator-metrics-reader:clusterrole',
    'everest-operator-metrics-auth-role:clusterrole',
    'everest-operator-metrics-auth-rolebinding:clusterrolebinding',
    'everest-operator-manager-role:clusterrole',
    'everest-operator-leader-election-rolebinding:rolebinding',
    'everest-operator-manager-rolebinding:clusterrolebinding'

    ],
    resource_deps = [
      'everest-namespace',
      'everest-crds',
    ],
    new_name='everest-operator-deploy',
    labels=["everest-operator"]
)

#################################
############ Everest ############
#################################

# Build backend
local_resource(
  'backend-build',
  'CGO_ENABLED=0 GOOS=linux GOARCH=amd64 make -C %s build' % backend_dir,
  deps=['%s/api' % backend_dir, '%s/cmd' % backend_dir, '%s/pkg' % backend_dir, '%s/public' % backend_dir, '%s/internal' % backend_dir],
  labels=["everest"]
)

# Build frontend
local_resource(
  'frontend-build',
  'make -C %s build EVEREST_OUT_DIR=%s/public/dist' % (frontend_dir, backend_dir),
  deps=['%s/apps' % frontend_dir],
  ignore=['%s/apps/*/dist' % frontend_dir, '%s/apps/*/.turbo' % frontend_dir],
  labels=["everest"]
)

# Live update the Everest container without generating a new pod
docker_build_with_restart('perconalab/everest',
  context='%s' % backend_dir,
  dockerfile='./everest.Dockerfile',
  entrypoint='/home/tilt/everest-api',
  only=['%s/bin/everest' % backend_dir],
  live_update=[
    sync('%s/bin/everest' % backend_dir, '/home/tilt/everest-api'),
  ]
)

k8s_resource(
    workload='everest-server',
    objects=[
    'everest-accounts:secret:%s' % everest_namespace,
    'everest-jwt:secret:%s' % everest_namespace,
    'everest-rbac:configmap:%s' % everest_namespace,
    'everest-settings:configmap:%s' % everest_namespace,
    'everest-admin-role:role:%s' % everest_namespace,
    'everest-admin-cluster-role:clusterrole',
    'everest-admin-cluster-role-binding:clusterrolebinding',
    'everest-admin:serviceaccount:%s' % everest_namespace,
    'everest-admin-role-binding:rolebinding'
    ],
    resource_deps = [
      'everest-namespace',
    ],
    port_forwards=8080,
    new_name='everest-server-deploy',
    labels=["everest"]
)
