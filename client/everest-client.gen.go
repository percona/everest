// Package client provides primitives to interact with the openapi HTTP API.
//
// Code generated by github.com/oapi-codegen/oapi-codegen/v2 version v2.5.0 DO NOT EDIT.
package client

import (
	"bytes"
	"compress/gzip"
	"context"
	"encoding/base64"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"net/url"
	"path"
	"strings"
	"time"

	"github.com/getkin/kin-openapi/openapi3"
	"github.com/oapi-codegen/runtime"
)

const (
	BearerAuthScopes = "BearerAuth.Scopes"
)

// Defines values for BackupStorageType.
const (
	BackupStorageTypeAzure BackupStorageType = "azure"
	BackupStorageTypeS3    BackupStorageType = "s3"
)

// Defines values for CreateBackupStorageParamsType.
const (
	CreateBackupStorageParamsTypeAzure CreateBackupStorageParamsType = "azure"
	CreateBackupStorageParamsTypeS3    CreateBackupStorageParamsType = "s3"
)

// Defines values for DatabaseClusterSpecDataSourcePitrType.
const (
	DatabaseClusterSpecDataSourcePitrTypeDate   DatabaseClusterSpecDataSourcePitrType = "date"
	DatabaseClusterSpecDataSourcePitrTypeLatest DatabaseClusterSpecDataSourcePitrType = "latest"
)

// Defines values for DatabaseClusterSpecEngineType.
const (
	DatabaseClusterSpecEngineTypePostgresql DatabaseClusterSpecEngineType = "postgresql"
	DatabaseClusterSpecEngineTypePsmdb      DatabaseClusterSpecEngineType = "psmdb"
	DatabaseClusterSpecEngineTypePxc        DatabaseClusterSpecEngineType = "pxc"
)

// Defines values for DatabaseClusterSpecProxyExposeType.
const (
	External DatabaseClusterSpecProxyExposeType = "external"
	Internal DatabaseClusterSpecProxyExposeType = "internal"
)

// Defines values for DatabaseClusterSpecProxyType.
const (
	Haproxy   DatabaseClusterSpecProxyType = "haproxy"
	Mongos    DatabaseClusterSpecProxyType = "mongos"
	Pgbouncer DatabaseClusterSpecProxyType = "pgbouncer"
	Proxysql  DatabaseClusterSpecProxyType = "proxysql"
)

// Defines values for DatabaseClusterStatusConditionsStatus.
const (
	False   DatabaseClusterStatusConditionsStatus = "False"
	True    DatabaseClusterStatusConditionsStatus = "True"
	Unknown DatabaseClusterStatusConditionsStatus = "Unknown"
)

// Defines values for DatabaseClusterRestoreSpecDataSourcePitrType.
const (
	DatabaseClusterRestoreSpecDataSourcePitrTypeDate   DatabaseClusterRestoreSpecDataSourcePitrType = "date"
	DatabaseClusterRestoreSpecDataSourcePitrTypeLatest DatabaseClusterRestoreSpecDataSourcePitrType = "latest"
)

// Defines values for MonitoringInstanceBaseType.
const (
	MonitoringInstanceBaseTypePmm MonitoringInstanceBaseType = "pmm"
)

// Defines values for MonitoringInstanceBaseWithNameType.
const (
	MonitoringInstanceBaseWithNameTypePmm MonitoringInstanceBaseWithNameType = "pmm"
)

// Defines values for MonitoringInstanceCreateParamsType.
const (
	MonitoringInstanceCreateParamsTypePmm MonitoringInstanceCreateParamsType = "pmm"
)

// Defines values for MonitoringInstanceUpdateParamsType.
const (
	MonitoringInstanceUpdateParamsTypePmm MonitoringInstanceUpdateParamsType = "pmm"
)

// Defines values for PodSchedulingPolicySpecEngineType.
const (
	PodSchedulingPolicySpecEngineTypePostgresql PodSchedulingPolicySpecEngineType = "postgresql"
	PodSchedulingPolicySpecEngineTypePsmdb      PodSchedulingPolicySpecEngineType = "psmdb"
	PodSchedulingPolicySpecEngineTypePxc        PodSchedulingPolicySpecEngineType = "pxc"
)

// Defines values for UpgradeTaskPendingTask.
const (
	NotReady      UpgradeTaskPendingTask = "notReady"
	Ready         UpgradeTaskPendingTask = "ready"
	Restart       UpgradeTaskPendingTask = "restart"
	UpgradeEngine UpgradeTaskPendingTask = "upgradeEngine"
)

// Defines values for ListPodSchedulingPolicyParamsEngineType.
const (
	Postgresql ListPodSchedulingPolicyParamsEngineType = "postgresql"
	Psmdb      ListPodSchedulingPolicyParamsEngineType = "psmdb"
	Pxc        ListPodSchedulingPolicyParamsEngineType = "pxc"
)

// BackupStorage Backup storage information
type BackupStorage struct {
	// AllowedNamespaces List of namespaces allowed to use this backup storage
	// Deprecated: this property has been marked as deprecated upstream, but no `x-deprecated-reason` was set
	AllowedNamespaces *[]string         `json:"allowedNamespaces,omitempty"`
	BucketName        string            `json:"bucketName"`
	Description       *string           `json:"description,omitempty"`
	ForcePathStyle    *bool             `json:"forcePathStyle,omitempty"`
	Name              string            `json:"name"`
	Namespace         string            `json:"namespace,omitempty"`
	Region            string            `json:"region,omitempty"`
	Type              BackupStorageType `json:"type"`
	Url               *string           `json:"url,omitempty"`
	VerifyTLS         *bool             `json:"verifyTLS,omitempty"`
}

// BackupStorageType defines model for BackupStorage.Type.
type BackupStorageType string

// BackupStoragesList defines model for BackupStoragesList.
type BackupStoragesList = []BackupStorage

// CreateBackupStorageParams Backup storage parameters
type CreateBackupStorageParams struct {
	AccessKey string `json:"accessKey"`

	// AllowedNamespaces List of namespaces allowed to use this backup storage
	// Deprecated: this property has been marked as deprecated upstream, but no `x-deprecated-reason` was set
	AllowedNamespaces *[]string `json:"allowedNamespaces,omitempty"`

	// BucketName The cloud storage bucket/container name
	BucketName     string  `json:"bucketName"`
	Description    *string `json:"description,omitempty"`
	ForcePathStyle *bool   `json:"forcePathStyle,omitempty"`

	// Name A user defined string name of the storage in the DNS name format https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#dns-label-names
	Name      string                        `json:"name"`
	Region    string                        `json:"region,omitempty"`
	SecretKey string                        `json:"secretKey"`
	Type      CreateBackupStorageParamsType `json:"type"`
	Url       *string                       `json:"url,omitempty"`
	VerifyTLS *bool                         `json:"verifyTLS,omitempty"`
}

// CreateBackupStorageParamsType defines model for CreateBackupStorageParams.Type.
type CreateBackupStorageParamsType string

// DataImportJob DataImportJob is the schema for the dataimportjobs API.
type DataImportJob struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object.
	// Servers should convert recognized schemas to the latest internal value, and
	// may reject unrecognized values.
	// More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string `json:"apiVersion,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents.
	// Servers may infer this from the endpoint the client submits requests to.
	// Cannot be updated.
	// In CamelCase.
	// More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`
	Spec     *struct {
		// Config Config defines the configuration for the data import job.
		// These options are specific to the DataImporter being used and must conform to
		// the schema defined in the DataImporter's .spec.config.openAPIV3Schema.
		Config *map[string]interface{} `json:"config,omitempty"`

		// DataImporterName DataImporterName is the data importer to use for the import.
		DataImporterName string `json:"dataImporterName"`

		// Source Source is the source of the data to import.
		Source struct {
			// Path Path is the path to the directory to import the data from.
			// This may be a path to a file or a directory, depending on the data importer.
			Path *string `json:"path,omitempty"`

			// S3 S3 contains the S3 information for the data import.
			S3 *struct {
				// AccessKeyId AccessKeyID allows specifying the S3 access key ID inline.
				// It is provided as a write-only input field for convenience.
				// When this field is set, a webhook writes this value in the Secret specified by `credentialsSecretName`
				// and empties this field.
				// This field is not stored in the API.
				AccessKeyId *string `json:"accessKeyId,omitempty"`

				// Bucket Bucket is the name of the S3 bucket.
				Bucket *string `json:"bucket,omitempty"`

				// CredentialsSecretName CredentialsSecreName is the reference to the secret containing the S3 credentials.
				// The Secret must contain the keys `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY`.
				CredentialsSecretName string `json:"credentialsSecretName"`

				// EndpointURL EndpointURL is an endpoint URL of backup storage.
				EndpointURL *string `json:"endpointURL,omitempty"`

				// ForcePathStyle ForcePathStyle is set to use path-style URLs.
				// If unspecified, the default value is false.
				ForcePathStyle *bool `json:"forcePathStyle,omitempty"`

				// Region Region is the region of the S3 bucket.
				Region *string `json:"region,omitempty"`

				// SecretAccessKey SecretAccessKey allows specifying the S3 secret access key inline.
				// It is provided as a write-only input field for convenience.
				// When this field is set, a webhook writes this value in the Secret specified by `credentialsSecretName`
				// and empties this field.
				// This field is not stored in the API.
				SecretAccessKey *string `json:"secretAccessKey,omitempty"`

				// VerifyTLS VerifyTLS is set to ensure TLS/SSL verification.
				// If unspecified, the default value is true.
				VerifyTLS *bool `json:"verifyTLS,omitempty"`
			} `json:"s3,omitempty"`
		} `json:"source"`

		// TargetClusterName TargetClusterName is the reference to the target cluster.
		TargetClusterName string `json:"targetClusterName"`
	} `json:"spec,omitempty"`
	Status *struct {
		// CompletedAt CompletedAt is the time when the data import job completed successfully.
		CompletedAt *time.Time `json:"completedAt,omitempty"`

		// JobName JobName is the reference to the job that is running the data import.
		JobName *string `json:"jobName,omitempty"`

		// LastObservedGeneration LastObservedGeneration is the last observed generation of the data import job.
		LastObservedGeneration *int64 `json:"lastObservedGeneration,omitempty"`

		// Message Message is the message of the data import job.
		Message *string `json:"message,omitempty"`

		// StartedAt StartedAt is the time when the data import job started.
		StartedAt *time.Time `json:"startedAt,omitempty"`

		// State State is the current state of the data import job.
		State *string `json:"state,omitempty"`
	} `json:"status,omitempty"`
}

// DataImportJobList DataImportJobList is an object that contains the list of the existing data import jobs.
type DataImportJobList struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string          `json:"apiVersion,omitempty"`
	Items      *[]DataImportJob `json:"items,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`
}

// DataImporter DataImporter defines a reusable strategy for importing data into a DatabaseCluster.
type DataImporter struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object.
	// Servers should convert recognized schemas to the latest internal value, and
	// may reject unrecognized values.
	// More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string `json:"apiVersion,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents.
	// Servers may infer this from the endpoint the client submits requests to.
	// Cannot be updated.
	// In CamelCase.
	// More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`

	// Spec DataImporterSpec defines the specification of a DataImporter.
	Spec *struct {
		// ClusterPermissions ClusterPermissions defines the cluster-wide permissions required by the data importer.
		// These permissions are used to generate a ClusterRole for the data importer job.
		ClusterPermissions *[]struct {
			// ApiGroups APIGroups is the name of the APIGroup that contains the resources.  If multiple API groups are specified, any action requested against one of
			// the enumerated resources in any API group will be allowed. "" represents the core API group and "*" represents all API groups.
			ApiGroups *[]string `json:"apiGroups,omitempty"`

			// NonResourceURLs NonResourceURLs is a set of partial urls that a user should have access to.  *s are allowed, but only as the full, final step in the path
			// Since non-resource URLs are not namespaced, this field is only applicable for ClusterRoles referenced from a ClusterRoleBinding.
			// Rules can either apply to API resources (such as "pods" or "secrets") or non-resource URL paths (such as "/api"),  but not both.
			NonResourceURLs *[]string `json:"nonResourceURLs,omitempty"`

			// ResourceNames ResourceNames is an optional white list of names that the rule applies to.  An empty set means that everything is allowed.
			ResourceNames *[]string `json:"resourceNames,omitempty"`

			// Resources Resources is a list of resources this rule applies to. '*' represents all resources.
			Resources *[]string `json:"resources,omitempty"`

			// Verbs Verbs is a list of Verbs that apply to ALL the ResourceKinds contained in this rule. '*' represents all verbs.
			Verbs []string `json:"verbs"`
		} `json:"clusterPermissions,omitempty"`

		// Config Config contains additional configuration defined for the data importer.
		Config *struct {
			// OpenAPIV3Schema OpenAPIV3Schema is the OpenAPI v3 schema of the data importer.
			OpenAPIV3Schema interface{} `json:"openAPIV3Schema,omitempty"`
		} `json:"config,omitempty"`

		// DatabaseClusterConstraints DatabaseClusterConstraints defines compatibility requirements and prerequisites that must be satisfied
		// by a DatabaseCluster before this data importer can be used with it. This allows the data importer to
		// express specific requirements about the database configuration needed for successful import operations,
		// such as required database fields, specific engine configurations, or other database properties.
		// When a DatabaseCluster references this data importer, the operator will validate the DatabaseCluster
		// against these constraints before proceeding with the import operation.
		DatabaseClusterConstraints *struct {
			// RequiredFields RequiredFields contains a list of fields that must be set in the DatabaseCluster spec.
			// Each key is a JSON path expressions that points to a field in the DatabaseCluster spec.
			// For example, ".spec.engine.type" or ".spec.dataSource.dataImport.config.someField".
			RequiredFields *[]string `json:"requiredFields,omitempty"`
		} `json:"databaseClusterConstraints,omitempty"`

		// Description Description is the description of the data importer.
		Description *string `json:"description,omitempty"`

		// DisplayName DisplayName is a human-readable name for the data importer.
		DisplayName *string `json:"displayName,omitempty"`

		// JobSpec JobSpec is the specification of the data importer job.
		JobSpec *struct {
			// Command Command is the command to run the data importer.
			Command *[]string `json:"command,omitempty"`

			// Image Image is the image of the data importer.
			Image *string `json:"image,omitempty"`
		} `json:"jobSpec,omitempty"`

		// Permissions Permissions defines the permissions required by the data importer.
		// These permissions are used to generate a Role for the data importer job.
		Permissions *[]struct {
			// ApiGroups APIGroups is the name of the APIGroup that contains the resources.  If multiple API groups are specified, any action requested against one of
			// the enumerated resources in any API group will be allowed. "" represents the core API group and "*" represents all API groups.
			ApiGroups *[]string `json:"apiGroups,omitempty"`

			// NonResourceURLs NonResourceURLs is a set of partial urls that a user should have access to.  *s are allowed, but only as the full, final step in the path
			// Since non-resource URLs are not namespaced, this field is only applicable for ClusterRoles referenced from a ClusterRoleBinding.
			// Rules can either apply to API resources (such as "pods" or "secrets") or non-resource URL paths (such as "/api"),  but not both.
			NonResourceURLs *[]string `json:"nonResourceURLs,omitempty"`

			// ResourceNames ResourceNames is an optional white list of names that the rule applies to.  An empty set means that everything is allowed.
			ResourceNames *[]string `json:"resourceNames,omitempty"`

			// Resources Resources is a list of resources this rule applies to. '*' represents all resources.
			Resources *[]string `json:"resources,omitempty"`

			// Verbs Verbs is a list of Verbs that apply to ALL the ResourceKinds contained in this rule. '*' represents all verbs.
			Verbs []string `json:"verbs"`
		} `json:"permissions,omitempty"`

		// SupportedEngines SupportedEngines is the list of engines that the data importer supports.
		SupportedEngines *[]string `json:"supportedEngines,omitempty"`
	} `json:"spec,omitempty"`
	Status *map[string]interface{} `json:"status,omitempty"`
}

// DataImporterList DataImporterList is an object that contains the list of the existing data importers.
type DataImporterList struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string         `json:"apiVersion,omitempty"`
	Items      *[]DataImporter `json:"items,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`
}

// DatabaseCluster DatabaseCluster is the Schema for the databaseclusters API.
type DatabaseCluster struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object.
	// Servers should convert recognized schemas to the latest internal value, and
	// may reject unrecognized values.
	// More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string `json:"apiVersion,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents.
	// Servers may infer this from the endpoint the client submits requests to.
	// Cannot be updated.
	// In CamelCase.
	// More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`

	// Spec DatabaseClusterSpec defines the desired state of DatabaseCluster.
	Spec *struct {
		// AllowUnsafeConfiguration AllowUnsafeConfiguration field used to ensure that the user can create configurations unfit for production use.
		//
		// Deprecated: AllowUnsafeConfiguration will not be supported in the future releases.
		AllowUnsafeConfiguration *bool `json:"allowUnsafeConfiguration,omitempty"`

		// Backup Backup is the backup specification
		Backup *struct {
			// Enabled Enabled is a flag to enable backups
			// Deprecated. Please use db.spec.backup.schedules[].enabled to control each schedule separately and db.spec.backup.pitr.enabled to control PITR.
			Enabled *bool `json:"enabled,omitempty"`

			// Pitr PITR is the configuration of the point in time recovery
			Pitr *struct {
				// BackupStorageName BackupStorageName is the name of the BackupStorage where the PITR is enabled
				// The BackupStorage must be created in the same namespace as the DatabaseCluster.
				BackupStorageName *string `json:"backupStorageName,omitempty"`

				// Enabled Enabled is a flag to enable PITR
				Enabled bool `json:"enabled"`

				// UploadIntervalSec UploadIntervalSec number of seconds between the binlogs uploads
				UploadIntervalSec *int `json:"uploadIntervalSec,omitempty"`
			} `json:"pitr,omitempty"`

			// Schedules Schedules is a list of backup schedules
			Schedules *[]struct {
				// BackupStorageName BackupStorageName is the name of the BackupStorage CR that defines the
				// storage location.
				// The BackupStorage must be created in the same namespace as the DatabaseCluster.
				BackupStorageName string `json:"backupStorageName"`

				// Enabled Enabled is a flag to enable the schedule
				Enabled bool `json:"enabled"`

				// Name Name is the name of the schedule
				Name string `json:"name"`

				// RetentionCopies RetentionCopies is the number of backup copies to retain
				RetentionCopies *int32 `json:"retentionCopies,omitempty"`

				// Schedule Schedule is the cron schedule
				Schedule string `json:"schedule"`
			} `json:"schedules,omitempty"`
		} `json:"backup,omitempty"`

		// DataSource DataSource defines a data source for bootstraping a new cluster
		DataSource *struct {
			// BackupSource BackupSource is the backup source to restore from
			BackupSource *struct {
				// BackupStorageName BackupStorageName is the name of the BackupStorage used for storing backups.
				// The BackupStorage must be created in the same namespace as the DatabaseCluster.
				BackupStorageName string `json:"backupStorageName"`

				// Path Path is the path to the backup file/directory.
				Path string `json:"path"`
			} `json:"backupSource,omitempty"`

			// DataImport DataImport allows importing data from an external backup source.
			DataImport *struct {
				// Config Config defines the configuration for the data import job.
				// These options are specific to the DataImporter being used and must conform to
				// the schema defined in the DataImporter's .spec.config.openAPIV3Schema.
				Config *map[string]interface{} `json:"config,omitempty"`

				// DataImporterName DataImporterName is the data importer to use for the import.
				DataImporterName string `json:"dataImporterName"`

				// Source Source is the source of the data to import.
				Source struct {
					// Path Path is the path to the directory to import the data from.
					// This may be a path to a file or a directory, depending on the data importer.
					// Only absolute file paths are allowed. Leading and trailing '/' are optional.
					Path string `json:"path"`

					// S3 S3 contains the S3 information for the data import.
					S3 *struct {
						// AccessKeyId AccessKeyID allows specifying the S3 access key ID inline.
						// It is provided as a write-only input field for convenience.
						// When this field is set, a webhook writes this value in the Secret specified by `credentialsSecretName`
						// and empties this field.
						// This field is not stored in the API.
						AccessKeyId *string `json:"accessKeyId,omitempty"`

						// Bucket Bucket is the name of the S3 bucket.
						Bucket string `json:"bucket"`

						// CredentialsSecretName CredentialsSecreName is the reference to the secret containing the S3 credentials.
						// The Secret must contain the keys `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY`.
						CredentialsSecretName string `json:"credentialsSecretName"`

						// EndpointURL EndpointURL is an endpoint URL of backup storage.
						EndpointURL string `json:"endpointURL"`

						// ForcePathStyle ForcePathStyle is set to use path-style URLs.
						// If unspecified, the default value is false.
						ForcePathStyle *bool `json:"forcePathStyle,omitempty"`

						// Region Region is the region of the S3 bucket.
						Region string `json:"region"`

						// SecretAccessKey SecretAccessKey allows specifying the S3 secret access key inline.
						// It is provided as a write-only input field for convenience.
						// When this field is set, a webhook writes this value in the Secret specified by `credentialsSecretName`
						// and empties this field.
						// This field is not stored in the API.
						SecretAccessKey *string `json:"secretAccessKey,omitempty"`

						// VerifyTLS VerifyTLS is set to ensure TLS/SSL verification.
						// If unspecified, the default value is true.
						VerifyTLS *bool `json:"verifyTLS,omitempty"`
					} `json:"s3,omitempty"`
				} `json:"source"`
			} `json:"dataImport,omitempty"`

			// DbClusterBackupName DBClusterBackupName is the name of the DB cluster backup to restore from
			DbClusterBackupName *string `json:"dbClusterBackupName,omitempty"`

			// Pitr PITR is the point-in-time recovery configuration
			Pitr *struct {
				// Date Date is the UTC date to recover to. The accepted format: "2006-01-02T15:04:05Z".
				Date *string `json:"date,omitempty"`

				// Type Type is the type of recovery.
				Type *DatabaseClusterSpecDataSourcePitrType `json:"type,omitempty"`
			} `json:"pitr,omitempty"`
		} `json:"dataSource,omitempty"`

		// Engine Engine is the database engine specification
		Engine struct {
			// Config Config is the engine configuration
			Config *string `json:"config,omitempty"`

			// CrVersion CRVersion is the desired version of the CR to use with the
			// underlying operator.
			// If unspecified, everest-operator will use the same version as the operator.
			//
			// NOTE: Updating this property post installation may lead to a restart of the cluster.
			CrVersion *string `json:"crVersion,omitempty"`

			// Replicas Replicas is the number of engine replicas
			Replicas *int32 `json:"replicas,omitempty"`

			// Resources Resources are the resource limits for each engine replica.
			// If not set, resource limits are not imposed
			Resources *struct {
				// Cpu CPU is the CPU resource requirements
				Cpu *DatabaseCluster_Spec_Engine_Resources_Cpu `json:"cpu,omitempty"`

				// Memory Memory is the memory resource requirements
				Memory *DatabaseCluster_Spec_Engine_Resources_Memory `json:"memory,omitempty"`
			} `json:"resources,omitempty"`

			// Storage Storage is the engine storage configuration
			Storage struct {
				// Class Class is the storage class to use for the persistent volume claim
				Class *string `json:"class,omitempty"`

				// Size Size is the size of the persistent volume claim
				Size DatabaseCluster_Spec_Engine_Storage_Size `json:"size"`
			} `json:"storage"`

			// Type Type is the engine type
			Type DatabaseClusterSpecEngineType `json:"type"`

			// UserSecretsName UserSecretsName is the name of the secret containing the user secrets
			UserSecretsName *string `json:"userSecretsName,omitempty"`

			// Version Version is the engine version
			Version *string `json:"version,omitempty"`
		} `json:"engine"`

		// EngineFeatures EngineFeatures represents configuration of additional features for the database engine.
		EngineFeatures *struct {
			// Psmdb PSMDB represents additional features for the PSMDB engine.
			Psmdb *struct {
				// SplitHorizonDnsConfigName SplitHorizonDNSConfigName is the name of a SplitHorizonDNSConfig CR.
				// The SplitHorizonDNSConfig must be created in the same namespace as the DatabaseCluster.
				SplitHorizonDnsConfigName *string `json:"splitHorizonDnsConfigName,omitempty"`
			} `json:"psmdb,omitempty"`
		} `json:"engineFeatures,omitempty"`

		// Monitoring Monitoring is the monitoring configuration
		Monitoring *struct {
			// MonitoringConfigName MonitoringConfigName is the name of a monitoringConfig CR.
			// The MonitoringConfig must be created in the same namespace as the DatabaseCluster.
			MonitoringConfigName *string `json:"monitoringConfigName,omitempty"`

			// Resources Resources defines resource limitations for the monitoring.
			Resources *struct {
				// Claims Claims lists the names of resources, defined in spec.resourceClaims,
				// that are used by this container.
				//
				// This field depends on the
				// DynamicResourceAllocation feature gate.
				//
				// This field is immutable. It can only be set for containers.
				Claims *[]struct {
					// Name Name must match the name of one entry in pod.spec.resourceClaims of
					// the Pod where this field is used. It makes that resource available
					// inside a container.
					Name string `json:"name"`

					// Request Request is the name chosen for a request in the referenced claim.
					// If empty, everything from the claim is made available, otherwise
					// only the result of this request.
					Request *string `json:"request,omitempty"`
				} `json:"claims,omitempty"`

				// Limits Limits describes the maximum amount of compute resources allowed.
				// More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
				Limits *map[string]DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties `json:"limits,omitempty"`

				// Requests Requests describes the minimum amount of compute resources required.
				// If Requests is omitted for a container, it defaults to Limits if that is explicitly specified,
				// otherwise to an implementation-defined value. Requests cannot exceed Limits.
				// More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
				Requests *map[string]DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties `json:"requests,omitempty"`
			} `json:"resources,omitempty"`
		} `json:"monitoring,omitempty"`

		// Paused Paused is a flag to stop the cluster
		Paused *bool `json:"paused,omitempty"`

		// PodSchedulingPolicyName PodSchedulingPolicyName is the name of the PodSchedulingPolicy CR that defines rules for DB cluster pods allocation across the cluster.
		PodSchedulingPolicyName *string `json:"podSchedulingPolicyName,omitempty"`

		// Proxy Proxy is the proxy specification. If not set, an appropriate
		// proxy specification will be applied for the given engine. A
		// common use case for setting this field is to control the
		// external access to the database cluster.
		Proxy *struct {
			// Config Config is the proxy configuration
			Config *string `json:"config,omitempty"`

			// Expose Expose is the proxy expose configuration
			Expose *struct {
				// IpSourceRanges IPSourceRanges is the list of IP source ranges (CIDR notation)
				// to allow access from. If not set, there is no limitations
				IpSourceRanges *[]string `json:"ipSourceRanges,omitempty"`

				// LoadBalancerConfigName LoadBalancerConfigName is the name of load balancer config if applied
				LoadBalancerConfigName *string `json:"loadBalancerConfigName,omitempty"`

				// Type Type is the expose type, can be internal or external
				Type *DatabaseClusterSpecProxyExposeType `json:"type,omitempty"`
			} `json:"expose,omitempty"`

			// Replicas Replicas is the number of proxy replicas
			Replicas *int32 `json:"replicas,omitempty"`

			// Resources Resources are the resource limits for each proxy replica.
			// If not set, resource limits are not imposed
			Resources *struct {
				// Cpu CPU is the CPU resource requirements
				Cpu *DatabaseCluster_Spec_Proxy_Resources_Cpu `json:"cpu,omitempty"`

				// Memory Memory is the memory resource requirements
				Memory *DatabaseCluster_Spec_Proxy_Resources_Memory `json:"memory,omitempty"`
			} `json:"resources,omitempty"`

			// Type Type is the proxy type
			Type *DatabaseClusterSpecProxyType `json:"type,omitempty"`
		} `json:"proxy,omitempty"`

		// Sharding Sharding is the sharding configuration. PSMDB-only
		Sharding *struct {
			// ConfigServer ConfigServer represents the sharding configuration server settings
			ConfigServer struct {
				// Replicas Replicas is the amount of configServers
				Replicas int32 `json:"replicas"`
			} `json:"configServer"`

			// Enabled Enabled defines if the sharding is enabled
			Enabled bool `json:"enabled"`

			// Shards Shards defines the number of shards
			Shards int32 `json:"shards"`
		} `json:"sharding,omitempty"`
	} `json:"spec,omitempty"`

	// Status DatabaseClusterStatus defines the observed state of DatabaseCluster.
	Status *struct {
		// ActiveStorage ActiveStorage is the storage used in cluster (psmdb only)
		ActiveStorage *string `json:"activeStorage,omitempty"`

		// Conditions Conditions contains the observed conditions of the DatabaseCluster.
		Conditions *[]struct {
			// LastTransitionTime lastTransitionTime is the last time the condition transitioned from one status to another.
			// This should be when the underlying condition changed.  If that is not known, then using the time when the API field changed is acceptable.
			LastTransitionTime time.Time `json:"lastTransitionTime"`

			// Message message is a human readable message indicating details about the transition.
			// This may be an empty string.
			Message string `json:"message"`

			// ObservedGeneration observedGeneration represents the .metadata.generation that the condition was set based upon.
			// For instance, if .metadata.generation is currently 12, but the .status.conditions[x].observedGeneration is 9, the condition is out of date
			// with respect to the current state of the instance.
			ObservedGeneration *int64 `json:"observedGeneration,omitempty"`

			// Reason reason contains a programmatic identifier indicating the reason for the condition's last transition.
			// Producers of specific condition types may define expected values and meanings for this field,
			// and whether the values are considered a guaranteed API.
			// The value should be a CamelCase string.
			// This field may not be empty.
			Reason string `json:"reason"`

			// Status status of the condition, one of True, False, Unknown.
			Status DatabaseClusterStatusConditionsStatus `json:"status"`

			// Type type of condition in CamelCase or in foo.example.com/CamelCase.
			Type string `json:"type"`
		} `json:"conditions,omitempty"`

		// CrVersion CRVersion is the observed version of the CR used with the underlying operator.
		CrVersion *string `json:"crVersion,omitempty"`

		// DataImportJobName DataImportJobName refers to the DataImportJob that is used to import data into the cluster.
		// This is set only when .spec.dataSource.dataImport is set.
		DataImportJobName *string `json:"dataImportJobName,omitempty"`

		// Details Details provides full status of the upstream cluster as a plain text.
		Details *string `json:"details,omitempty"`

		// EngineFeatures EngineFeaturesStatus represents additional features statuses for the database engine.
		EngineFeatures *struct {
			// Psmdb PSMDB represents additional features statuses for the PSMDB engine.
			Psmdb *struct {
				// SplitHorizon SplitHorizon status of SplitHorizon feature.
				SplitHorizon *struct {
					// Domains SplitHorizon status of SplitHorizon feature.
					Domains *[]struct {
						// Domain Domain is the SplitHorizon domain name.
						Domain *string `json:"domain,omitempty"`

						// PrivateIP PrivateIP is the private IP address for the domain.
						PrivateIP *string `json:"privateIP,omitempty"`

						// PublicIP PublicIP is the public IP address for the domain.
						PublicIP *string `json:"publicIP,omitempty"`
					} `json:"domains,omitempty"`

					// Host ConnectionURL is the connection URL using SplitHorizon domains.
					Host *string `json:"host,omitempty"`
				} `json:"splitHorizon,omitempty"`
			} `json:"psmdb,omitempty"`
		} `json:"engineFeatures,omitempty"`

		// Hostname Hostname is the hostname where the cluster can be reached
		Hostname *string `json:"hostname,omitempty"`

		// Message Message is extra information about the cluster
		Message *string `json:"message,omitempty"`

		// ObservedGeneration ObservedGeneration is the most recent generation observed for this DatabaseCluster.
		ObservedGeneration *int64 `json:"observedGeneration,omitempty"`

		// Port Port is the port where the cluster can be reached
		Port *int32 `json:"port,omitempty"`

		// Ready Ready is the number of ready pods
		Ready *int32 `json:"ready,omitempty"`

		// RecommendedCRVersion RecommendedCRVersion indicates the target version that the underlying CR should be updated to.
		// When this field is set, it means the CR is running an outdated version and requires an update.
		// The following restrictions apply until the CR is updated to the recommended version:
		// - The operator cannot be upgraded
		// - The database engine version (.spec.engine.version) cannot be modified
		// This field is unset when the CR is already running at the latest recommended version.
		RecommendedCRVersion *string `json:"recommendedCRVersion,omitempty"`

		// Size Size is the total number of pods
		Size *int32 `json:"size,omitempty"`

		// Status Status is the status of the cluster
		Status *string `json:"status,omitempty"`
	} `json:"status,omitempty"`
}

// DatabaseClusterSpecDataSourcePitrType Type is the type of recovery.
type DatabaseClusterSpecDataSourcePitrType string

// DatabaseClusterSpecEngineResourcesCpu0 defines model for .
type DatabaseClusterSpecEngineResourcesCpu0 = int

// DatabaseClusterSpecEngineResourcesCpu1 defines model for .
type DatabaseClusterSpecEngineResourcesCpu1 = string

// DatabaseCluster_Spec_Engine_Resources_Cpu CPU is the CPU resource requirements
type DatabaseCluster_Spec_Engine_Resources_Cpu struct {
	union json.RawMessage
}

// DatabaseClusterSpecEngineResourcesMemory0 defines model for .
type DatabaseClusterSpecEngineResourcesMemory0 = int

// DatabaseClusterSpecEngineResourcesMemory1 defines model for .
type DatabaseClusterSpecEngineResourcesMemory1 = string

// DatabaseCluster_Spec_Engine_Resources_Memory Memory is the memory resource requirements
type DatabaseCluster_Spec_Engine_Resources_Memory struct {
	union json.RawMessage
}

// DatabaseClusterSpecEngineStorageSize0 defines model for .
type DatabaseClusterSpecEngineStorageSize0 = int

// DatabaseClusterSpecEngineStorageSize1 defines model for .
type DatabaseClusterSpecEngineStorageSize1 = string

// DatabaseCluster_Spec_Engine_Storage_Size Size is the size of the persistent volume claim
type DatabaseCluster_Spec_Engine_Storage_Size struct {
	union json.RawMessage
}

// DatabaseClusterSpecEngineType Type is the engine type
type DatabaseClusterSpecEngineType string

// DatabaseClusterSpecMonitoringResourcesLimits0 defines model for .
type DatabaseClusterSpecMonitoringResourcesLimits0 = int

// DatabaseClusterSpecMonitoringResourcesLimits1 defines model for .
type DatabaseClusterSpecMonitoringResourcesLimits1 = string

// DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties defines model for DatabaseCluster.Spec.Monitoring.Resources.Limits.AdditionalProperties.
type DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties struct {
	union json.RawMessage
}

// DatabaseClusterSpecMonitoringResourcesRequests0 defines model for .
type DatabaseClusterSpecMonitoringResourcesRequests0 = int

// DatabaseClusterSpecMonitoringResourcesRequests1 defines model for .
type DatabaseClusterSpecMonitoringResourcesRequests1 = string

// DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties defines model for DatabaseCluster.Spec.Monitoring.Resources.Requests.AdditionalProperties.
type DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties struct {
	union json.RawMessage
}

// DatabaseClusterSpecProxyExposeType Type is the expose type, can be internal or external
type DatabaseClusterSpecProxyExposeType string

// DatabaseClusterSpecProxyResourcesCpu0 defines model for .
type DatabaseClusterSpecProxyResourcesCpu0 = int

// DatabaseClusterSpecProxyResourcesCpu1 defines model for .
type DatabaseClusterSpecProxyResourcesCpu1 = string

// DatabaseCluster_Spec_Proxy_Resources_Cpu CPU is the CPU resource requirements
type DatabaseCluster_Spec_Proxy_Resources_Cpu struct {
	union json.RawMessage
}

// DatabaseClusterSpecProxyResourcesMemory0 defines model for .
type DatabaseClusterSpecProxyResourcesMemory0 = int

// DatabaseClusterSpecProxyResourcesMemory1 defines model for .
type DatabaseClusterSpecProxyResourcesMemory1 = string

// DatabaseCluster_Spec_Proxy_Resources_Memory Memory is the memory resource requirements
type DatabaseCluster_Spec_Proxy_Resources_Memory struct {
	union json.RawMessage
}

// DatabaseClusterSpecProxyType Type is the proxy type
type DatabaseClusterSpecProxyType string

// DatabaseClusterStatusConditionsStatus status of the condition, one of True, False, Unknown.
type DatabaseClusterStatusConditionsStatus string

// DatabaseClusterBackup DatabaseClusterBackup is the Schema for the databaseclusterbackups API.
type DatabaseClusterBackup struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object.
	// Servers should convert recognized schemas to the latest internal value, and
	// may reject unrecognized values.
	// More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string `json:"apiVersion,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents.
	// Servers may infer this from the endpoint the client submits requests to.
	// Cannot be updated.
	// In CamelCase.
	// More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`

	// Spec DatabaseClusterBackupSpec defines the desired state of DatabaseClusterBackup.
	Spec *struct {
		// BackupStorageName BackupStorageName is the name of the BackupStorage used for backups.
		// The BackupStorage must be created in the same namespace as the DatabaseCluster.
		BackupStorageName string `json:"backupStorageName"`

		// DbClusterName DBClusterName is the original database cluster name.
		DbClusterName string `json:"dbClusterName"`
	} `json:"spec,omitempty"`

	// Status DatabaseClusterBackupStatus defines the observed state of DatabaseClusterBackup.
	Status *struct {
		// Completed Completed is the time when the job was completed.
		Completed *time.Time `json:"completed,omitempty"`

		// Created Created is the timestamp of the upstream backup's creation.
		Created *time.Time `json:"created,omitempty"`

		// Destination Destination is the full path to the backup.
		Destination *string `json:"destination,omitempty"`

		// Gaps Gaps identifies if there are gaps detected in the PITR logs
		Gaps bool `json:"gaps"`

		// InUse InUse is a flag that indicates if this restore resource is being used to restore DB cluster from backup.
		InUse *bool `json:"inUse,omitempty"`

		// LatestRestorableTime LatestRestorableTime is the latest time that can be used for PITR restore
		LatestRestorableTime *time.Time `json:"latestRestorableTime,omitempty"`

		// State State is the DatabaseBackup state.
		State *string `json:"state,omitempty"`
	} `json:"status,omitempty"`
}

// DatabaseClusterBackupList DatabaseClusterBackupList is an object that contains the list of the existing database cluster backups.
type DatabaseClusterBackupList struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string                  `json:"apiVersion,omitempty"`
	Items      *[]DatabaseClusterBackup `json:"items,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`
}

// DatabaseClusterComponentContainer defines model for DatabaseClusterComponentContainer.
type DatabaseClusterComponentContainer struct {
	Name     *string `json:"name,omitempty"`
	Ready    *bool   `json:"ready,omitempty"`
	Restarts *int    `json:"restarts,omitempty"`
	Started  *string `json:"started,omitempty"`
	Status   *string `json:"status,omitempty"`
}

// DatabaseClusterComponents components related data
type DatabaseClusterComponents = []DatabaseClusterComponent

// DatabaseClusterComponent defines model for .
type DatabaseClusterComponent struct {
	Containers *[]DatabaseClusterComponentContainer `json:"containers,omitempty"`
	Name       *string                              `json:"name,omitempty"`
	Ready      *string                              `json:"ready,omitempty"`
	Restarts   *int                                 `json:"restarts,omitempty"`
	Started    *string                              `json:"started,omitempty"`
	Status     *string                              `json:"status,omitempty"`
	Type       *string                              `json:"type,omitempty"`
}

// DatabaseClusterCredential kubernetes object
type DatabaseClusterCredential struct {
	ConnectionUrl *string `json:"connectionUrl,omitempty"`
	Password      *string `json:"password,omitempty"`
	Username      *string `json:"username,omitempty"`
}

// DatabaseClusterList DatabaseClusterList is an object that contains the list of the existing database clusters.
type DatabaseClusterList struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string            `json:"apiVersion,omitempty"`
	Items      *[]DatabaseCluster `json:"items,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`
}

// DatabaseClusterPitr point-in-time recovery related data
type DatabaseClusterPitr struct {
	EarliestDate *time.Time `json:"earliestDate,omitempty"`

	// Gaps indicates if there are pitr logs gaps detected after this backup was taken
	Gaps             *bool      `json:"gaps,omitempty"`
	LatestBackupName *string    `json:"latestBackupName,omitempty"`
	LatestDate       *time.Time `json:"latestDate,omitempty"`
}

// DatabaseClusterRestore DatabaseClusterRestore is the Schema for the databaseclusterrestores API.
type DatabaseClusterRestore struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object.
	// Servers should convert recognized schemas to the latest internal value, and
	// may reject unrecognized values.
	// More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string `json:"apiVersion,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents.
	// Servers may infer this from the endpoint the client submits requests to.
	// Cannot be updated.
	// In CamelCase.
	// More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`

	// Spec DatabaseClusterRestoreSpec defines the desired state of DatabaseClusterRestore.
	Spec *struct {
		// DataSource DataSource defines a data source for restoration.
		DataSource struct {
			// BackupSource BackupSource is the backup source to restore from.
			// Shall be set either this field or DBClusterBackupName.
			BackupSource *struct {
				// BackupStorageName BackupStorageName is the name of the BackupStorage used for storing backups.
				// The BackupStorage must be created in the same namespace as the DatabaseCluster.
				BackupStorageName string `json:"backupStorageName"`

				// Path Path is the path to the backup file/directory.
				Path string `json:"path"`
			} `json:"backupSource,omitempty"`

			// DbClusterBackupName DBClusterBackupName is the name of the DB cluster backup to restore from.
			// Shall be set either this field or BackupSource.
			DbClusterBackupName *string `json:"dbClusterBackupName,omitempty"`

			// Pitr PITR is the point-in-time recovery configuration.
			// May be set in addition to DBClusterBackupName or BackupSource to perform PITR restore.
			Pitr *struct {
				// Date Date is the UTC date to recover to. The accepted format: "2006-01-02T15:04:05Z".
				Date *string `json:"date,omitempty"`

				// Type Type is the type of recovery.
				Type *DatabaseClusterRestoreSpecDataSourcePitrType `json:"type,omitempty"`
			} `json:"pitr,omitempty"`
		} `json:"dataSource"`

		// DbClusterName DBClusterName defines the target database cluster name that needs to be restored from backup.
		DbClusterName string `json:"dbClusterName"`
	} `json:"spec,omitempty"`

	// Status DatabaseClusterRestoreStatus defines the observed state of DatabaseClusterRestore.
	Status *struct {
		Completed *time.Time `json:"completed,omitempty"`

		// InUse InUse is a flag that indicates if this restore resource is being used to restore DB cluster from backup.
		InUse   *bool   `json:"inUse,omitempty"`
		Message *string `json:"message,omitempty"`

		// State RestoreState represents state of restoration.
		State *string `json:"state,omitempty"`
	} `json:"status,omitempty"`
}

// DatabaseClusterRestoreSpecDataSourcePitrType Type is the type of recovery.
type DatabaseClusterRestoreSpecDataSourcePitrType string

// DatabaseClusterRestoreList DatabaseClusterRestoreList is an object that contains the list of the existing database cluster restores.
type DatabaseClusterRestoreList struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string                   `json:"apiVersion,omitempty"`
	Items      *[]DatabaseClusterRestore `json:"items,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`
}

// DatabaseEngine DatabaseEngine is the Schema for the databaseengines API.
type DatabaseEngine struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object.
	// Servers should convert recognized schemas to the latest internal value, and
	// may reject unrecognized values.
	// More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string `json:"apiVersion,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents.
	// Servers may infer this from the endpoint the client submits requests to.
	// Cannot be updated.
	// In CamelCase.
	// More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`

	// Spec DatabaseEngineSpec is a spec for a database engine.
	Spec *struct {
		AllowedVersions *[]string `json:"allowedVersions,omitempty"`

		// SecretKeys SecretKeys contains the definition of the various Secrets that
		// the given DBEngine supports.
		// This information acts like metadata for the Everest UI to guide the users
		// in filling out the correct Secret keys for their clusters.
		SecretKeys *struct {
			// User User secret keys are used to store the details of the users.
			User *[]struct {
				// Description Description is a human-readable description of the Secret key.
				Description *string `json:"description,omitempty"`

				// Name Name is the name of the Secret key.
				Name *string `json:"name,omitempty"`
			} `json:"user,omitempty"`
		} `json:"secretKeys,omitempty"`

		// Type EngineType stands for the supported database engines. Right now it's only pxc
		// and psmdb. However, it can be ps, pg and any other source.
		Type string `json:"type"`
	} `json:"spec,omitempty"`

	// Status DatabaseEngineStatus defines the observed state of DatabaseEngine.
	Status *struct {
		// AvailableVersions Versions struct represents available versions of database engine components.
		AvailableVersions *struct {
			// Backup ComponentsMap is a map of database engine components.
			Backup *map[string]struct {
				Critical  *bool   `json:"critical,omitempty"`
				ImageHash *string `json:"imageHash,omitempty"`
				ImagePath *string `json:"imagePath,omitempty"`

				// Status ComponentStatus represents status of the database engine component.
				Status *string `json:"status,omitempty"`
			} `json:"backup,omitempty"`

			// Engine ComponentsMap is a map of database engine components.
			Engine *map[string]struct {
				Critical  *bool   `json:"critical,omitempty"`
				ImageHash *string `json:"imageHash,omitempty"`
				ImagePath *string `json:"imagePath,omitempty"`

				// Status ComponentStatus represents status of the database engine component.
				Status *string `json:"status,omitempty"`
			} `json:"engine,omitempty"`
			Proxy *map[string]map[string]struct {
				Critical  *bool   `json:"critical,omitempty"`
				ImageHash *string `json:"imageHash,omitempty"`
				ImagePath *string `json:"imagePath,omitempty"`

				// Status ComponentStatus represents status of the database engine component.
				Status *string `json:"status,omitempty"`
			} `json:"proxy,omitempty"`
			Tools *map[string]map[string]struct {
				Critical  *bool   `json:"critical,omitempty"`
				ImageHash *string `json:"imageHash,omitempty"`
				ImagePath *string `json:"imagePath,omitempty"`

				// Status ComponentStatus represents status of the database engine component.
				Status *string `json:"status,omitempty"`
			} `json:"tools,omitempty"`
		} `json:"availableVersions,omitempty"`

		// OperatorUpgrade OperatorUpgrade contains the status of the operator upgrade.
		OperatorUpgrade *struct {
			// InstallPlanRef InstallPlanRef is a reference to the InstallPlan object created for the operator upgrade.
			//
			// We do not recommended approving this InstallPlan directly from the Kubernetes API.
			// This is because this InstallPlan may also upgrade other operators in the namespace and that
			// can have unintended consequences.
			// This behaviour is not a bug from Everest, but an unfortunate limitation of OLM.
			// We suggest using the Everest API/UI to handle operator upgrades, which will perform a series
			// of checks and safely upgrade all operators in the namespace.
			InstallPlanRef *struct {
				// Name Name of the referent.
				// This field is effectively required, but due to backwards compatibility is
				// allowed to be empty. Instances of this type with an empty value here are
				// almost certainly wrong.
				// More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
				Name *string `json:"name,omitempty"`
			} `json:"installPlanRef,omitempty"`
			Message *string `json:"message,omitempty"`

			// Phase UpgradePhase represents the phase of the operator upgrade.
			Phase     *string    `json:"phase,omitempty"`
			StartedAt *time.Time `json:"startedAt,omitempty"`

			// TargetVersion TargetVersion is the version to which the operator should be upgraded.
			TargetVersion *string `json:"targetVersion,omitempty"`
		} `json:"operatorUpgrade,omitempty"`
		OperatorVersion         *string `json:"operatorVersion,omitempty"`
		PendingOperatorUpgrades *[]struct {
			// InstallPlanRef InstallPlanRef is a reference to the InstallPlan object created for the operator upgrade.
			//
			// We do not recommended approving this InstallPlan directly from the Kubernetes API.
			// This is because this InstallPlan may also upgrade other operators in the namespace and that
			// can have unintended consequences.
			// This behaviour is not a bug from Everest, but an unfortunate limitation of OLM.
			// We suggest using the Everest API/UI to handle operator upgrades, which will perform a series
			// of checks and safely upgrade all operators in the namespace.
			InstallPlanRef *struct {
				// Name Name of the referent.
				// This field is effectively required, but due to backwards compatibility is
				// allowed to be empty. Instances of this type with an empty value here are
				// almost certainly wrong.
				// More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
				Name *string `json:"name,omitempty"`
			} `json:"installPlanRef,omitempty"`

			// TargetVersion TargetVersion is the version to which the operator should be upgraded.
			TargetVersion *string `json:"targetVersion,omitempty"`
		} `json:"pendingOperatorUpgrades,omitempty"`

		// Status EngineState represents state of engine in a k8s cluster.
		Status *string `json:"status,omitempty"`
	} `json:"status,omitempty"`
}

// DatabaseEngineList DatabaseEngineList is an object that contains the list of the existing database engines.
type DatabaseEngineList struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string           `json:"apiVersion,omitempty"`
	Items      *[]DatabaseEngine `json:"items,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`
}

// Error Error response
type Error struct {
	Message *string `json:"message,omitempty"`
}

// KubernetesClusterInfo kubernetes cluster info
type KubernetesClusterInfo struct {
	ClusterType string `json:"clusterType"`

	// StorageClassNames List of storage class names that are available in the cluster.
	// Deprecated: this property has been marked as deprecated upstream, but no `x-deprecated-reason` was set
	StorageClassNames []string        `json:"storageClassNames"`
	StorageClasses    *[]StorageClass `json:"storageClasses,omitempty"`
}

// KubernetesClusterResources kubernetes cluster resources
type KubernetesClusterResources struct {
	Available ResourcesAvailable `json:"available"`
	Capacity  ResourcesCapacity  `json:"capacity"`
}

// ResourcesAvailable defines model for .
type ResourcesAvailable struct {
	CpuMillis   *uint64 `json:"cpuMillis,omitempty"`
	DiskSize    *uint64 `json:"diskSize,omitempty"`
	MemoryBytes *uint64 `json:"memoryBytes,omitempty"`
}

// ResourcesCapacity defines model for .
type ResourcesCapacity struct {
	CpuMillis   *uint64 `json:"cpuMillis,omitempty"`
	DiskSize    *uint64 `json:"diskSize,omitempty"`
	MemoryBytes *uint64 `json:"memoryBytes,omitempty"`
}

// LoadBalancerConfig LoadBalancerConfig is the Schema for the Load Balancer Config API.
type LoadBalancerConfig struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object.
	// Servers should convert recognized schemas to the latest internal value, and
	// may reject unrecognized values.
	// More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string `json:"apiVersion,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents.
	// Servers may infer this from the endpoint the client submits requests to.
	// Cannot be updated.
	// In CamelCase.
	// More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`

	// Spec LoadBalancerConfigSpec defines the desired state of LoadBalancerConfig.
	Spec *struct {
		// Annotations Annotations key-value pairs to apply as annotations to the load balancer
		Annotations *map[string]string `json:"annotations,omitempty"`
	} `json:"spec,omitempty"`

	// Status LoadBalancerConfigStatus defines the observed state of LoadBalancerConfig.
	Status *struct {
		// InUse InUse is a flag that indicates if the config is used by any DB cluster.
		InUse *bool `json:"inUse,omitempty"`

		// LastObservedGeneration LastObservedGeneration is the most recent generation observed for this LoadBalancerConfig.
		LastObservedGeneration *int64 `json:"lastObservedGeneration,omitempty"`
	} `json:"status,omitempty"`
}

// LoadBalancerConfigList LoadBalancerConfigList is an object that contains the list of the existing load balancer configs.
type LoadBalancerConfigList struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string               `json:"apiVersion,omitempty"`
	Items      *[]LoadBalancerConfig `json:"items,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`
}

// MonitoringInstance Monitoring instance information
type MonitoringInstance = MonitoringInstanceBaseWithName

// MonitoringInstanceBase Monitoring instance information
type MonitoringInstanceBase struct {
	// AllowedNamespaces List of namespaces allowed to use this monitoring instance
	// Deprecated: this property has been marked as deprecated upstream, but no `x-deprecated-reason` was set
	AllowedNamespaces *[]string                  `json:"allowedNamespaces,omitempty"`
	Type              MonitoringInstanceBaseType `json:"type,omitempty"`
	Url               string                     `json:"url,omitempty"`

	// VerifyTLS VerifyTLS is set to ensure TLS/SSL verification.
	VerifyTLS *bool `json:"verifyTLS,omitempty"`
}

// MonitoringInstanceBaseType defines model for MonitoringInstanceBase.Type.
type MonitoringInstanceBaseType string

// MonitoringInstanceBaseWithName defines model for MonitoringInstanceBaseWithName.
type MonitoringInstanceBaseWithName struct {
	// AllowedNamespaces List of namespaces allowed to use this monitoring instance
	// Deprecated: this property has been marked as deprecated upstream, but no `x-deprecated-reason` was set
	AllowedNamespaces *[]string `json:"allowedNamespaces,omitempty"`

	// Name A user defined string name of the storage in the DNS name format https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#dns-label-names
	Name      string                             `json:"name,omitempty"`
	Namespace string                             `json:"namespace,omitempty"`
	Type      MonitoringInstanceBaseWithNameType `json:"type,omitempty"`
	Url       string                             `json:"url,omitempty"`

	// VerifyTLS VerifyTLS is set to ensure TLS/SSL verification.
	VerifyTLS *bool `json:"verifyTLS,omitempty"`
}

// MonitoringInstanceBaseWithNameType defines model for MonitoringInstanceBaseWithName.Type.
type MonitoringInstanceBaseWithNameType string

// MonitoringInstanceCreateParams defines model for MonitoringInstanceCreateParams.
type MonitoringInstanceCreateParams struct {
	// AllowedNamespaces List of namespaces allowed to use this monitoring instance
	// Deprecated: this property has been marked as deprecated upstream, but no `x-deprecated-reason` was set
	AllowedNamespaces *[]string `json:"allowedNamespaces,omitempty"`

	// Name A user defined string name of the storage in the DNS name format https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#dns-label-names
	Name      string                             `json:"name,omitempty"`
	Namespace string                             `json:"namespace,omitempty"`
	Pmm       *PMMMonitoringInstanceSpec         `json:"pmm,omitempty"`
	Type      MonitoringInstanceCreateParamsType `json:"type,omitempty"`
	Url       string                             `json:"url,omitempty"`

	// VerifyTLS VerifyTLS is set to ensure TLS/SSL verification.
	VerifyTLS *bool `json:"verifyTLS,omitempty"`
}

// PMMMonitoringInstanceSpec defines model for .
type PMMMonitoringInstanceSpec struct {
	ApiKey   string `json:"apiKey,omitempty"`
	Password string `json:"password,omitempty"`
	User     string `json:"user,omitempty"`
}

// MonitoringInstanceCreateParamsType defines model for MonitoringInstanceCreateParams.Type.
type MonitoringInstanceCreateParamsType string

// MonitoringInstancePMM defines model for MonitoringInstancePMM.
type MonitoringInstancePMM struct {
	Pmm *PMMMonitoringInstanceSpec `json:"pmm,omitempty"`
}

// MonitoringInstanceUpdateParams defines model for MonitoringInstanceUpdateParams.
type MonitoringInstanceUpdateParams struct {
	// AllowedNamespaces List of namespaces allowed to use this monitoring instance
	// Deprecated: this property has been marked as deprecated upstream, but no `x-deprecated-reason` was set
	AllowedNamespaces *[]string                          `json:"allowedNamespaces,omitempty"`
	Pmm               *PMMMonitoringInstanceSpec         `json:"pmm,omitempty"`
	Type              MonitoringInstanceUpdateParamsType `json:"type,omitempty"`
	Url               string                             `json:"url,omitempty"`

	// VerifyTLS VerifyTLS is set to ensure TLS/SSL verification.
	VerifyTLS *bool `json:"verifyTLS,omitempty"`
}

// MonitoringInstanceUpdateParamsType defines model for MonitoringInstanceUpdateParams.Type.
type MonitoringInstanceUpdateParamsType string

// MonitoringInstancesList defines model for MonitoringInstancesList.
type MonitoringInstancesList = []MonitoringInstance

// NamespaceList defines model for NamespaceList.
type NamespaceList = []string

// OIDCConfig Everest OIDC provider configuration
type OIDCConfig struct {
	// ClientId OIDC application clientID
	ClientId string `json:"clientId"`

	// IssuerURL OIDC provider url
	IssuerURL string `json:"issuerURL"`

	// Scopes OIDC scopes
	Scopes []string `json:"scopes"`
}

// PodSchedulingPolicy PodSchedulingPolicy is the Schema for the Pod Scheduling Policy API.
type PodSchedulingPolicy struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object.
	// Servers should convert recognized schemas to the latest internal value, and
	// may reject unrecognized values.
	// More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string `json:"apiVersion,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents.
	// Servers may infer this from the endpoint the client submits requests to.
	// Cannot be updated.
	// In CamelCase.
	// More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`

	// Spec PodSchedulingPolicySpec defines the desired state of PodSchedulingPolicy.
	Spec *struct {
		// AffinityConfig AffinityConfig is a configuration for the affinity settings depending on the engine type.
		AffinityConfig *struct {
			// Postgresql PostgreSQL is the affinity configuration for the PostgreSQL DB clusters.
			Postgresql *struct {
				// Engine Engine is the affinity configuration for the DB Engine pods.
				Engine *struct {
					// NodeAffinity Describes node affinity scheduling rules for the pod.
					NodeAffinity *struct {
						// PreferredDuringSchedulingIgnoredDuringExecution The scheduler will prefer to schedule pods to nodes that satisfy
						// the affinity expressions specified by this field, but it may choose
						// a node that violates one or more of the expressions. The node that is
						// most preferred is the one with the greatest sum of weights, i.e.
						// for each node that meets all of the scheduling requirements (resource
						// request, requiredDuringScheduling affinity expressions, etc.),
						// compute a sum by iterating through the elements of this field and adding
						// "weight" to the sum if the node matches the corresponding matchExpressions; the
						// node(s) with the highest sum are the most preferred.
						PreferredDuringSchedulingIgnoredDuringExecution *[]struct {
							// Preference A node selector term, associated with the corresponding weight.
							Preference struct {
								// MatchExpressions A list of node selector requirements by node's labels.
								MatchExpressions *[]struct {
									// Key The label key that the selector applies to.
									Key string `json:"key"`

									// Operator Represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
									Operator string `json:"operator"`

									// Values An array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. If the operator is Gt or Lt, the values
									// array must have a single element, which will be interpreted as an integer.
									// This array is replaced during a strategic merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchFields A list of node selector requirements by node's fields.
								MatchFields *[]struct {
									// Key The label key that the selector applies to.
									Key string `json:"key"`

									// Operator Represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
									Operator string `json:"operator"`

									// Values An array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. If the operator is Gt or Lt, the values
									// array must have a single element, which will be interpreted as an integer.
									// This array is replaced during a strategic merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchFields,omitempty"`
							} `json:"preference"`

							// Weight Weight associated with matching the corresponding nodeSelectorTerm, in the range 1-100.
							Weight int32 `json:"weight"`
						} `json:"preferredDuringSchedulingIgnoredDuringExecution,omitempty"`

						// RequiredDuringSchedulingIgnoredDuringExecution If the affinity requirements specified by this field are not met at
						// scheduling time, the pod will not be scheduled onto the node.
						// If the affinity requirements specified by this field cease to be met
						// at some point during pod execution (e.g. due to an update), the system
						// may or may not try to eventually evict the pod from its node.
						RequiredDuringSchedulingIgnoredDuringExecution *struct {
							// NodeSelectorTerms Required. A list of node selector terms. The terms are ORed.
							NodeSelectorTerms []struct {
								// MatchExpressions A list of node selector requirements by node's labels.
								MatchExpressions *[]struct {
									// Key The label key that the selector applies to.
									Key string `json:"key"`

									// Operator Represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
									Operator string `json:"operator"`

									// Values An array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. If the operator is Gt or Lt, the values
									// array must have a single element, which will be interpreted as an integer.
									// This array is replaced during a strategic merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchFields A list of node selector requirements by node's fields.
								MatchFields *[]struct {
									// Key The label key that the selector applies to.
									Key string `json:"key"`

									// Operator Represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
									Operator string `json:"operator"`

									// Values An array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. If the operator is Gt or Lt, the values
									// array must have a single element, which will be interpreted as an integer.
									// This array is replaced during a strategic merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchFields,omitempty"`
							} `json:"nodeSelectorTerms"`
						} `json:"requiredDuringSchedulingIgnoredDuringExecution,omitempty"`
					} `json:"nodeAffinity,omitempty"`

					// PodAffinity Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
					PodAffinity *struct {
						// PreferredDuringSchedulingIgnoredDuringExecution The scheduler will prefer to schedule pods to nodes that satisfy
						// the affinity expressions specified by this field, but it may choose
						// a node that violates one or more of the expressions. The node that is
						// most preferred is the one with the greatest sum of weights, i.e.
						// for each node that meets all of the scheduling requirements (resource
						// request, requiredDuringScheduling affinity expressions, etc.),
						// compute a sum by iterating through the elements of this field and adding
						// "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the
						// node(s) with the highest sum are the most preferred.
						PreferredDuringSchedulingIgnoredDuringExecution *[]struct {
							// PodAffinityTerm Required. A pod affinity term, associated with the corresponding weight.
							PodAffinityTerm struct {
								// LabelSelector A label query over a set of resources, in this case pods.
								// If it's null, this PodAffinityTerm matches with no Pods.
								LabelSelector *struct {
									// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
									MatchExpressions *[]struct {
										// Key key is the label key that the selector applies to.
										Key string `json:"key"`

										// Operator operator represents a key's relationship to a set of values.
										// Valid operators are In, NotIn, Exists and DoesNotExist.
										Operator string `json:"operator"`

										// Values values is an array of string values. If the operator is In or NotIn,
										// the values array must be non-empty. If the operator is Exists or DoesNotExist,
										// the values array must be empty. This array is replaced during a strategic
										// merge patch.
										Values *[]string `json:"values,omitempty"`
									} `json:"matchExpressions,omitempty"`

									// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
									// map is equivalent to an element of matchExpressions, whose key field is "key", the
									// operator is "In", and the values array contains only "value". The requirements are ANDed.
									MatchLabels *map[string]string `json:"matchLabels,omitempty"`
								} `json:"labelSelector,omitempty"`

								// MatchLabelKeys MatchLabelKeys is a set of pod label keys to select which pods will
								// be taken into consideration. The keys are used to lookup values from the
								// incoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`
								// to select the group of existing pods which pods will be taken into consideration
								// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
								// pod labels will be ignored. The default value is empty.
								// The same key is forbidden to exist in both matchLabelKeys and labelSelector.
								// Also, matchLabelKeys cannot be set when labelSelector isn't set.
								MatchLabelKeys *[]string `json:"matchLabelKeys,omitempty"`

								// MismatchLabelKeys MismatchLabelKeys is a set of pod label keys to select which pods will
								// be taken into consideration. The keys are used to lookup values from the
								// incoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`
								// to select the group of existing pods which pods will be taken into consideration
								// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
								// pod labels will be ignored. The default value is empty.
								// The same key is forbidden to exist in both mismatchLabelKeys and labelSelector.
								// Also, mismatchLabelKeys cannot be set when labelSelector isn't set.
								MismatchLabelKeys *[]string `json:"mismatchLabelKeys,omitempty"`

								// NamespaceSelector A label query over the set of namespaces that the term applies to.
								// The term is applied to the union of the namespaces selected by this field
								// and the ones listed in the namespaces field.
								// null selector and null or empty namespaces list means "this pod's namespace".
								// An empty selector ({}) matches all namespaces.
								NamespaceSelector *struct {
									// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
									MatchExpressions *[]struct {
										// Key key is the label key that the selector applies to.
										Key string `json:"key"`

										// Operator operator represents a key's relationship to a set of values.
										// Valid operators are In, NotIn, Exists and DoesNotExist.
										Operator string `json:"operator"`

										// Values values is an array of string values. If the operator is In or NotIn,
										// the values array must be non-empty. If the operator is Exists or DoesNotExist,
										// the values array must be empty. This array is replaced during a strategic
										// merge patch.
										Values *[]string `json:"values,omitempty"`
									} `json:"matchExpressions,omitempty"`

									// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
									// map is equivalent to an element of matchExpressions, whose key field is "key", the
									// operator is "In", and the values array contains only "value". The requirements are ANDed.
									MatchLabels *map[string]string `json:"matchLabels,omitempty"`
								} `json:"namespaceSelector,omitempty"`

								// Namespaces namespaces specifies a static list of namespace names that the term applies to.
								// The term is applied to the union of the namespaces listed in this field
								// and the ones selected by namespaceSelector.
								// null or empty namespaces list and null namespaceSelector means "this pod's namespace".
								Namespaces *[]string `json:"namespaces,omitempty"`

								// TopologyKey This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
								// the labelSelector in the specified namespaces, where co-located is defined as running on a node
								// whose value of the label with key topologyKey matches that of any node on which any of the
								// selected pods is running.
								// Empty topologyKey is not allowed.
								TopologyKey string `json:"topologyKey"`
							} `json:"podAffinityTerm"`

							// Weight weight associated with matching the corresponding podAffinityTerm,
							// in the range 1-100.
							Weight int32 `json:"weight"`
						} `json:"preferredDuringSchedulingIgnoredDuringExecution,omitempty"`

						// RequiredDuringSchedulingIgnoredDuringExecution If the affinity requirements specified by this field are not met at
						// scheduling time, the pod will not be scheduled onto the node.
						// If the affinity requirements specified by this field cease to be met
						// at some point during pod execution (e.g. due to a pod label update), the
						// system may or may not try to eventually evict the pod from its node.
						// When there are multiple elements, the lists of nodes corresponding to each
						// podAffinityTerm are intersected, i.e. all terms must be satisfied.
						RequiredDuringSchedulingIgnoredDuringExecution *[]struct {
							// LabelSelector A label query over a set of resources, in this case pods.
							// If it's null, this PodAffinityTerm matches with no Pods.
							LabelSelector *struct {
								// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
								MatchExpressions *[]struct {
									// Key key is the label key that the selector applies to.
									Key string `json:"key"`

									// Operator operator represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists and DoesNotExist.
									Operator string `json:"operator"`

									// Values values is an array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. This array is replaced during a strategic
									// merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
								// map is equivalent to an element of matchExpressions, whose key field is "key", the
								// operator is "In", and the values array contains only "value". The requirements are ANDed.
								MatchLabels *map[string]string `json:"matchLabels,omitempty"`
							} `json:"labelSelector,omitempty"`

							// MatchLabelKeys MatchLabelKeys is a set of pod label keys to select which pods will
							// be taken into consideration. The keys are used to lookup values from the
							// incoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`
							// to select the group of existing pods which pods will be taken into consideration
							// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
							// pod labels will be ignored. The default value is empty.
							// The same key is forbidden to exist in both matchLabelKeys and labelSelector.
							// Also, matchLabelKeys cannot be set when labelSelector isn't set.
							MatchLabelKeys *[]string `json:"matchLabelKeys,omitempty"`

							// MismatchLabelKeys MismatchLabelKeys is a set of pod label keys to select which pods will
							// be taken into consideration. The keys are used to lookup values from the
							// incoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`
							// to select the group of existing pods which pods will be taken into consideration
							// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
							// pod labels will be ignored. The default value is empty.
							// The same key is forbidden to exist in both mismatchLabelKeys and labelSelector.
							// Also, mismatchLabelKeys cannot be set when labelSelector isn't set.
							MismatchLabelKeys *[]string `json:"mismatchLabelKeys,omitempty"`

							// NamespaceSelector A label query over the set of namespaces that the term applies to.
							// The term is applied to the union of the namespaces selected by this field
							// and the ones listed in the namespaces field.
							// null selector and null or empty namespaces list means "this pod's namespace".
							// An empty selector ({}) matches all namespaces.
							NamespaceSelector *struct {
								// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
								MatchExpressions *[]struct {
									// Key key is the label key that the selector applies to.
									Key string `json:"key"`

									// Operator operator represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists and DoesNotExist.
									Operator string `json:"operator"`

									// Values values is an array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. This array is replaced during a strategic
									// merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
								// map is equivalent to an element of matchExpressions, whose key field is "key", the
								// operator is "In", and the values array contains only "value". The requirements are ANDed.
								MatchLabels *map[string]string `json:"matchLabels,omitempty"`
							} `json:"namespaceSelector,omitempty"`

							// Namespaces namespaces specifies a static list of namespace names that the term applies to.
							// The term is applied to the union of the namespaces listed in this field
							// and the ones selected by namespaceSelector.
							// null or empty namespaces list and null namespaceSelector means "this pod's namespace".
							Namespaces *[]string `json:"namespaces,omitempty"`

							// TopologyKey This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
							// the labelSelector in the specified namespaces, where co-located is defined as running on a node
							// whose value of the label with key topologyKey matches that of any node on which any of the
							// selected pods is running.
							// Empty topologyKey is not allowed.
							TopologyKey string `json:"topologyKey"`
						} `json:"requiredDuringSchedulingIgnoredDuringExecution,omitempty"`
					} `json:"podAffinity,omitempty"`

					// PodAntiAffinity Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
					PodAntiAffinity *struct {
						// PreferredDuringSchedulingIgnoredDuringExecution The scheduler will prefer to schedule pods to nodes that satisfy
						// the anti-affinity expressions specified by this field, but it may choose
						// a node that violates one or more of the expressions. The node that is
						// most preferred is the one with the greatest sum of weights, i.e.
						// for each node that meets all of the scheduling requirements (resource
						// request, requiredDuringScheduling anti-affinity expressions, etc.),
						// compute a sum by iterating through the elements of this field and adding
						// "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the
						// node(s) with the highest sum are the most preferred.
						PreferredDuringSchedulingIgnoredDuringExecution *[]struct {
							// PodAffinityTerm Required. A pod affinity term, associated with the corresponding weight.
							PodAffinityTerm struct {
								// LabelSelector A label query over a set of resources, in this case pods.
								// If it's null, this PodAffinityTerm matches with no Pods.
								LabelSelector *struct {
									// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
									MatchExpressions *[]struct {
										// Key key is the label key that the selector applies to.
										Key string `json:"key"`

										// Operator operator represents a key's relationship to a set of values.
										// Valid operators are In, NotIn, Exists and DoesNotExist.
										Operator string `json:"operator"`

										// Values values is an array of string values. If the operator is In or NotIn,
										// the values array must be non-empty. If the operator is Exists or DoesNotExist,
										// the values array must be empty. This array is replaced during a strategic
										// merge patch.
										Values *[]string `json:"values,omitempty"`
									} `json:"matchExpressions,omitempty"`

									// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
									// map is equivalent to an element of matchExpressions, whose key field is "key", the
									// operator is "In", and the values array contains only "value". The requirements are ANDed.
									MatchLabels *map[string]string `json:"matchLabels,omitempty"`
								} `json:"labelSelector,omitempty"`

								// MatchLabelKeys MatchLabelKeys is a set of pod label keys to select which pods will
								// be taken into consideration. The keys are used to lookup values from the
								// incoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`
								// to select the group of existing pods which pods will be taken into consideration
								// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
								// pod labels will be ignored. The default value is empty.
								// The same key is forbidden to exist in both matchLabelKeys and labelSelector.
								// Also, matchLabelKeys cannot be set when labelSelector isn't set.
								MatchLabelKeys *[]string `json:"matchLabelKeys,omitempty"`

								// MismatchLabelKeys MismatchLabelKeys is a set of pod label keys to select which pods will
								// be taken into consideration. The keys are used to lookup values from the
								// incoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`
								// to select the group of existing pods which pods will be taken into consideration
								// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
								// pod labels will be ignored. The default value is empty.
								// The same key is forbidden to exist in both mismatchLabelKeys and labelSelector.
								// Also, mismatchLabelKeys cannot be set when labelSelector isn't set.
								MismatchLabelKeys *[]string `json:"mismatchLabelKeys,omitempty"`

								// NamespaceSelector A label query over the set of namespaces that the term applies to.
								// The term is applied to the union of the namespaces selected by this field
								// and the ones listed in the namespaces field.
								// null selector and null or empty namespaces list means "this pod's namespace".
								// An empty selector ({}) matches all namespaces.
								NamespaceSelector *struct {
									// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
									MatchExpressions *[]struct {
										// Key key is the label key that the selector applies to.
										Key string `json:"key"`

										// Operator operator represents a key's relationship to a set of values.
										// Valid operators are In, NotIn, Exists and DoesNotExist.
										Operator string `json:"operator"`

										// Values values is an array of string values. If the operator is In or NotIn,
										// the values array must be non-empty. If the operator is Exists or DoesNotExist,
										// the values array must be empty. This array is replaced during a strategic
										// merge patch.
										Values *[]string `json:"values,omitempty"`
									} `json:"matchExpressions,omitempty"`

									// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
									// map is equivalent to an element of matchExpressions, whose key field is "key", the
									// operator is "In", and the values array contains only "value". The requirements are ANDed.
									MatchLabels *map[string]string `json:"matchLabels,omitempty"`
								} `json:"namespaceSelector,omitempty"`

								// Namespaces namespaces specifies a static list of namespace names that the term applies to.
								// The term is applied to the union of the namespaces listed in this field
								// and the ones selected by namespaceSelector.
								// null or empty namespaces list and null namespaceSelector means "this pod's namespace".
								Namespaces *[]string `json:"namespaces,omitempty"`

								// TopologyKey This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
								// the labelSelector in the specified namespaces, where co-located is defined as running on a node
								// whose value of the label with key topologyKey matches that of any node on which any of the
								// selected pods is running.
								// Empty topologyKey is not allowed.
								TopologyKey string `json:"topologyKey"`
							} `json:"podAffinityTerm"`

							// Weight weight associated with matching the corresponding podAffinityTerm,
							// in the range 1-100.
							Weight int32 `json:"weight"`
						} `json:"preferredDuringSchedulingIgnoredDuringExecution,omitempty"`

						// RequiredDuringSchedulingIgnoredDuringExecution If the anti-affinity requirements specified by this field are not met at
						// scheduling time, the pod will not be scheduled onto the node.
						// If the anti-affinity requirements specified by this field cease to be met
						// at some point during pod execution (e.g. due to a pod label update), the
						// system may or may not try to eventually evict the pod from its node.
						// When there are multiple elements, the lists of nodes corresponding to each
						// podAffinityTerm are intersected, i.e. all terms must be satisfied.
						RequiredDuringSchedulingIgnoredDuringExecution *[]struct {
							// LabelSelector A label query over a set of resources, in this case pods.
							// If it's null, this PodAffinityTerm matches with no Pods.
							LabelSelector *struct {
								// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
								MatchExpressions *[]struct {
									// Key key is the label key that the selector applies to.
									Key string `json:"key"`

									// Operator operator represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists and DoesNotExist.
									Operator string `json:"operator"`

									// Values values is an array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. This array is replaced during a strategic
									// merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
								// map is equivalent to an element of matchExpressions, whose key field is "key", the
								// operator is "In", and the values array contains only "value". The requirements are ANDed.
								MatchLabels *map[string]string `json:"matchLabels,omitempty"`
							} `json:"labelSelector,omitempty"`

							// MatchLabelKeys MatchLabelKeys is a set of pod label keys to select which pods will
							// be taken into consideration. The keys are used to lookup values from the
							// incoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`
							// to select the group of existing pods which pods will be taken into consideration
							// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
							// pod labels will be ignored. The default value is empty.
							// The same key is forbidden to exist in both matchLabelKeys and labelSelector.
							// Also, matchLabelKeys cannot be set when labelSelector isn't set.
							MatchLabelKeys *[]string `json:"matchLabelKeys,omitempty"`

							// MismatchLabelKeys MismatchLabelKeys is a set of pod label keys to select which pods will
							// be taken into consideration. The keys are used to lookup values from the
							// incoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`
							// to select the group of existing pods which pods will be taken into consideration
							// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
							// pod labels will be ignored. The default value is empty.
							// The same key is forbidden to exist in both mismatchLabelKeys and labelSelector.
							// Also, mismatchLabelKeys cannot be set when labelSelector isn't set.
							MismatchLabelKeys *[]string `json:"mismatchLabelKeys,omitempty"`

							// NamespaceSelector A label query over the set of namespaces that the term applies to.
							// The term is applied to the union of the namespaces selected by this field
							// and the ones listed in the namespaces field.
							// null selector and null or empty namespaces list means "this pod's namespace".
							// An empty selector ({}) matches all namespaces.
							NamespaceSelector *struct {
								// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
								MatchExpressions *[]struct {
									// Key key is the label key that the selector applies to.
									Key string `json:"key"`

									// Operator operator represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists and DoesNotExist.
									Operator string `json:"operator"`

									// Values values is an array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. This array is replaced during a strategic
									// merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
								// map is equivalent to an element of matchExpressions, whose key field is "key", the
								// operator is "In", and the values array contains only "value". The requirements are ANDed.
								MatchLabels *map[string]string `json:"matchLabels,omitempty"`
							} `json:"namespaceSelector,omitempty"`

							// Namespaces namespaces specifies a static list of namespace names that the term applies to.
							// The term is applied to the union of the namespaces listed in this field
							// and the ones selected by namespaceSelector.
							// null or empty namespaces list and null namespaceSelector means "this pod's namespace".
							Namespaces *[]string `json:"namespaces,omitempty"`

							// TopologyKey This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
							// the labelSelector in the specified namespaces, where co-located is defined as running on a node
							// whose value of the label with key topologyKey matches that of any node on which any of the
							// selected pods is running.
							// Empty topologyKey is not allowed.
							TopologyKey string `json:"topologyKey"`
						} `json:"requiredDuringSchedulingIgnoredDuringExecution,omitempty"`
					} `json:"podAntiAffinity,omitempty"`
				} `json:"engine,omitempty"`

				// Proxy Proxy is the affinity configuration for the DB Proxy pods.
				Proxy *struct {
					// NodeAffinity Describes node affinity scheduling rules for the pod.
					NodeAffinity *struct {
						// PreferredDuringSchedulingIgnoredDuringExecution The scheduler will prefer to schedule pods to nodes that satisfy
						// the affinity expressions specified by this field, but it may choose
						// a node that violates one or more of the expressions. The node that is
						// most preferred is the one with the greatest sum of weights, i.e.
						// for each node that meets all of the scheduling requirements (resource
						// request, requiredDuringScheduling affinity expressions, etc.),
						// compute a sum by iterating through the elements of this field and adding
						// "weight" to the sum if the node matches the corresponding matchExpressions; the
						// node(s) with the highest sum are the most preferred.
						PreferredDuringSchedulingIgnoredDuringExecution *[]struct {
							// Preference A node selector term, associated with the corresponding weight.
							Preference struct {
								// MatchExpressions A list of node selector requirements by node's labels.
								MatchExpressions *[]struct {
									// Key The label key that the selector applies to.
									Key string `json:"key"`

									// Operator Represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
									Operator string `json:"operator"`

									// Values An array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. If the operator is Gt or Lt, the values
									// array must have a single element, which will be interpreted as an integer.
									// This array is replaced during a strategic merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchFields A list of node selector requirements by node's fields.
								MatchFields *[]struct {
									// Key The label key that the selector applies to.
									Key string `json:"key"`

									// Operator Represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
									Operator string `json:"operator"`

									// Values An array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. If the operator is Gt or Lt, the values
									// array must have a single element, which will be interpreted as an integer.
									// This array is replaced during a strategic merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchFields,omitempty"`
							} `json:"preference"`

							// Weight Weight associated with matching the corresponding nodeSelectorTerm, in the range 1-100.
							Weight int32 `json:"weight"`
						} `json:"preferredDuringSchedulingIgnoredDuringExecution,omitempty"`

						// RequiredDuringSchedulingIgnoredDuringExecution If the affinity requirements specified by this field are not met at
						// scheduling time, the pod will not be scheduled onto the node.
						// If the affinity requirements specified by this field cease to be met
						// at some point during pod execution (e.g. due to an update), the system
						// may or may not try to eventually evict the pod from its node.
						RequiredDuringSchedulingIgnoredDuringExecution *struct {
							// NodeSelectorTerms Required. A list of node selector terms. The terms are ORed.
							NodeSelectorTerms []struct {
								// MatchExpressions A list of node selector requirements by node's labels.
								MatchExpressions *[]struct {
									// Key The label key that the selector applies to.
									Key string `json:"key"`

									// Operator Represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
									Operator string `json:"operator"`

									// Values An array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. If the operator is Gt or Lt, the values
									// array must have a single element, which will be interpreted as an integer.
									// This array is replaced during a strategic merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchFields A list of node selector requirements by node's fields.
								MatchFields *[]struct {
									// Key The label key that the selector applies to.
									Key string `json:"key"`

									// Operator Represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
									Operator string `json:"operator"`

									// Values An array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. If the operator is Gt or Lt, the values
									// array must have a single element, which will be interpreted as an integer.
									// This array is replaced during a strategic merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchFields,omitempty"`
							} `json:"nodeSelectorTerms"`
						} `json:"requiredDuringSchedulingIgnoredDuringExecution,omitempty"`
					} `json:"nodeAffinity,omitempty"`

					// PodAffinity Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
					PodAffinity *struct {
						// PreferredDuringSchedulingIgnoredDuringExecution The scheduler will prefer to schedule pods to nodes that satisfy
						// the affinity expressions specified by this field, but it may choose
						// a node that violates one or more of the expressions. The node that is
						// most preferred is the one with the greatest sum of weights, i.e.
						// for each node that meets all of the scheduling requirements (resource
						// request, requiredDuringScheduling affinity expressions, etc.),
						// compute a sum by iterating through the elements of this field and adding
						// "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the
						// node(s) with the highest sum are the most preferred.
						PreferredDuringSchedulingIgnoredDuringExecution *[]struct {
							// PodAffinityTerm Required. A pod affinity term, associated with the corresponding weight.
							PodAffinityTerm struct {
								// LabelSelector A label query over a set of resources, in this case pods.
								// If it's null, this PodAffinityTerm matches with no Pods.
								LabelSelector *struct {
									// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
									MatchExpressions *[]struct {
										// Key key is the label key that the selector applies to.
										Key string `json:"key"`

										// Operator operator represents a key's relationship to a set of values.
										// Valid operators are In, NotIn, Exists and DoesNotExist.
										Operator string `json:"operator"`

										// Values values is an array of string values. If the operator is In or NotIn,
										// the values array must be non-empty. If the operator is Exists or DoesNotExist,
										// the values array must be empty. This array is replaced during a strategic
										// merge patch.
										Values *[]string `json:"values,omitempty"`
									} `json:"matchExpressions,omitempty"`

									// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
									// map is equivalent to an element of matchExpressions, whose key field is "key", the
									// operator is "In", and the values array contains only "value". The requirements are ANDed.
									MatchLabels *map[string]string `json:"matchLabels,omitempty"`
								} `json:"labelSelector,omitempty"`

								// MatchLabelKeys MatchLabelKeys is a set of pod label keys to select which pods will
								// be taken into consideration. The keys are used to lookup values from the
								// incoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`
								// to select the group of existing pods which pods will be taken into consideration
								// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
								// pod labels will be ignored. The default value is empty.
								// The same key is forbidden to exist in both matchLabelKeys and labelSelector.
								// Also, matchLabelKeys cannot be set when labelSelector isn't set.
								MatchLabelKeys *[]string `json:"matchLabelKeys,omitempty"`

								// MismatchLabelKeys MismatchLabelKeys is a set of pod label keys to select which pods will
								// be taken into consideration. The keys are used to lookup values from the
								// incoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`
								// to select the group of existing pods which pods will be taken into consideration
								// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
								// pod labels will be ignored. The default value is empty.
								// The same key is forbidden to exist in both mismatchLabelKeys and labelSelector.
								// Also, mismatchLabelKeys cannot be set when labelSelector isn't set.
								MismatchLabelKeys *[]string `json:"mismatchLabelKeys,omitempty"`

								// NamespaceSelector A label query over the set of namespaces that the term applies to.
								// The term is applied to the union of the namespaces selected by this field
								// and the ones listed in the namespaces field.
								// null selector and null or empty namespaces list means "this pod's namespace".
								// An empty selector ({}) matches all namespaces.
								NamespaceSelector *struct {
									// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
									MatchExpressions *[]struct {
										// Key key is the label key that the selector applies to.
										Key string `json:"key"`

										// Operator operator represents a key's relationship to a set of values.
										// Valid operators are In, NotIn, Exists and DoesNotExist.
										Operator string `json:"operator"`

										// Values values is an array of string values. If the operator is In or NotIn,
										// the values array must be non-empty. If the operator is Exists or DoesNotExist,
										// the values array must be empty. This array is replaced during a strategic
										// merge patch.
										Values *[]string `json:"values,omitempty"`
									} `json:"matchExpressions,omitempty"`

									// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
									// map is equivalent to an element of matchExpressions, whose key field is "key", the
									// operator is "In", and the values array contains only "value". The requirements are ANDed.
									MatchLabels *map[string]string `json:"matchLabels,omitempty"`
								} `json:"namespaceSelector,omitempty"`

								// Namespaces namespaces specifies a static list of namespace names that the term applies to.
								// The term is applied to the union of the namespaces listed in this field
								// and the ones selected by namespaceSelector.
								// null or empty namespaces list and null namespaceSelector means "this pod's namespace".
								Namespaces *[]string `json:"namespaces,omitempty"`

								// TopologyKey This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
								// the labelSelector in the specified namespaces, where co-located is defined as running on a node
								// whose value of the label with key topologyKey matches that of any node on which any of the
								// selected pods is running.
								// Empty topologyKey is not allowed.
								TopologyKey string `json:"topologyKey"`
							} `json:"podAffinityTerm"`

							// Weight weight associated with matching the corresponding podAffinityTerm,
							// in the range 1-100.
							Weight int32 `json:"weight"`
						} `json:"preferredDuringSchedulingIgnoredDuringExecution,omitempty"`

						// RequiredDuringSchedulingIgnoredDuringExecution If the affinity requirements specified by this field are not met at
						// scheduling time, the pod will not be scheduled onto the node.
						// If the affinity requirements specified by this field cease to be met
						// at some point during pod execution (e.g. due to a pod label update), the
						// system may or may not try to eventually evict the pod from its node.
						// When there are multiple elements, the lists of nodes corresponding to each
						// podAffinityTerm are intersected, i.e. all terms must be satisfied.
						RequiredDuringSchedulingIgnoredDuringExecution *[]struct {
							// LabelSelector A label query over a set of resources, in this case pods.
							// If it's null, this PodAffinityTerm matches with no Pods.
							LabelSelector *struct {
								// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
								MatchExpressions *[]struct {
									// Key key is the label key that the selector applies to.
									Key string `json:"key"`

									// Operator operator represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists and DoesNotExist.
									Operator string `json:"operator"`

									// Values values is an array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. This array is replaced during a strategic
									// merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
								// map is equivalent to an element of matchExpressions, whose key field is "key", the
								// operator is "In", and the values array contains only "value". The requirements are ANDed.
								MatchLabels *map[string]string `json:"matchLabels,omitempty"`
							} `json:"labelSelector,omitempty"`

							// MatchLabelKeys MatchLabelKeys is a set of pod label keys to select which pods will
							// be taken into consideration. The keys are used to lookup values from the
							// incoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`
							// to select the group of existing pods which pods will be taken into consideration
							// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
							// pod labels will be ignored. The default value is empty.
							// The same key is forbidden to exist in both matchLabelKeys and labelSelector.
							// Also, matchLabelKeys cannot be set when labelSelector isn't set.
							MatchLabelKeys *[]string `json:"matchLabelKeys,omitempty"`

							// MismatchLabelKeys MismatchLabelKeys is a set of pod label keys to select which pods will
							// be taken into consideration. The keys are used to lookup values from the
							// incoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`
							// to select the group of existing pods which pods will be taken into consideration
							// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
							// pod labels will be ignored. The default value is empty.
							// The same key is forbidden to exist in both mismatchLabelKeys and labelSelector.
							// Also, mismatchLabelKeys cannot be set when labelSelector isn't set.
							MismatchLabelKeys *[]string `json:"mismatchLabelKeys,omitempty"`

							// NamespaceSelector A label query over the set of namespaces that the term applies to.
							// The term is applied to the union of the namespaces selected by this field
							// and the ones listed in the namespaces field.
							// null selector and null or empty namespaces list means "this pod's namespace".
							// An empty selector ({}) matches all namespaces.
							NamespaceSelector *struct {
								// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
								MatchExpressions *[]struct {
									// Key key is the label key that the selector applies to.
									Key string `json:"key"`

									// Operator operator represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists and DoesNotExist.
									Operator string `json:"operator"`

									// Values values is an array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. This array is replaced during a strategic
									// merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
								// map is equivalent to an element of matchExpressions, whose key field is "key", the
								// operator is "In", and the values array contains only "value". The requirements are ANDed.
								MatchLabels *map[string]string `json:"matchLabels,omitempty"`
							} `json:"namespaceSelector,omitempty"`

							// Namespaces namespaces specifies a static list of namespace names that the term applies to.
							// The term is applied to the union of the namespaces listed in this field
							// and the ones selected by namespaceSelector.
							// null or empty namespaces list and null namespaceSelector means "this pod's namespace".
							Namespaces *[]string `json:"namespaces,omitempty"`

							// TopologyKey This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
							// the labelSelector in the specified namespaces, where co-located is defined as running on a node
							// whose value of the label with key topologyKey matches that of any node on which any of the
							// selected pods is running.
							// Empty topologyKey is not allowed.
							TopologyKey string `json:"topologyKey"`
						} `json:"requiredDuringSchedulingIgnoredDuringExecution,omitempty"`
					} `json:"podAffinity,omitempty"`

					// PodAntiAffinity Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
					PodAntiAffinity *struct {
						// PreferredDuringSchedulingIgnoredDuringExecution The scheduler will prefer to schedule pods to nodes that satisfy
						// the anti-affinity expressions specified by this field, but it may choose
						// a node that violates one or more of the expressions. The node that is
						// most preferred is the one with the greatest sum of weights, i.e.
						// for each node that meets all of the scheduling requirements (resource
						// request, requiredDuringScheduling anti-affinity expressions, etc.),
						// compute a sum by iterating through the elements of this field and adding
						// "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the
						// node(s) with the highest sum are the most preferred.
						PreferredDuringSchedulingIgnoredDuringExecution *[]struct {
							// PodAffinityTerm Required. A pod affinity term, associated with the corresponding weight.
							PodAffinityTerm struct {
								// LabelSelector A label query over a set of resources, in this case pods.
								// If it's null, this PodAffinityTerm matches with no Pods.
								LabelSelector *struct {
									// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
									MatchExpressions *[]struct {
										// Key key is the label key that the selector applies to.
										Key string `json:"key"`

										// Operator operator represents a key's relationship to a set of values.
										// Valid operators are In, NotIn, Exists and DoesNotExist.
										Operator string `json:"operator"`

										// Values values is an array of string values. If the operator is In or NotIn,
										// the values array must be non-empty. If the operator is Exists or DoesNotExist,
										// the values array must be empty. This array is replaced during a strategic
										// merge patch.
										Values *[]string `json:"values,omitempty"`
									} `json:"matchExpressions,omitempty"`

									// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
									// map is equivalent to an element of matchExpressions, whose key field is "key", the
									// operator is "In", and the values array contains only "value". The requirements are ANDed.
									MatchLabels *map[string]string `json:"matchLabels,omitempty"`
								} `json:"labelSelector,omitempty"`

								// MatchLabelKeys MatchLabelKeys is a set of pod label keys to select which pods will
								// be taken into consideration. The keys are used to lookup values from the
								// incoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`
								// to select the group of existing pods which pods will be taken into consideration
								// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
								// pod labels will be ignored. The default value is empty.
								// The same key is forbidden to exist in both matchLabelKeys and labelSelector.
								// Also, matchLabelKeys cannot be set when labelSelector isn't set.
								MatchLabelKeys *[]string `json:"matchLabelKeys,omitempty"`

								// MismatchLabelKeys MismatchLabelKeys is a set of pod label keys to select which pods will
								// be taken into consideration. The keys are used to lookup values from the
								// incoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`
								// to select the group of existing pods which pods will be taken into consideration
								// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
								// pod labels will be ignored. The default value is empty.
								// The same key is forbidden to exist in both mismatchLabelKeys and labelSelector.
								// Also, mismatchLabelKeys cannot be set when labelSelector isn't set.
								MismatchLabelKeys *[]string `json:"mismatchLabelKeys,omitempty"`

								// NamespaceSelector A label query over the set of namespaces that the term applies to.
								// The term is applied to the union of the namespaces selected by this field
								// and the ones listed in the namespaces field.
								// null selector and null or empty namespaces list means "this pod's namespace".
								// An empty selector ({}) matches all namespaces.
								NamespaceSelector *struct {
									// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
									MatchExpressions *[]struct {
										// Key key is the label key that the selector applies to.
										Key string `json:"key"`

										// Operator operator represents a key's relationship to a set of values.
										// Valid operators are In, NotIn, Exists and DoesNotExist.
										Operator string `json:"operator"`

										// Values values is an array of string values. If the operator is In or NotIn,
										// the values array must be non-empty. If the operator is Exists or DoesNotExist,
										// the values array must be empty. This array is replaced during a strategic
										// merge patch.
										Values *[]string `json:"values,omitempty"`
									} `json:"matchExpressions,omitempty"`

									// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
									// map is equivalent to an element of matchExpressions, whose key field is "key", the
									// operator is "In", and the values array contains only "value". The requirements are ANDed.
									MatchLabels *map[string]string `json:"matchLabels,omitempty"`
								} `json:"namespaceSelector,omitempty"`

								// Namespaces namespaces specifies a static list of namespace names that the term applies to.
								// The term is applied to the union of the namespaces listed in this field
								// and the ones selected by namespaceSelector.
								// null or empty namespaces list and null namespaceSelector means "this pod's namespace".
								Namespaces *[]string `json:"namespaces,omitempty"`

								// TopologyKey This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
								// the labelSelector in the specified namespaces, where co-located is defined as running on a node
								// whose value of the label with key topologyKey matches that of any node on which any of the
								// selected pods is running.
								// Empty topologyKey is not allowed.
								TopologyKey string `json:"topologyKey"`
							} `json:"podAffinityTerm"`

							// Weight weight associated with matching the corresponding podAffinityTerm,
							// in the range 1-100.
							Weight int32 `json:"weight"`
						} `json:"preferredDuringSchedulingIgnoredDuringExecution,omitempty"`

						// RequiredDuringSchedulingIgnoredDuringExecution If the anti-affinity requirements specified by this field are not met at
						// scheduling time, the pod will not be scheduled onto the node.
						// If the anti-affinity requirements specified by this field cease to be met
						// at some point during pod execution (e.g. due to a pod label update), the
						// system may or may not try to eventually evict the pod from its node.
						// When there are multiple elements, the lists of nodes corresponding to each
						// podAffinityTerm are intersected, i.e. all terms must be satisfied.
						RequiredDuringSchedulingIgnoredDuringExecution *[]struct {
							// LabelSelector A label query over a set of resources, in this case pods.
							// If it's null, this PodAffinityTerm matches with no Pods.
							LabelSelector *struct {
								// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
								MatchExpressions *[]struct {
									// Key key is the label key that the selector applies to.
									Key string `json:"key"`

									// Operator operator represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists and DoesNotExist.
									Operator string `json:"operator"`

									// Values values is an array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. This array is replaced during a strategic
									// merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
								// map is equivalent to an element of matchExpressions, whose key field is "key", the
								// operator is "In", and the values array contains only "value". The requirements are ANDed.
								MatchLabels *map[string]string `json:"matchLabels,omitempty"`
							} `json:"labelSelector,omitempty"`

							// MatchLabelKeys MatchLabelKeys is a set of pod label keys to select which pods will
							// be taken into consideration. The keys are used to lookup values from the
							// incoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`
							// to select the group of existing pods which pods will be taken into consideration
							// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
							// pod labels will be ignored. The default value is empty.
							// The same key is forbidden to exist in both matchLabelKeys and labelSelector.
							// Also, matchLabelKeys cannot be set when labelSelector isn't set.
							MatchLabelKeys *[]string `json:"matchLabelKeys,omitempty"`

							// MismatchLabelKeys MismatchLabelKeys is a set of pod label keys to select which pods will
							// be taken into consideration. The keys are used to lookup values from the
							// incoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`
							// to select the group of existing pods which pods will be taken into consideration
							// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
							// pod labels will be ignored. The default value is empty.
							// The same key is forbidden to exist in both mismatchLabelKeys and labelSelector.
							// Also, mismatchLabelKeys cannot be set when labelSelector isn't set.
							MismatchLabelKeys *[]string `json:"mismatchLabelKeys,omitempty"`

							// NamespaceSelector A label query over the set of namespaces that the term applies to.
							// The term is applied to the union of the namespaces selected by this field
							// and the ones listed in the namespaces field.
							// null selector and null or empty namespaces list means "this pod's namespace".
							// An empty selector ({}) matches all namespaces.
							NamespaceSelector *struct {
								// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
								MatchExpressions *[]struct {
									// Key key is the label key that the selector applies to.
									Key string `json:"key"`

									// Operator operator represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists and DoesNotExist.
									Operator string `json:"operator"`

									// Values values is an array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. This array is replaced during a strategic
									// merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
								// map is equivalent to an element of matchExpressions, whose key field is "key", the
								// operator is "In", and the values array contains only "value". The requirements are ANDed.
								MatchLabels *map[string]string `json:"matchLabels,omitempty"`
							} `json:"namespaceSelector,omitempty"`

							// Namespaces namespaces specifies a static list of namespace names that the term applies to.
							// The term is applied to the union of the namespaces listed in this field
							// and the ones selected by namespaceSelector.
							// null or empty namespaces list and null namespaceSelector means "this pod's namespace".
							Namespaces *[]string `json:"namespaces,omitempty"`

							// TopologyKey This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
							// the labelSelector in the specified namespaces, where co-located is defined as running on a node
							// whose value of the label with key topologyKey matches that of any node on which any of the
							// selected pods is running.
							// Empty topologyKey is not allowed.
							TopologyKey string `json:"topologyKey"`
						} `json:"requiredDuringSchedulingIgnoredDuringExecution,omitempty"`
					} `json:"podAntiAffinity,omitempty"`
				} `json:"proxy,omitempty"`
			} `json:"postgresql,omitempty"`

			// Psmdb PSMDB is the affinity configuration for the PSMDB DB clusters.
			Psmdb *struct {
				// ConfigServer ConfigServer is the affinity configuration for the DB Config Server pods.
				ConfigServer *struct {
					// NodeAffinity Describes node affinity scheduling rules for the pod.
					NodeAffinity *struct {
						// PreferredDuringSchedulingIgnoredDuringExecution The scheduler will prefer to schedule pods to nodes that satisfy
						// the affinity expressions specified by this field, but it may choose
						// a node that violates one or more of the expressions. The node that is
						// most preferred is the one with the greatest sum of weights, i.e.
						// for each node that meets all of the scheduling requirements (resource
						// request, requiredDuringScheduling affinity expressions, etc.),
						// compute a sum by iterating through the elements of this field and adding
						// "weight" to the sum if the node matches the corresponding matchExpressions; the
						// node(s) with the highest sum are the most preferred.
						PreferredDuringSchedulingIgnoredDuringExecution *[]struct {
							// Preference A node selector term, associated with the corresponding weight.
							Preference struct {
								// MatchExpressions A list of node selector requirements by node's labels.
								MatchExpressions *[]struct {
									// Key The label key that the selector applies to.
									Key string `json:"key"`

									// Operator Represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
									Operator string `json:"operator"`

									// Values An array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. If the operator is Gt or Lt, the values
									// array must have a single element, which will be interpreted as an integer.
									// This array is replaced during a strategic merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchFields A list of node selector requirements by node's fields.
								MatchFields *[]struct {
									// Key The label key that the selector applies to.
									Key string `json:"key"`

									// Operator Represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
									Operator string `json:"operator"`

									// Values An array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. If the operator is Gt or Lt, the values
									// array must have a single element, which will be interpreted as an integer.
									// This array is replaced during a strategic merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchFields,omitempty"`
							} `json:"preference"`

							// Weight Weight associated with matching the corresponding nodeSelectorTerm, in the range 1-100.
							Weight int32 `json:"weight"`
						} `json:"preferredDuringSchedulingIgnoredDuringExecution,omitempty"`

						// RequiredDuringSchedulingIgnoredDuringExecution If the affinity requirements specified by this field are not met at
						// scheduling time, the pod will not be scheduled onto the node.
						// If the affinity requirements specified by this field cease to be met
						// at some point during pod execution (e.g. due to an update), the system
						// may or may not try to eventually evict the pod from its node.
						RequiredDuringSchedulingIgnoredDuringExecution *struct {
							// NodeSelectorTerms Required. A list of node selector terms. The terms are ORed.
							NodeSelectorTerms []struct {
								// MatchExpressions A list of node selector requirements by node's labels.
								MatchExpressions *[]struct {
									// Key The label key that the selector applies to.
									Key string `json:"key"`

									// Operator Represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
									Operator string `json:"operator"`

									// Values An array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. If the operator is Gt or Lt, the values
									// array must have a single element, which will be interpreted as an integer.
									// This array is replaced during a strategic merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchFields A list of node selector requirements by node's fields.
								MatchFields *[]struct {
									// Key The label key that the selector applies to.
									Key string `json:"key"`

									// Operator Represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
									Operator string `json:"operator"`

									// Values An array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. If the operator is Gt or Lt, the values
									// array must have a single element, which will be interpreted as an integer.
									// This array is replaced during a strategic merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchFields,omitempty"`
							} `json:"nodeSelectorTerms"`
						} `json:"requiredDuringSchedulingIgnoredDuringExecution,omitempty"`
					} `json:"nodeAffinity,omitempty"`

					// PodAffinity Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
					PodAffinity *struct {
						// PreferredDuringSchedulingIgnoredDuringExecution The scheduler will prefer to schedule pods to nodes that satisfy
						// the affinity expressions specified by this field, but it may choose
						// a node that violates one or more of the expressions. The node that is
						// most preferred is the one with the greatest sum of weights, i.e.
						// for each node that meets all of the scheduling requirements (resource
						// request, requiredDuringScheduling affinity expressions, etc.),
						// compute a sum by iterating through the elements of this field and adding
						// "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the
						// node(s) with the highest sum are the most preferred.
						PreferredDuringSchedulingIgnoredDuringExecution *[]struct {
							// PodAffinityTerm Required. A pod affinity term, associated with the corresponding weight.
							PodAffinityTerm struct {
								// LabelSelector A label query over a set of resources, in this case pods.
								// If it's null, this PodAffinityTerm matches with no Pods.
								LabelSelector *struct {
									// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
									MatchExpressions *[]struct {
										// Key key is the label key that the selector applies to.
										Key string `json:"key"`

										// Operator operator represents a key's relationship to a set of values.
										// Valid operators are In, NotIn, Exists and DoesNotExist.
										Operator string `json:"operator"`

										// Values values is an array of string values. If the operator is In or NotIn,
										// the values array must be non-empty. If the operator is Exists or DoesNotExist,
										// the values array must be empty. This array is replaced during a strategic
										// merge patch.
										Values *[]string `json:"values,omitempty"`
									} `json:"matchExpressions,omitempty"`

									// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
									// map is equivalent to an element of matchExpressions, whose key field is "key", the
									// operator is "In", and the values array contains only "value". The requirements are ANDed.
									MatchLabels *map[string]string `json:"matchLabels,omitempty"`
								} `json:"labelSelector,omitempty"`

								// MatchLabelKeys MatchLabelKeys is a set of pod label keys to select which pods will
								// be taken into consideration. The keys are used to lookup values from the
								// incoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`
								// to select the group of existing pods which pods will be taken into consideration
								// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
								// pod labels will be ignored. The default value is empty.
								// The same key is forbidden to exist in both matchLabelKeys and labelSelector.
								// Also, matchLabelKeys cannot be set when labelSelector isn't set.
								MatchLabelKeys *[]string `json:"matchLabelKeys,omitempty"`

								// MismatchLabelKeys MismatchLabelKeys is a set of pod label keys to select which pods will
								// be taken into consideration. The keys are used to lookup values from the
								// incoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`
								// to select the group of existing pods which pods will be taken into consideration
								// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
								// pod labels will be ignored. The default value is empty.
								// The same key is forbidden to exist in both mismatchLabelKeys and labelSelector.
								// Also, mismatchLabelKeys cannot be set when labelSelector isn't set.
								MismatchLabelKeys *[]string `json:"mismatchLabelKeys,omitempty"`

								// NamespaceSelector A label query over the set of namespaces that the term applies to.
								// The term is applied to the union of the namespaces selected by this field
								// and the ones listed in the namespaces field.
								// null selector and null or empty namespaces list means "this pod's namespace".
								// An empty selector ({}) matches all namespaces.
								NamespaceSelector *struct {
									// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
									MatchExpressions *[]struct {
										// Key key is the label key that the selector applies to.
										Key string `json:"key"`

										// Operator operator represents a key's relationship to a set of values.
										// Valid operators are In, NotIn, Exists and DoesNotExist.
										Operator string `json:"operator"`

										// Values values is an array of string values. If the operator is In or NotIn,
										// the values array must be non-empty. If the operator is Exists or DoesNotExist,
										// the values array must be empty. This array is replaced during a strategic
										// merge patch.
										Values *[]string `json:"values,omitempty"`
									} `json:"matchExpressions,omitempty"`

									// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
									// map is equivalent to an element of matchExpressions, whose key field is "key", the
									// operator is "In", and the values array contains only "value". The requirements are ANDed.
									MatchLabels *map[string]string `json:"matchLabels,omitempty"`
								} `json:"namespaceSelector,omitempty"`

								// Namespaces namespaces specifies a static list of namespace names that the term applies to.
								// The term is applied to the union of the namespaces listed in this field
								// and the ones selected by namespaceSelector.
								// null or empty namespaces list and null namespaceSelector means "this pod's namespace".
								Namespaces *[]string `json:"namespaces,omitempty"`

								// TopologyKey This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
								// the labelSelector in the specified namespaces, where co-located is defined as running on a node
								// whose value of the label with key topologyKey matches that of any node on which any of the
								// selected pods is running.
								// Empty topologyKey is not allowed.
								TopologyKey string `json:"topologyKey"`
							} `json:"podAffinityTerm"`

							// Weight weight associated with matching the corresponding podAffinityTerm,
							// in the range 1-100.
							Weight int32 `json:"weight"`
						} `json:"preferredDuringSchedulingIgnoredDuringExecution,omitempty"`

						// RequiredDuringSchedulingIgnoredDuringExecution If the affinity requirements specified by this field are not met at
						// scheduling time, the pod will not be scheduled onto the node.
						// If the affinity requirements specified by this field cease to be met
						// at some point during pod execution (e.g. due to a pod label update), the
						// system may or may not try to eventually evict the pod from its node.
						// When there are multiple elements, the lists of nodes corresponding to each
						// podAffinityTerm are intersected, i.e. all terms must be satisfied.
						RequiredDuringSchedulingIgnoredDuringExecution *[]struct {
							// LabelSelector A label query over a set of resources, in this case pods.
							// If it's null, this PodAffinityTerm matches with no Pods.
							LabelSelector *struct {
								// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
								MatchExpressions *[]struct {
									// Key key is the label key that the selector applies to.
									Key string `json:"key"`

									// Operator operator represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists and DoesNotExist.
									Operator string `json:"operator"`

									// Values values is an array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. This array is replaced during a strategic
									// merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
								// map is equivalent to an element of matchExpressions, whose key field is "key", the
								// operator is "In", and the values array contains only "value". The requirements are ANDed.
								MatchLabels *map[string]string `json:"matchLabels,omitempty"`
							} `json:"labelSelector,omitempty"`

							// MatchLabelKeys MatchLabelKeys is a set of pod label keys to select which pods will
							// be taken into consideration. The keys are used to lookup values from the
							// incoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`
							// to select the group of existing pods which pods will be taken into consideration
							// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
							// pod labels will be ignored. The default value is empty.
							// The same key is forbidden to exist in both matchLabelKeys and labelSelector.
							// Also, matchLabelKeys cannot be set when labelSelector isn't set.
							MatchLabelKeys *[]string `json:"matchLabelKeys,omitempty"`

							// MismatchLabelKeys MismatchLabelKeys is a set of pod label keys to select which pods will
							// be taken into consideration. The keys are used to lookup values from the
							// incoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`
							// to select the group of existing pods which pods will be taken into consideration
							// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
							// pod labels will be ignored. The default value is empty.
							// The same key is forbidden to exist in both mismatchLabelKeys and labelSelector.
							// Also, mismatchLabelKeys cannot be set when labelSelector isn't set.
							MismatchLabelKeys *[]string `json:"mismatchLabelKeys,omitempty"`

							// NamespaceSelector A label query over the set of namespaces that the term applies to.
							// The term is applied to the union of the namespaces selected by this field
							// and the ones listed in the namespaces field.
							// null selector and null or empty namespaces list means "this pod's namespace".
							// An empty selector ({}) matches all namespaces.
							NamespaceSelector *struct {
								// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
								MatchExpressions *[]struct {
									// Key key is the label key that the selector applies to.
									Key string `json:"key"`

									// Operator operator represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists and DoesNotExist.
									Operator string `json:"operator"`

									// Values values is an array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. This array is replaced during a strategic
									// merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
								// map is equivalent to an element of matchExpressions, whose key field is "key", the
								// operator is "In", and the values array contains only "value". The requirements are ANDed.
								MatchLabels *map[string]string `json:"matchLabels,omitempty"`
							} `json:"namespaceSelector,omitempty"`

							// Namespaces namespaces specifies a static list of namespace names that the term applies to.
							// The term is applied to the union of the namespaces listed in this field
							// and the ones selected by namespaceSelector.
							// null or empty namespaces list and null namespaceSelector means "this pod's namespace".
							Namespaces *[]string `json:"namespaces,omitempty"`

							// TopologyKey This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
							// the labelSelector in the specified namespaces, where co-located is defined as running on a node
							// whose value of the label with key topologyKey matches that of any node on which any of the
							// selected pods is running.
							// Empty topologyKey is not allowed.
							TopologyKey string `json:"topologyKey"`
						} `json:"requiredDuringSchedulingIgnoredDuringExecution,omitempty"`
					} `json:"podAffinity,omitempty"`

					// PodAntiAffinity Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
					PodAntiAffinity *struct {
						// PreferredDuringSchedulingIgnoredDuringExecution The scheduler will prefer to schedule pods to nodes that satisfy
						// the anti-affinity expressions specified by this field, but it may choose
						// a node that violates one or more of the expressions. The node that is
						// most preferred is the one with the greatest sum of weights, i.e.
						// for each node that meets all of the scheduling requirements (resource
						// request, requiredDuringScheduling anti-affinity expressions, etc.),
						// compute a sum by iterating through the elements of this field and adding
						// "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the
						// node(s) with the highest sum are the most preferred.
						PreferredDuringSchedulingIgnoredDuringExecution *[]struct {
							// PodAffinityTerm Required. A pod affinity term, associated with the corresponding weight.
							PodAffinityTerm struct {
								// LabelSelector A label query over a set of resources, in this case pods.
								// If it's null, this PodAffinityTerm matches with no Pods.
								LabelSelector *struct {
									// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
									MatchExpressions *[]struct {
										// Key key is the label key that the selector applies to.
										Key string `json:"key"`

										// Operator operator represents a key's relationship to a set of values.
										// Valid operators are In, NotIn, Exists and DoesNotExist.
										Operator string `json:"operator"`

										// Values values is an array of string values. If the operator is In or NotIn,
										// the values array must be non-empty. If the operator is Exists or DoesNotExist,
										// the values array must be empty. This array is replaced during a strategic
										// merge patch.
										Values *[]string `json:"values,omitempty"`
									} `json:"matchExpressions,omitempty"`

									// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
									// map is equivalent to an element of matchExpressions, whose key field is "key", the
									// operator is "In", and the values array contains only "value". The requirements are ANDed.
									MatchLabels *map[string]string `json:"matchLabels,omitempty"`
								} `json:"labelSelector,omitempty"`

								// MatchLabelKeys MatchLabelKeys is a set of pod label keys to select which pods will
								// be taken into consideration. The keys are used to lookup values from the
								// incoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`
								// to select the group of existing pods which pods will be taken into consideration
								// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
								// pod labels will be ignored. The default value is empty.
								// The same key is forbidden to exist in both matchLabelKeys and labelSelector.
								// Also, matchLabelKeys cannot be set when labelSelector isn't set.
								MatchLabelKeys *[]string `json:"matchLabelKeys,omitempty"`

								// MismatchLabelKeys MismatchLabelKeys is a set of pod label keys to select which pods will
								// be taken into consideration. The keys are used to lookup values from the
								// incoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`
								// to select the group of existing pods which pods will be taken into consideration
								// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
								// pod labels will be ignored. The default value is empty.
								// The same key is forbidden to exist in both mismatchLabelKeys and labelSelector.
								// Also, mismatchLabelKeys cannot be set when labelSelector isn't set.
								MismatchLabelKeys *[]string `json:"mismatchLabelKeys,omitempty"`

								// NamespaceSelector A label query over the set of namespaces that the term applies to.
								// The term is applied to the union of the namespaces selected by this field
								// and the ones listed in the namespaces field.
								// null selector and null or empty namespaces list means "this pod's namespace".
								// An empty selector ({}) matches all namespaces.
								NamespaceSelector *struct {
									// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
									MatchExpressions *[]struct {
										// Key key is the label key that the selector applies to.
										Key string `json:"key"`

										// Operator operator represents a key's relationship to a set of values.
										// Valid operators are In, NotIn, Exists and DoesNotExist.
										Operator string `json:"operator"`

										// Values values is an array of string values. If the operator is In or NotIn,
										// the values array must be non-empty. If the operator is Exists or DoesNotExist,
										// the values array must be empty. This array is replaced during a strategic
										// merge patch.
										Values *[]string `json:"values,omitempty"`
									} `json:"matchExpressions,omitempty"`

									// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
									// map is equivalent to an element of matchExpressions, whose key field is "key", the
									// operator is "In", and the values array contains only "value". The requirements are ANDed.
									MatchLabels *map[string]string `json:"matchLabels,omitempty"`
								} `json:"namespaceSelector,omitempty"`

								// Namespaces namespaces specifies a static list of namespace names that the term applies to.
								// The term is applied to the union of the namespaces listed in this field
								// and the ones selected by namespaceSelector.
								// null or empty namespaces list and null namespaceSelector means "this pod's namespace".
								Namespaces *[]string `json:"namespaces,omitempty"`

								// TopologyKey This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
								// the labelSelector in the specified namespaces, where co-located is defined as running on a node
								// whose value of the label with key topologyKey matches that of any node on which any of the
								// selected pods is running.
								// Empty topologyKey is not allowed.
								TopologyKey string `json:"topologyKey"`
							} `json:"podAffinityTerm"`

							// Weight weight associated with matching the corresponding podAffinityTerm,
							// in the range 1-100.
							Weight int32 `json:"weight"`
						} `json:"preferredDuringSchedulingIgnoredDuringExecution,omitempty"`

						// RequiredDuringSchedulingIgnoredDuringExecution If the anti-affinity requirements specified by this field are not met at
						// scheduling time, the pod will not be scheduled onto the node.
						// If the anti-affinity requirements specified by this field cease to be met
						// at some point during pod execution (e.g. due to a pod label update), the
						// system may or may not try to eventually evict the pod from its node.
						// When there are multiple elements, the lists of nodes corresponding to each
						// podAffinityTerm are intersected, i.e. all terms must be satisfied.
						RequiredDuringSchedulingIgnoredDuringExecution *[]struct {
							// LabelSelector A label query over a set of resources, in this case pods.
							// If it's null, this PodAffinityTerm matches with no Pods.
							LabelSelector *struct {
								// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
								MatchExpressions *[]struct {
									// Key key is the label key that the selector applies to.
									Key string `json:"key"`

									// Operator operator represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists and DoesNotExist.
									Operator string `json:"operator"`

									// Values values is an array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. This array is replaced during a strategic
									// merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
								// map is equivalent to an element of matchExpressions, whose key field is "key", the
								// operator is "In", and the values array contains only "value". The requirements are ANDed.
								MatchLabels *map[string]string `json:"matchLabels,omitempty"`
							} `json:"labelSelector,omitempty"`

							// MatchLabelKeys MatchLabelKeys is a set of pod label keys to select which pods will
							// be taken into consideration. The keys are used to lookup values from the
							// incoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`
							// to select the group of existing pods which pods will be taken into consideration
							// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
							// pod labels will be ignored. The default value is empty.
							// The same key is forbidden to exist in both matchLabelKeys and labelSelector.
							// Also, matchLabelKeys cannot be set when labelSelector isn't set.
							MatchLabelKeys *[]string `json:"matchLabelKeys,omitempty"`

							// MismatchLabelKeys MismatchLabelKeys is a set of pod label keys to select which pods will
							// be taken into consideration. The keys are used to lookup values from the
							// incoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`
							// to select the group of existing pods which pods will be taken into consideration
							// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
							// pod labels will be ignored. The default value is empty.
							// The same key is forbidden to exist in both mismatchLabelKeys and labelSelector.
							// Also, mismatchLabelKeys cannot be set when labelSelector isn't set.
							MismatchLabelKeys *[]string `json:"mismatchLabelKeys,omitempty"`

							// NamespaceSelector A label query over the set of namespaces that the term applies to.
							// The term is applied to the union of the namespaces selected by this field
							// and the ones listed in the namespaces field.
							// null selector and null or empty namespaces list means "this pod's namespace".
							// An empty selector ({}) matches all namespaces.
							NamespaceSelector *struct {
								// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
								MatchExpressions *[]struct {
									// Key key is the label key that the selector applies to.
									Key string `json:"key"`

									// Operator operator represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists and DoesNotExist.
									Operator string `json:"operator"`

									// Values values is an array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. This array is replaced during a strategic
									// merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
								// map is equivalent to an element of matchExpressions, whose key field is "key", the
								// operator is "In", and the values array contains only "value". The requirements are ANDed.
								MatchLabels *map[string]string `json:"matchLabels,omitempty"`
							} `json:"namespaceSelector,omitempty"`

							// Namespaces namespaces specifies a static list of namespace names that the term applies to.
							// The term is applied to the union of the namespaces listed in this field
							// and the ones selected by namespaceSelector.
							// null or empty namespaces list and null namespaceSelector means "this pod's namespace".
							Namespaces *[]string `json:"namespaces,omitempty"`

							// TopologyKey This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
							// the labelSelector in the specified namespaces, where co-located is defined as running on a node
							// whose value of the label with key topologyKey matches that of any node on which any of the
							// selected pods is running.
							// Empty topologyKey is not allowed.
							TopologyKey string `json:"topologyKey"`
						} `json:"requiredDuringSchedulingIgnoredDuringExecution,omitempty"`
					} `json:"podAntiAffinity,omitempty"`
				} `json:"configServer,omitempty"`

				// Engine Engine is the affinity configuration for the DB Engine pods.
				Engine *struct {
					// NodeAffinity Describes node affinity scheduling rules for the pod.
					NodeAffinity *struct {
						// PreferredDuringSchedulingIgnoredDuringExecution The scheduler will prefer to schedule pods to nodes that satisfy
						// the affinity expressions specified by this field, but it may choose
						// a node that violates one or more of the expressions. The node that is
						// most preferred is the one with the greatest sum of weights, i.e.
						// for each node that meets all of the scheduling requirements (resource
						// request, requiredDuringScheduling affinity expressions, etc.),
						// compute a sum by iterating through the elements of this field and adding
						// "weight" to the sum if the node matches the corresponding matchExpressions; the
						// node(s) with the highest sum are the most preferred.
						PreferredDuringSchedulingIgnoredDuringExecution *[]struct {
							// Preference A node selector term, associated with the corresponding weight.
							Preference struct {
								// MatchExpressions A list of node selector requirements by node's labels.
								MatchExpressions *[]struct {
									// Key The label key that the selector applies to.
									Key string `json:"key"`

									// Operator Represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
									Operator string `json:"operator"`

									// Values An array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. If the operator is Gt or Lt, the values
									// array must have a single element, which will be interpreted as an integer.
									// This array is replaced during a strategic merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchFields A list of node selector requirements by node's fields.
								MatchFields *[]struct {
									// Key The label key that the selector applies to.
									Key string `json:"key"`

									// Operator Represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
									Operator string `json:"operator"`

									// Values An array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. If the operator is Gt or Lt, the values
									// array must have a single element, which will be interpreted as an integer.
									// This array is replaced during a strategic merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchFields,omitempty"`
							} `json:"preference"`

							// Weight Weight associated with matching the corresponding nodeSelectorTerm, in the range 1-100.
							Weight int32 `json:"weight"`
						} `json:"preferredDuringSchedulingIgnoredDuringExecution,omitempty"`

						// RequiredDuringSchedulingIgnoredDuringExecution If the affinity requirements specified by this field are not met at
						// scheduling time, the pod will not be scheduled onto the node.
						// If the affinity requirements specified by this field cease to be met
						// at some point during pod execution (e.g. due to an update), the system
						// may or may not try to eventually evict the pod from its node.
						RequiredDuringSchedulingIgnoredDuringExecution *struct {
							// NodeSelectorTerms Required. A list of node selector terms. The terms are ORed.
							NodeSelectorTerms []struct {
								// MatchExpressions A list of node selector requirements by node's labels.
								MatchExpressions *[]struct {
									// Key The label key that the selector applies to.
									Key string `json:"key"`

									// Operator Represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
									Operator string `json:"operator"`

									// Values An array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. If the operator is Gt or Lt, the values
									// array must have a single element, which will be interpreted as an integer.
									// This array is replaced during a strategic merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchFields A list of node selector requirements by node's fields.
								MatchFields *[]struct {
									// Key The label key that the selector applies to.
									Key string `json:"key"`

									// Operator Represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
									Operator string `json:"operator"`

									// Values An array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. If the operator is Gt or Lt, the values
									// array must have a single element, which will be interpreted as an integer.
									// This array is replaced during a strategic merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchFields,omitempty"`
							} `json:"nodeSelectorTerms"`
						} `json:"requiredDuringSchedulingIgnoredDuringExecution,omitempty"`
					} `json:"nodeAffinity,omitempty"`

					// PodAffinity Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
					PodAffinity *struct {
						// PreferredDuringSchedulingIgnoredDuringExecution The scheduler will prefer to schedule pods to nodes that satisfy
						// the affinity expressions specified by this field, but it may choose
						// a node that violates one or more of the expressions. The node that is
						// most preferred is the one with the greatest sum of weights, i.e.
						// for each node that meets all of the scheduling requirements (resource
						// request, requiredDuringScheduling affinity expressions, etc.),
						// compute a sum by iterating through the elements of this field and adding
						// "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the
						// node(s) with the highest sum are the most preferred.
						PreferredDuringSchedulingIgnoredDuringExecution *[]struct {
							// PodAffinityTerm Required. A pod affinity term, associated with the corresponding weight.
							PodAffinityTerm struct {
								// LabelSelector A label query over a set of resources, in this case pods.
								// If it's null, this PodAffinityTerm matches with no Pods.
								LabelSelector *struct {
									// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
									MatchExpressions *[]struct {
										// Key key is the label key that the selector applies to.
										Key string `json:"key"`

										// Operator operator represents a key's relationship to a set of values.
										// Valid operators are In, NotIn, Exists and DoesNotExist.
										Operator string `json:"operator"`

										// Values values is an array of string values. If the operator is In or NotIn,
										// the values array must be non-empty. If the operator is Exists or DoesNotExist,
										// the values array must be empty. This array is replaced during a strategic
										// merge patch.
										Values *[]string `json:"values,omitempty"`
									} `json:"matchExpressions,omitempty"`

									// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
									// map is equivalent to an element of matchExpressions, whose key field is "key", the
									// operator is "In", and the values array contains only "value". The requirements are ANDed.
									MatchLabels *map[string]string `json:"matchLabels,omitempty"`
								} `json:"labelSelector,omitempty"`

								// MatchLabelKeys MatchLabelKeys is a set of pod label keys to select which pods will
								// be taken into consideration. The keys are used to lookup values from the
								// incoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`
								// to select the group of existing pods which pods will be taken into consideration
								// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
								// pod labels will be ignored. The default value is empty.
								// The same key is forbidden to exist in both matchLabelKeys and labelSelector.
								// Also, matchLabelKeys cannot be set when labelSelector isn't set.
								MatchLabelKeys *[]string `json:"matchLabelKeys,omitempty"`

								// MismatchLabelKeys MismatchLabelKeys is a set of pod label keys to select which pods will
								// be taken into consideration. The keys are used to lookup values from the
								// incoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`
								// to select the group of existing pods which pods will be taken into consideration
								// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
								// pod labels will be ignored. The default value is empty.
								// The same key is forbidden to exist in both mismatchLabelKeys and labelSelector.
								// Also, mismatchLabelKeys cannot be set when labelSelector isn't set.
								MismatchLabelKeys *[]string `json:"mismatchLabelKeys,omitempty"`

								// NamespaceSelector A label query over the set of namespaces that the term applies to.
								// The term is applied to the union of the namespaces selected by this field
								// and the ones listed in the namespaces field.
								// null selector and null or empty namespaces list means "this pod's namespace".
								// An empty selector ({}) matches all namespaces.
								NamespaceSelector *struct {
									// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
									MatchExpressions *[]struct {
										// Key key is the label key that the selector applies to.
										Key string `json:"key"`

										// Operator operator represents a key's relationship to a set of values.
										// Valid operators are In, NotIn, Exists and DoesNotExist.
										Operator string `json:"operator"`

										// Values values is an array of string values. If the operator is In or NotIn,
										// the values array must be non-empty. If the operator is Exists or DoesNotExist,
										// the values array must be empty. This array is replaced during a strategic
										// merge patch.
										Values *[]string `json:"values,omitempty"`
									} `json:"matchExpressions,omitempty"`

									// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
									// map is equivalent to an element of matchExpressions, whose key field is "key", the
									// operator is "In", and the values array contains only "value". The requirements are ANDed.
									MatchLabels *map[string]string `json:"matchLabels,omitempty"`
								} `json:"namespaceSelector,omitempty"`

								// Namespaces namespaces specifies a static list of namespace names that the term applies to.
								// The term is applied to the union of the namespaces listed in this field
								// and the ones selected by namespaceSelector.
								// null or empty namespaces list and null namespaceSelector means "this pod's namespace".
								Namespaces *[]string `json:"namespaces,omitempty"`

								// TopologyKey This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
								// the labelSelector in the specified namespaces, where co-located is defined as running on a node
								// whose value of the label with key topologyKey matches that of any node on which any of the
								// selected pods is running.
								// Empty topologyKey is not allowed.
								TopologyKey string `json:"topologyKey"`
							} `json:"podAffinityTerm"`

							// Weight weight associated with matching the corresponding podAffinityTerm,
							// in the range 1-100.
							Weight int32 `json:"weight"`
						} `json:"preferredDuringSchedulingIgnoredDuringExecution,omitempty"`

						// RequiredDuringSchedulingIgnoredDuringExecution If the affinity requirements specified by this field are not met at
						// scheduling time, the pod will not be scheduled onto the node.
						// If the affinity requirements specified by this field cease to be met
						// at some point during pod execution (e.g. due to a pod label update), the
						// system may or may not try to eventually evict the pod from its node.
						// When there are multiple elements, the lists of nodes corresponding to each
						// podAffinityTerm are intersected, i.e. all terms must be satisfied.
						RequiredDuringSchedulingIgnoredDuringExecution *[]struct {
							// LabelSelector A label query over a set of resources, in this case pods.
							// If it's null, this PodAffinityTerm matches with no Pods.
							LabelSelector *struct {
								// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
								MatchExpressions *[]struct {
									// Key key is the label key that the selector applies to.
									Key string `json:"key"`

									// Operator operator represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists and DoesNotExist.
									Operator string `json:"operator"`

									// Values values is an array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. This array is replaced during a strategic
									// merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
								// map is equivalent to an element of matchExpressions, whose key field is "key", the
								// operator is "In", and the values array contains only "value". The requirements are ANDed.
								MatchLabels *map[string]string `json:"matchLabels,omitempty"`
							} `json:"labelSelector,omitempty"`

							// MatchLabelKeys MatchLabelKeys is a set of pod label keys to select which pods will
							// be taken into consideration. The keys are used to lookup values from the
							// incoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`
							// to select the group of existing pods which pods will be taken into consideration
							// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
							// pod labels will be ignored. The default value is empty.
							// The same key is forbidden to exist in both matchLabelKeys and labelSelector.
							// Also, matchLabelKeys cannot be set when labelSelector isn't set.
							MatchLabelKeys *[]string `json:"matchLabelKeys,omitempty"`

							// MismatchLabelKeys MismatchLabelKeys is a set of pod label keys to select which pods will
							// be taken into consideration. The keys are used to lookup values from the
							// incoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`
							// to select the group of existing pods which pods will be taken into consideration
							// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
							// pod labels will be ignored. The default value is empty.
							// The same key is forbidden to exist in both mismatchLabelKeys and labelSelector.
							// Also, mismatchLabelKeys cannot be set when labelSelector isn't set.
							MismatchLabelKeys *[]string `json:"mismatchLabelKeys,omitempty"`

							// NamespaceSelector A label query over the set of namespaces that the term applies to.
							// The term is applied to the union of the namespaces selected by this field
							// and the ones listed in the namespaces field.
							// null selector and null or empty namespaces list means "this pod's namespace".
							// An empty selector ({}) matches all namespaces.
							NamespaceSelector *struct {
								// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
								MatchExpressions *[]struct {
									// Key key is the label key that the selector applies to.
									Key string `json:"key"`

									// Operator operator represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists and DoesNotExist.
									Operator string `json:"operator"`

									// Values values is an array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. This array is replaced during a strategic
									// merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
								// map is equivalent to an element of matchExpressions, whose key field is "key", the
								// operator is "In", and the values array contains only "value". The requirements are ANDed.
								MatchLabels *map[string]string `json:"matchLabels,omitempty"`
							} `json:"namespaceSelector,omitempty"`

							// Namespaces namespaces specifies a static list of namespace names that the term applies to.
							// The term is applied to the union of the namespaces listed in this field
							// and the ones selected by namespaceSelector.
							// null or empty namespaces list and null namespaceSelector means "this pod's namespace".
							Namespaces *[]string `json:"namespaces,omitempty"`

							// TopologyKey This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
							// the labelSelector in the specified namespaces, where co-located is defined as running on a node
							// whose value of the label with key topologyKey matches that of any node on which any of the
							// selected pods is running.
							// Empty topologyKey is not allowed.
							TopologyKey string `json:"topologyKey"`
						} `json:"requiredDuringSchedulingIgnoredDuringExecution,omitempty"`
					} `json:"podAffinity,omitempty"`

					// PodAntiAffinity Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
					PodAntiAffinity *struct {
						// PreferredDuringSchedulingIgnoredDuringExecution The scheduler will prefer to schedule pods to nodes that satisfy
						// the anti-affinity expressions specified by this field, but it may choose
						// a node that violates one or more of the expressions. The node that is
						// most preferred is the one with the greatest sum of weights, i.e.
						// for each node that meets all of the scheduling requirements (resource
						// request, requiredDuringScheduling anti-affinity expressions, etc.),
						// compute a sum by iterating through the elements of this field and adding
						// "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the
						// node(s) with the highest sum are the most preferred.
						PreferredDuringSchedulingIgnoredDuringExecution *[]struct {
							// PodAffinityTerm Required. A pod affinity term, associated with the corresponding weight.
							PodAffinityTerm struct {
								// LabelSelector A label query over a set of resources, in this case pods.
								// If it's null, this PodAffinityTerm matches with no Pods.
								LabelSelector *struct {
									// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
									MatchExpressions *[]struct {
										// Key key is the label key that the selector applies to.
										Key string `json:"key"`

										// Operator operator represents a key's relationship to a set of values.
										// Valid operators are In, NotIn, Exists and DoesNotExist.
										Operator string `json:"operator"`

										// Values values is an array of string values. If the operator is In or NotIn,
										// the values array must be non-empty. If the operator is Exists or DoesNotExist,
										// the values array must be empty. This array is replaced during a strategic
										// merge patch.
										Values *[]string `json:"values,omitempty"`
									} `json:"matchExpressions,omitempty"`

									// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
									// map is equivalent to an element of matchExpressions, whose key field is "key", the
									// operator is "In", and the values array contains only "value". The requirements are ANDed.
									MatchLabels *map[string]string `json:"matchLabels,omitempty"`
								} `json:"labelSelector,omitempty"`

								// MatchLabelKeys MatchLabelKeys is a set of pod label keys to select which pods will
								// be taken into consideration. The keys are used to lookup values from the
								// incoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`
								// to select the group of existing pods which pods will be taken into consideration
								// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
								// pod labels will be ignored. The default value is empty.
								// The same key is forbidden to exist in both matchLabelKeys and labelSelector.
								// Also, matchLabelKeys cannot be set when labelSelector isn't set.
								MatchLabelKeys *[]string `json:"matchLabelKeys,omitempty"`

								// MismatchLabelKeys MismatchLabelKeys is a set of pod label keys to select which pods will
								// be taken into consideration. The keys are used to lookup values from the
								// incoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`
								// to select the group of existing pods which pods will be taken into consideration
								// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
								// pod labels will be ignored. The default value is empty.
								// The same key is forbidden to exist in both mismatchLabelKeys and labelSelector.
								// Also, mismatchLabelKeys cannot be set when labelSelector isn't set.
								MismatchLabelKeys *[]string `json:"mismatchLabelKeys,omitempty"`

								// NamespaceSelector A label query over the set of namespaces that the term applies to.
								// The term is applied to the union of the namespaces selected by this field
								// and the ones listed in the namespaces field.
								// null selector and null or empty namespaces list means "this pod's namespace".
								// An empty selector ({}) matches all namespaces.
								NamespaceSelector *struct {
									// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
									MatchExpressions *[]struct {
										// Key key is the label key that the selector applies to.
										Key string `json:"key"`

										// Operator operator represents a key's relationship to a set of values.
										// Valid operators are In, NotIn, Exists and DoesNotExist.
										Operator string `json:"operator"`

										// Values values is an array of string values. If the operator is In or NotIn,
										// the values array must be non-empty. If the operator is Exists or DoesNotExist,
										// the values array must be empty. This array is replaced during a strategic
										// merge patch.
										Values *[]string `json:"values,omitempty"`
									} `json:"matchExpressions,omitempty"`

									// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
									// map is equivalent to an element of matchExpressions, whose key field is "key", the
									// operator is "In", and the values array contains only "value". The requirements are ANDed.
									MatchLabels *map[string]string `json:"matchLabels,omitempty"`
								} `json:"namespaceSelector,omitempty"`

								// Namespaces namespaces specifies a static list of namespace names that the term applies to.
								// The term is applied to the union of the namespaces listed in this field
								// and the ones selected by namespaceSelector.
								// null or empty namespaces list and null namespaceSelector means "this pod's namespace".
								Namespaces *[]string `json:"namespaces,omitempty"`

								// TopologyKey This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
								// the labelSelector in the specified namespaces, where co-located is defined as running on a node
								// whose value of the label with key topologyKey matches that of any node on which any of the
								// selected pods is running.
								// Empty topologyKey is not allowed.
								TopologyKey string `json:"topologyKey"`
							} `json:"podAffinityTerm"`

							// Weight weight associated with matching the corresponding podAffinityTerm,
							// in the range 1-100.
							Weight int32 `json:"weight"`
						} `json:"preferredDuringSchedulingIgnoredDuringExecution,omitempty"`

						// RequiredDuringSchedulingIgnoredDuringExecution If the anti-affinity requirements specified by this field are not met at
						// scheduling time, the pod will not be scheduled onto the node.
						// If the anti-affinity requirements specified by this field cease to be met
						// at some point during pod execution (e.g. due to a pod label update), the
						// system may or may not try to eventually evict the pod from its node.
						// When there are multiple elements, the lists of nodes corresponding to each
						// podAffinityTerm are intersected, i.e. all terms must be satisfied.
						RequiredDuringSchedulingIgnoredDuringExecution *[]struct {
							// LabelSelector A label query over a set of resources, in this case pods.
							// If it's null, this PodAffinityTerm matches with no Pods.
							LabelSelector *struct {
								// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
								MatchExpressions *[]struct {
									// Key key is the label key that the selector applies to.
									Key string `json:"key"`

									// Operator operator represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists and DoesNotExist.
									Operator string `json:"operator"`

									// Values values is an array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. This array is replaced during a strategic
									// merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
								// map is equivalent to an element of matchExpressions, whose key field is "key", the
								// operator is "In", and the values array contains only "value". The requirements are ANDed.
								MatchLabels *map[string]string `json:"matchLabels,omitempty"`
							} `json:"labelSelector,omitempty"`

							// MatchLabelKeys MatchLabelKeys is a set of pod label keys to select which pods will
							// be taken into consideration. The keys are used to lookup values from the
							// incoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`
							// to select the group of existing pods which pods will be taken into consideration
							// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
							// pod labels will be ignored. The default value is empty.
							// The same key is forbidden to exist in both matchLabelKeys and labelSelector.
							// Also, matchLabelKeys cannot be set when labelSelector isn't set.
							MatchLabelKeys *[]string `json:"matchLabelKeys,omitempty"`

							// MismatchLabelKeys MismatchLabelKeys is a set of pod label keys to select which pods will
							// be taken into consideration. The keys are used to lookup values from the
							// incoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`
							// to select the group of existing pods which pods will be taken into consideration
							// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
							// pod labels will be ignored. The default value is empty.
							// The same key is forbidden to exist in both mismatchLabelKeys and labelSelector.
							// Also, mismatchLabelKeys cannot be set when labelSelector isn't set.
							MismatchLabelKeys *[]string `json:"mismatchLabelKeys,omitempty"`

							// NamespaceSelector A label query over the set of namespaces that the term applies to.
							// The term is applied to the union of the namespaces selected by this field
							// and the ones listed in the namespaces field.
							// null selector and null or empty namespaces list means "this pod's namespace".
							// An empty selector ({}) matches all namespaces.
							NamespaceSelector *struct {
								// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
								MatchExpressions *[]struct {
									// Key key is the label key that the selector applies to.
									Key string `json:"key"`

									// Operator operator represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists and DoesNotExist.
									Operator string `json:"operator"`

									// Values values is an array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. This array is replaced during a strategic
									// merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
								// map is equivalent to an element of matchExpressions, whose key field is "key", the
								// operator is "In", and the values array contains only "value". The requirements are ANDed.
								MatchLabels *map[string]string `json:"matchLabels,omitempty"`
							} `json:"namespaceSelector,omitempty"`

							// Namespaces namespaces specifies a static list of namespace names that the term applies to.
							// The term is applied to the union of the namespaces listed in this field
							// and the ones selected by namespaceSelector.
							// null or empty namespaces list and null namespaceSelector means "this pod's namespace".
							Namespaces *[]string `json:"namespaces,omitempty"`

							// TopologyKey This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
							// the labelSelector in the specified namespaces, where co-located is defined as running on a node
							// whose value of the label with key topologyKey matches that of any node on which any of the
							// selected pods is running.
							// Empty topologyKey is not allowed.
							TopologyKey string `json:"topologyKey"`
						} `json:"requiredDuringSchedulingIgnoredDuringExecution,omitempty"`
					} `json:"podAntiAffinity,omitempty"`
				} `json:"engine,omitempty"`

				// Proxy Proxy is the affinity configuration for the DB Proxy pods.
				Proxy *struct {
					// NodeAffinity Describes node affinity scheduling rules for the pod.
					NodeAffinity *struct {
						// PreferredDuringSchedulingIgnoredDuringExecution The scheduler will prefer to schedule pods to nodes that satisfy
						// the affinity expressions specified by this field, but it may choose
						// a node that violates one or more of the expressions. The node that is
						// most preferred is the one with the greatest sum of weights, i.e.
						// for each node that meets all of the scheduling requirements (resource
						// request, requiredDuringScheduling affinity expressions, etc.),
						// compute a sum by iterating through the elements of this field and adding
						// "weight" to the sum if the node matches the corresponding matchExpressions; the
						// node(s) with the highest sum are the most preferred.
						PreferredDuringSchedulingIgnoredDuringExecution *[]struct {
							// Preference A node selector term, associated with the corresponding weight.
							Preference struct {
								// MatchExpressions A list of node selector requirements by node's labels.
								MatchExpressions *[]struct {
									// Key The label key that the selector applies to.
									Key string `json:"key"`

									// Operator Represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
									Operator string `json:"operator"`

									// Values An array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. If the operator is Gt or Lt, the values
									// array must have a single element, which will be interpreted as an integer.
									// This array is replaced during a strategic merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchFields A list of node selector requirements by node's fields.
								MatchFields *[]struct {
									// Key The label key that the selector applies to.
									Key string `json:"key"`

									// Operator Represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
									Operator string `json:"operator"`

									// Values An array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. If the operator is Gt or Lt, the values
									// array must have a single element, which will be interpreted as an integer.
									// This array is replaced during a strategic merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchFields,omitempty"`
							} `json:"preference"`

							// Weight Weight associated with matching the corresponding nodeSelectorTerm, in the range 1-100.
							Weight int32 `json:"weight"`
						} `json:"preferredDuringSchedulingIgnoredDuringExecution,omitempty"`

						// RequiredDuringSchedulingIgnoredDuringExecution If the affinity requirements specified by this field are not met at
						// scheduling time, the pod will not be scheduled onto the node.
						// If the affinity requirements specified by this field cease to be met
						// at some point during pod execution (e.g. due to an update), the system
						// may or may not try to eventually evict the pod from its node.
						RequiredDuringSchedulingIgnoredDuringExecution *struct {
							// NodeSelectorTerms Required. A list of node selector terms. The terms are ORed.
							NodeSelectorTerms []struct {
								// MatchExpressions A list of node selector requirements by node's labels.
								MatchExpressions *[]struct {
									// Key The label key that the selector applies to.
									Key string `json:"key"`

									// Operator Represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
									Operator string `json:"operator"`

									// Values An array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. If the operator is Gt or Lt, the values
									// array must have a single element, which will be interpreted as an integer.
									// This array is replaced during a strategic merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchFields A list of node selector requirements by node's fields.
								MatchFields *[]struct {
									// Key The label key that the selector applies to.
									Key string `json:"key"`

									// Operator Represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
									Operator string `json:"operator"`

									// Values An array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. If the operator is Gt or Lt, the values
									// array must have a single element, which will be interpreted as an integer.
									// This array is replaced during a strategic merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchFields,omitempty"`
							} `json:"nodeSelectorTerms"`
						} `json:"requiredDuringSchedulingIgnoredDuringExecution,omitempty"`
					} `json:"nodeAffinity,omitempty"`

					// PodAffinity Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
					PodAffinity *struct {
						// PreferredDuringSchedulingIgnoredDuringExecution The scheduler will prefer to schedule pods to nodes that satisfy
						// the affinity expressions specified by this field, but it may choose
						// a node that violates one or more of the expressions. The node that is
						// most preferred is the one with the greatest sum of weights, i.e.
						// for each node that meets all of the scheduling requirements (resource
						// request, requiredDuringScheduling affinity expressions, etc.),
						// compute a sum by iterating through the elements of this field and adding
						// "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the
						// node(s) with the highest sum are the most preferred.
						PreferredDuringSchedulingIgnoredDuringExecution *[]struct {
							// PodAffinityTerm Required. A pod affinity term, associated with the corresponding weight.
							PodAffinityTerm struct {
								// LabelSelector A label query over a set of resources, in this case pods.
								// If it's null, this PodAffinityTerm matches with no Pods.
								LabelSelector *struct {
									// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
									MatchExpressions *[]struct {
										// Key key is the label key that the selector applies to.
										Key string `json:"key"`

										// Operator operator represents a key's relationship to a set of values.
										// Valid operators are In, NotIn, Exists and DoesNotExist.
										Operator string `json:"operator"`

										// Values values is an array of string values. If the operator is In or NotIn,
										// the values array must be non-empty. If the operator is Exists or DoesNotExist,
										// the values array must be empty. This array is replaced during a strategic
										// merge patch.
										Values *[]string `json:"values,omitempty"`
									} `json:"matchExpressions,omitempty"`

									// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
									// map is equivalent to an element of matchExpressions, whose key field is "key", the
									// operator is "In", and the values array contains only "value". The requirements are ANDed.
									MatchLabels *map[string]string `json:"matchLabels,omitempty"`
								} `json:"labelSelector,omitempty"`

								// MatchLabelKeys MatchLabelKeys is a set of pod label keys to select which pods will
								// be taken into consideration. The keys are used to lookup values from the
								// incoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`
								// to select the group of existing pods which pods will be taken into consideration
								// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
								// pod labels will be ignored. The default value is empty.
								// The same key is forbidden to exist in both matchLabelKeys and labelSelector.
								// Also, matchLabelKeys cannot be set when labelSelector isn't set.
								MatchLabelKeys *[]string `json:"matchLabelKeys,omitempty"`

								// MismatchLabelKeys MismatchLabelKeys is a set of pod label keys to select which pods will
								// be taken into consideration. The keys are used to lookup values from the
								// incoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`
								// to select the group of existing pods which pods will be taken into consideration
								// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
								// pod labels will be ignored. The default value is empty.
								// The same key is forbidden to exist in both mismatchLabelKeys and labelSelector.
								// Also, mismatchLabelKeys cannot be set when labelSelector isn't set.
								MismatchLabelKeys *[]string `json:"mismatchLabelKeys,omitempty"`

								// NamespaceSelector A label query over the set of namespaces that the term applies to.
								// The term is applied to the union of the namespaces selected by this field
								// and the ones listed in the namespaces field.
								// null selector and null or empty namespaces list means "this pod's namespace".
								// An empty selector ({}) matches all namespaces.
								NamespaceSelector *struct {
									// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
									MatchExpressions *[]struct {
										// Key key is the label key that the selector applies to.
										Key string `json:"key"`

										// Operator operator represents a key's relationship to a set of values.
										// Valid operators are In, NotIn, Exists and DoesNotExist.
										Operator string `json:"operator"`

										// Values values is an array of string values. If the operator is In or NotIn,
										// the values array must be non-empty. If the operator is Exists or DoesNotExist,
										// the values array must be empty. This array is replaced during a strategic
										// merge patch.
										Values *[]string `json:"values,omitempty"`
									} `json:"matchExpressions,omitempty"`

									// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
									// map is equivalent to an element of matchExpressions, whose key field is "key", the
									// operator is "In", and the values array contains only "value". The requirements are ANDed.
									MatchLabels *map[string]string `json:"matchLabels,omitempty"`
								} `json:"namespaceSelector,omitempty"`

								// Namespaces namespaces specifies a static list of namespace names that the term applies to.
								// The term is applied to the union of the namespaces listed in this field
								// and the ones selected by namespaceSelector.
								// null or empty namespaces list and null namespaceSelector means "this pod's namespace".
								Namespaces *[]string `json:"namespaces,omitempty"`

								// TopologyKey This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
								// the labelSelector in the specified namespaces, where co-located is defined as running on a node
								// whose value of the label with key topologyKey matches that of any node on which any of the
								// selected pods is running.
								// Empty topologyKey is not allowed.
								TopologyKey string `json:"topologyKey"`
							} `json:"podAffinityTerm"`

							// Weight weight associated with matching the corresponding podAffinityTerm,
							// in the range 1-100.
							Weight int32 `json:"weight"`
						} `json:"preferredDuringSchedulingIgnoredDuringExecution,omitempty"`

						// RequiredDuringSchedulingIgnoredDuringExecution If the affinity requirements specified by this field are not met at
						// scheduling time, the pod will not be scheduled onto the node.
						// If the affinity requirements specified by this field cease to be met
						// at some point during pod execution (e.g. due to a pod label update), the
						// system may or may not try to eventually evict the pod from its node.
						// When there are multiple elements, the lists of nodes corresponding to each
						// podAffinityTerm are intersected, i.e. all terms must be satisfied.
						RequiredDuringSchedulingIgnoredDuringExecution *[]struct {
							// LabelSelector A label query over a set of resources, in this case pods.
							// If it's null, this PodAffinityTerm matches with no Pods.
							LabelSelector *struct {
								// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
								MatchExpressions *[]struct {
									// Key key is the label key that the selector applies to.
									Key string `json:"key"`

									// Operator operator represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists and DoesNotExist.
									Operator string `json:"operator"`

									// Values values is an array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. This array is replaced during a strategic
									// merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
								// map is equivalent to an element of matchExpressions, whose key field is "key", the
								// operator is "In", and the values array contains only "value". The requirements are ANDed.
								MatchLabels *map[string]string `json:"matchLabels,omitempty"`
							} `json:"labelSelector,omitempty"`

							// MatchLabelKeys MatchLabelKeys is a set of pod label keys to select which pods will
							// be taken into consideration. The keys are used to lookup values from the
							// incoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`
							// to select the group of existing pods which pods will be taken into consideration
							// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
							// pod labels will be ignored. The default value is empty.
							// The same key is forbidden to exist in both matchLabelKeys and labelSelector.
							// Also, matchLabelKeys cannot be set when labelSelector isn't set.
							MatchLabelKeys *[]string `json:"matchLabelKeys,omitempty"`

							// MismatchLabelKeys MismatchLabelKeys is a set of pod label keys to select which pods will
							// be taken into consideration. The keys are used to lookup values from the
							// incoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`
							// to select the group of existing pods which pods will be taken into consideration
							// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
							// pod labels will be ignored. The default value is empty.
							// The same key is forbidden to exist in both mismatchLabelKeys and labelSelector.
							// Also, mismatchLabelKeys cannot be set when labelSelector isn't set.
							MismatchLabelKeys *[]string `json:"mismatchLabelKeys,omitempty"`

							// NamespaceSelector A label query over the set of namespaces that the term applies to.
							// The term is applied to the union of the namespaces selected by this field
							// and the ones listed in the namespaces field.
							// null selector and null or empty namespaces list means "this pod's namespace".
							// An empty selector ({}) matches all namespaces.
							NamespaceSelector *struct {
								// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
								MatchExpressions *[]struct {
									// Key key is the label key that the selector applies to.
									Key string `json:"key"`

									// Operator operator represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists and DoesNotExist.
									Operator string `json:"operator"`

									// Values values is an array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. This array is replaced during a strategic
									// merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
								// map is equivalent to an element of matchExpressions, whose key field is "key", the
								// operator is "In", and the values array contains only "value". The requirements are ANDed.
								MatchLabels *map[string]string `json:"matchLabels,omitempty"`
							} `json:"namespaceSelector,omitempty"`

							// Namespaces namespaces specifies a static list of namespace names that the term applies to.
							// The term is applied to the union of the namespaces listed in this field
							// and the ones selected by namespaceSelector.
							// null or empty namespaces list and null namespaceSelector means "this pod's namespace".
							Namespaces *[]string `json:"namespaces,omitempty"`

							// TopologyKey This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
							// the labelSelector in the specified namespaces, where co-located is defined as running on a node
							// whose value of the label with key topologyKey matches that of any node on which any of the
							// selected pods is running.
							// Empty topologyKey is not allowed.
							TopologyKey string `json:"topologyKey"`
						} `json:"requiredDuringSchedulingIgnoredDuringExecution,omitempty"`
					} `json:"podAffinity,omitempty"`

					// PodAntiAffinity Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
					PodAntiAffinity *struct {
						// PreferredDuringSchedulingIgnoredDuringExecution The scheduler will prefer to schedule pods to nodes that satisfy
						// the anti-affinity expressions specified by this field, but it may choose
						// a node that violates one or more of the expressions. The node that is
						// most preferred is the one with the greatest sum of weights, i.e.
						// for each node that meets all of the scheduling requirements (resource
						// request, requiredDuringScheduling anti-affinity expressions, etc.),
						// compute a sum by iterating through the elements of this field and adding
						// "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the
						// node(s) with the highest sum are the most preferred.
						PreferredDuringSchedulingIgnoredDuringExecution *[]struct {
							// PodAffinityTerm Required. A pod affinity term, associated with the corresponding weight.
							PodAffinityTerm struct {
								// LabelSelector A label query over a set of resources, in this case pods.
								// If it's null, this PodAffinityTerm matches with no Pods.
								LabelSelector *struct {
									// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
									MatchExpressions *[]struct {
										// Key key is the label key that the selector applies to.
										Key string `json:"key"`

										// Operator operator represents a key's relationship to a set of values.
										// Valid operators are In, NotIn, Exists and DoesNotExist.
										Operator string `json:"operator"`

										// Values values is an array of string values. If the operator is In or NotIn,
										// the values array must be non-empty. If the operator is Exists or DoesNotExist,
										// the values array must be empty. This array is replaced during a strategic
										// merge patch.
										Values *[]string `json:"values,omitempty"`
									} `json:"matchExpressions,omitempty"`

									// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
									// map is equivalent to an element of matchExpressions, whose key field is "key", the
									// operator is "In", and the values array contains only "value". The requirements are ANDed.
									MatchLabels *map[string]string `json:"matchLabels,omitempty"`
								} `json:"labelSelector,omitempty"`

								// MatchLabelKeys MatchLabelKeys is a set of pod label keys to select which pods will
								// be taken into consideration. The keys are used to lookup values from the
								// incoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`
								// to select the group of existing pods which pods will be taken into consideration
								// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
								// pod labels will be ignored. The default value is empty.
								// The same key is forbidden to exist in both matchLabelKeys and labelSelector.
								// Also, matchLabelKeys cannot be set when labelSelector isn't set.
								MatchLabelKeys *[]string `json:"matchLabelKeys,omitempty"`

								// MismatchLabelKeys MismatchLabelKeys is a set of pod label keys to select which pods will
								// be taken into consideration. The keys are used to lookup values from the
								// incoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`
								// to select the group of existing pods which pods will be taken into consideration
								// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
								// pod labels will be ignored. The default value is empty.
								// The same key is forbidden to exist in both mismatchLabelKeys and labelSelector.
								// Also, mismatchLabelKeys cannot be set when labelSelector isn't set.
								MismatchLabelKeys *[]string `json:"mismatchLabelKeys,omitempty"`

								// NamespaceSelector A label query over the set of namespaces that the term applies to.
								// The term is applied to the union of the namespaces selected by this field
								// and the ones listed in the namespaces field.
								// null selector and null or empty namespaces list means "this pod's namespace".
								// An empty selector ({}) matches all namespaces.
								NamespaceSelector *struct {
									// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
									MatchExpressions *[]struct {
										// Key key is the label key that the selector applies to.
										Key string `json:"key"`

										// Operator operator represents a key's relationship to a set of values.
										// Valid operators are In, NotIn, Exists and DoesNotExist.
										Operator string `json:"operator"`

										// Values values is an array of string values. If the operator is In or NotIn,
										// the values array must be non-empty. If the operator is Exists or DoesNotExist,
										// the values array must be empty. This array is replaced during a strategic
										// merge patch.
										Values *[]string `json:"values,omitempty"`
									} `json:"matchExpressions,omitempty"`

									// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
									// map is equivalent to an element of matchExpressions, whose key field is "key", the
									// operator is "In", and the values array contains only "value". The requirements are ANDed.
									MatchLabels *map[string]string `json:"matchLabels,omitempty"`
								} `json:"namespaceSelector,omitempty"`

								// Namespaces namespaces specifies a static list of namespace names that the term applies to.
								// The term is applied to the union of the namespaces listed in this field
								// and the ones selected by namespaceSelector.
								// null or empty namespaces list and null namespaceSelector means "this pod's namespace".
								Namespaces *[]string `json:"namespaces,omitempty"`

								// TopologyKey This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
								// the labelSelector in the specified namespaces, where co-located is defined as running on a node
								// whose value of the label with key topologyKey matches that of any node on which any of the
								// selected pods is running.
								// Empty topologyKey is not allowed.
								TopologyKey string `json:"topologyKey"`
							} `json:"podAffinityTerm"`

							// Weight weight associated with matching the corresponding podAffinityTerm,
							// in the range 1-100.
							Weight int32 `json:"weight"`
						} `json:"preferredDuringSchedulingIgnoredDuringExecution,omitempty"`

						// RequiredDuringSchedulingIgnoredDuringExecution If the anti-affinity requirements specified by this field are not met at
						// scheduling time, the pod will not be scheduled onto the node.
						// If the anti-affinity requirements specified by this field cease to be met
						// at some point during pod execution (e.g. due to a pod label update), the
						// system may or may not try to eventually evict the pod from its node.
						// When there are multiple elements, the lists of nodes corresponding to each
						// podAffinityTerm are intersected, i.e. all terms must be satisfied.
						RequiredDuringSchedulingIgnoredDuringExecution *[]struct {
							// LabelSelector A label query over a set of resources, in this case pods.
							// If it's null, this PodAffinityTerm matches with no Pods.
							LabelSelector *struct {
								// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
								MatchExpressions *[]struct {
									// Key key is the label key that the selector applies to.
									Key string `json:"key"`

									// Operator operator represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists and DoesNotExist.
									Operator string `json:"operator"`

									// Values values is an array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. This array is replaced during a strategic
									// merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
								// map is equivalent to an element of matchExpressions, whose key field is "key", the
								// operator is "In", and the values array contains only "value". The requirements are ANDed.
								MatchLabels *map[string]string `json:"matchLabels,omitempty"`
							} `json:"labelSelector,omitempty"`

							// MatchLabelKeys MatchLabelKeys is a set of pod label keys to select which pods will
							// be taken into consideration. The keys are used to lookup values from the
							// incoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`
							// to select the group of existing pods which pods will be taken into consideration
							// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
							// pod labels will be ignored. The default value is empty.
							// The same key is forbidden to exist in both matchLabelKeys and labelSelector.
							// Also, matchLabelKeys cannot be set when labelSelector isn't set.
							MatchLabelKeys *[]string `json:"matchLabelKeys,omitempty"`

							// MismatchLabelKeys MismatchLabelKeys is a set of pod label keys to select which pods will
							// be taken into consideration. The keys are used to lookup values from the
							// incoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`
							// to select the group of existing pods which pods will be taken into consideration
							// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
							// pod labels will be ignored. The default value is empty.
							// The same key is forbidden to exist in both mismatchLabelKeys and labelSelector.
							// Also, mismatchLabelKeys cannot be set when labelSelector isn't set.
							MismatchLabelKeys *[]string `json:"mismatchLabelKeys,omitempty"`

							// NamespaceSelector A label query over the set of namespaces that the term applies to.
							// The term is applied to the union of the namespaces selected by this field
							// and the ones listed in the namespaces field.
							// null selector and null or empty namespaces list means "this pod's namespace".
							// An empty selector ({}) matches all namespaces.
							NamespaceSelector *struct {
								// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
								MatchExpressions *[]struct {
									// Key key is the label key that the selector applies to.
									Key string `json:"key"`

									// Operator operator represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists and DoesNotExist.
									Operator string `json:"operator"`

									// Values values is an array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. This array is replaced during a strategic
									// merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
								// map is equivalent to an element of matchExpressions, whose key field is "key", the
								// operator is "In", and the values array contains only "value". The requirements are ANDed.
								MatchLabels *map[string]string `json:"matchLabels,omitempty"`
							} `json:"namespaceSelector,omitempty"`

							// Namespaces namespaces specifies a static list of namespace names that the term applies to.
							// The term is applied to the union of the namespaces listed in this field
							// and the ones selected by namespaceSelector.
							// null or empty namespaces list and null namespaceSelector means "this pod's namespace".
							Namespaces *[]string `json:"namespaces,omitempty"`

							// TopologyKey This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
							// the labelSelector in the specified namespaces, where co-located is defined as running on a node
							// whose value of the label with key topologyKey matches that of any node on which any of the
							// selected pods is running.
							// Empty topologyKey is not allowed.
							TopologyKey string `json:"topologyKey"`
						} `json:"requiredDuringSchedulingIgnoredDuringExecution,omitempty"`
					} `json:"podAntiAffinity,omitempty"`
				} `json:"proxy,omitempty"`
			} `json:"psmdb,omitempty"`

			// Pxc PXC is the affinity configuration for the PXC DB clusters.
			Pxc *struct {
				// Engine Engine is the affinity configuration for the DB Engine pods.
				Engine *struct {
					// NodeAffinity Describes node affinity scheduling rules for the pod.
					NodeAffinity *struct {
						// PreferredDuringSchedulingIgnoredDuringExecution The scheduler will prefer to schedule pods to nodes that satisfy
						// the affinity expressions specified by this field, but it may choose
						// a node that violates one or more of the expressions. The node that is
						// most preferred is the one with the greatest sum of weights, i.e.
						// for each node that meets all of the scheduling requirements (resource
						// request, requiredDuringScheduling affinity expressions, etc.),
						// compute a sum by iterating through the elements of this field and adding
						// "weight" to the sum if the node matches the corresponding matchExpressions; the
						// node(s) with the highest sum are the most preferred.
						PreferredDuringSchedulingIgnoredDuringExecution *[]struct {
							// Preference A node selector term, associated with the corresponding weight.
							Preference struct {
								// MatchExpressions A list of node selector requirements by node's labels.
								MatchExpressions *[]struct {
									// Key The label key that the selector applies to.
									Key string `json:"key"`

									// Operator Represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
									Operator string `json:"operator"`

									// Values An array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. If the operator is Gt or Lt, the values
									// array must have a single element, which will be interpreted as an integer.
									// This array is replaced during a strategic merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchFields A list of node selector requirements by node's fields.
								MatchFields *[]struct {
									// Key The label key that the selector applies to.
									Key string `json:"key"`

									// Operator Represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
									Operator string `json:"operator"`

									// Values An array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. If the operator is Gt or Lt, the values
									// array must have a single element, which will be interpreted as an integer.
									// This array is replaced during a strategic merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchFields,omitempty"`
							} `json:"preference"`

							// Weight Weight associated with matching the corresponding nodeSelectorTerm, in the range 1-100.
							Weight int32 `json:"weight"`
						} `json:"preferredDuringSchedulingIgnoredDuringExecution,omitempty"`

						// RequiredDuringSchedulingIgnoredDuringExecution If the affinity requirements specified by this field are not met at
						// scheduling time, the pod will not be scheduled onto the node.
						// If the affinity requirements specified by this field cease to be met
						// at some point during pod execution (e.g. due to an update), the system
						// may or may not try to eventually evict the pod from its node.
						RequiredDuringSchedulingIgnoredDuringExecution *struct {
							// NodeSelectorTerms Required. A list of node selector terms. The terms are ORed.
							NodeSelectorTerms []struct {
								// MatchExpressions A list of node selector requirements by node's labels.
								MatchExpressions *[]struct {
									// Key The label key that the selector applies to.
									Key string `json:"key"`

									// Operator Represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
									Operator string `json:"operator"`

									// Values An array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. If the operator is Gt or Lt, the values
									// array must have a single element, which will be interpreted as an integer.
									// This array is replaced during a strategic merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchFields A list of node selector requirements by node's fields.
								MatchFields *[]struct {
									// Key The label key that the selector applies to.
									Key string `json:"key"`

									// Operator Represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
									Operator string `json:"operator"`

									// Values An array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. If the operator is Gt or Lt, the values
									// array must have a single element, which will be interpreted as an integer.
									// This array is replaced during a strategic merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchFields,omitempty"`
							} `json:"nodeSelectorTerms"`
						} `json:"requiredDuringSchedulingIgnoredDuringExecution,omitempty"`
					} `json:"nodeAffinity,omitempty"`

					// PodAffinity Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
					PodAffinity *struct {
						// PreferredDuringSchedulingIgnoredDuringExecution The scheduler will prefer to schedule pods to nodes that satisfy
						// the affinity expressions specified by this field, but it may choose
						// a node that violates one or more of the expressions. The node that is
						// most preferred is the one with the greatest sum of weights, i.e.
						// for each node that meets all of the scheduling requirements (resource
						// request, requiredDuringScheduling affinity expressions, etc.),
						// compute a sum by iterating through the elements of this field and adding
						// "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the
						// node(s) with the highest sum are the most preferred.
						PreferredDuringSchedulingIgnoredDuringExecution *[]struct {
							// PodAffinityTerm Required. A pod affinity term, associated with the corresponding weight.
							PodAffinityTerm struct {
								// LabelSelector A label query over a set of resources, in this case pods.
								// If it's null, this PodAffinityTerm matches with no Pods.
								LabelSelector *struct {
									// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
									MatchExpressions *[]struct {
										// Key key is the label key that the selector applies to.
										Key string `json:"key"`

										// Operator operator represents a key's relationship to a set of values.
										// Valid operators are In, NotIn, Exists and DoesNotExist.
										Operator string `json:"operator"`

										// Values values is an array of string values. If the operator is In or NotIn,
										// the values array must be non-empty. If the operator is Exists or DoesNotExist,
										// the values array must be empty. This array is replaced during a strategic
										// merge patch.
										Values *[]string `json:"values,omitempty"`
									} `json:"matchExpressions,omitempty"`

									// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
									// map is equivalent to an element of matchExpressions, whose key field is "key", the
									// operator is "In", and the values array contains only "value". The requirements are ANDed.
									MatchLabels *map[string]string `json:"matchLabels,omitempty"`
								} `json:"labelSelector,omitempty"`

								// MatchLabelKeys MatchLabelKeys is a set of pod label keys to select which pods will
								// be taken into consideration. The keys are used to lookup values from the
								// incoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`
								// to select the group of existing pods which pods will be taken into consideration
								// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
								// pod labels will be ignored. The default value is empty.
								// The same key is forbidden to exist in both matchLabelKeys and labelSelector.
								// Also, matchLabelKeys cannot be set when labelSelector isn't set.
								MatchLabelKeys *[]string `json:"matchLabelKeys,omitempty"`

								// MismatchLabelKeys MismatchLabelKeys is a set of pod label keys to select which pods will
								// be taken into consideration. The keys are used to lookup values from the
								// incoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`
								// to select the group of existing pods which pods will be taken into consideration
								// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
								// pod labels will be ignored. The default value is empty.
								// The same key is forbidden to exist in both mismatchLabelKeys and labelSelector.
								// Also, mismatchLabelKeys cannot be set when labelSelector isn't set.
								MismatchLabelKeys *[]string `json:"mismatchLabelKeys,omitempty"`

								// NamespaceSelector A label query over the set of namespaces that the term applies to.
								// The term is applied to the union of the namespaces selected by this field
								// and the ones listed in the namespaces field.
								// null selector and null or empty namespaces list means "this pod's namespace".
								// An empty selector ({}) matches all namespaces.
								NamespaceSelector *struct {
									// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
									MatchExpressions *[]struct {
										// Key key is the label key that the selector applies to.
										Key string `json:"key"`

										// Operator operator represents a key's relationship to a set of values.
										// Valid operators are In, NotIn, Exists and DoesNotExist.
										Operator string `json:"operator"`

										// Values values is an array of string values. If the operator is In or NotIn,
										// the values array must be non-empty. If the operator is Exists or DoesNotExist,
										// the values array must be empty. This array is replaced during a strategic
										// merge patch.
										Values *[]string `json:"values,omitempty"`
									} `json:"matchExpressions,omitempty"`

									// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
									// map is equivalent to an element of matchExpressions, whose key field is "key", the
									// operator is "In", and the values array contains only "value". The requirements are ANDed.
									MatchLabels *map[string]string `json:"matchLabels,omitempty"`
								} `json:"namespaceSelector,omitempty"`

								// Namespaces namespaces specifies a static list of namespace names that the term applies to.
								// The term is applied to the union of the namespaces listed in this field
								// and the ones selected by namespaceSelector.
								// null or empty namespaces list and null namespaceSelector means "this pod's namespace".
								Namespaces *[]string `json:"namespaces,omitempty"`

								// TopologyKey This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
								// the labelSelector in the specified namespaces, where co-located is defined as running on a node
								// whose value of the label with key topologyKey matches that of any node on which any of the
								// selected pods is running.
								// Empty topologyKey is not allowed.
								TopologyKey string `json:"topologyKey"`
							} `json:"podAffinityTerm"`

							// Weight weight associated with matching the corresponding podAffinityTerm,
							// in the range 1-100.
							Weight int32 `json:"weight"`
						} `json:"preferredDuringSchedulingIgnoredDuringExecution,omitempty"`

						// RequiredDuringSchedulingIgnoredDuringExecution If the affinity requirements specified by this field are not met at
						// scheduling time, the pod will not be scheduled onto the node.
						// If the affinity requirements specified by this field cease to be met
						// at some point during pod execution (e.g. due to a pod label update), the
						// system may or may not try to eventually evict the pod from its node.
						// When there are multiple elements, the lists of nodes corresponding to each
						// podAffinityTerm are intersected, i.e. all terms must be satisfied.
						RequiredDuringSchedulingIgnoredDuringExecution *[]struct {
							// LabelSelector A label query over a set of resources, in this case pods.
							// If it's null, this PodAffinityTerm matches with no Pods.
							LabelSelector *struct {
								// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
								MatchExpressions *[]struct {
									// Key key is the label key that the selector applies to.
									Key string `json:"key"`

									// Operator operator represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists and DoesNotExist.
									Operator string `json:"operator"`

									// Values values is an array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. This array is replaced during a strategic
									// merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
								// map is equivalent to an element of matchExpressions, whose key field is "key", the
								// operator is "In", and the values array contains only "value". The requirements are ANDed.
								MatchLabels *map[string]string `json:"matchLabels,omitempty"`
							} `json:"labelSelector,omitempty"`

							// MatchLabelKeys MatchLabelKeys is a set of pod label keys to select which pods will
							// be taken into consideration. The keys are used to lookup values from the
							// incoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`
							// to select the group of existing pods which pods will be taken into consideration
							// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
							// pod labels will be ignored. The default value is empty.
							// The same key is forbidden to exist in both matchLabelKeys and labelSelector.
							// Also, matchLabelKeys cannot be set when labelSelector isn't set.
							MatchLabelKeys *[]string `json:"matchLabelKeys,omitempty"`

							// MismatchLabelKeys MismatchLabelKeys is a set of pod label keys to select which pods will
							// be taken into consideration. The keys are used to lookup values from the
							// incoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`
							// to select the group of existing pods which pods will be taken into consideration
							// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
							// pod labels will be ignored. The default value is empty.
							// The same key is forbidden to exist in both mismatchLabelKeys and labelSelector.
							// Also, mismatchLabelKeys cannot be set when labelSelector isn't set.
							MismatchLabelKeys *[]string `json:"mismatchLabelKeys,omitempty"`

							// NamespaceSelector A label query over the set of namespaces that the term applies to.
							// The term is applied to the union of the namespaces selected by this field
							// and the ones listed in the namespaces field.
							// null selector and null or empty namespaces list means "this pod's namespace".
							// An empty selector ({}) matches all namespaces.
							NamespaceSelector *struct {
								// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
								MatchExpressions *[]struct {
									// Key key is the label key that the selector applies to.
									Key string `json:"key"`

									// Operator operator represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists and DoesNotExist.
									Operator string `json:"operator"`

									// Values values is an array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. This array is replaced during a strategic
									// merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
								// map is equivalent to an element of matchExpressions, whose key field is "key", the
								// operator is "In", and the values array contains only "value". The requirements are ANDed.
								MatchLabels *map[string]string `json:"matchLabels,omitempty"`
							} `json:"namespaceSelector,omitempty"`

							// Namespaces namespaces specifies a static list of namespace names that the term applies to.
							// The term is applied to the union of the namespaces listed in this field
							// and the ones selected by namespaceSelector.
							// null or empty namespaces list and null namespaceSelector means "this pod's namespace".
							Namespaces *[]string `json:"namespaces,omitempty"`

							// TopologyKey This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
							// the labelSelector in the specified namespaces, where co-located is defined as running on a node
							// whose value of the label with key topologyKey matches that of any node on which any of the
							// selected pods is running.
							// Empty topologyKey is not allowed.
							TopologyKey string `json:"topologyKey"`
						} `json:"requiredDuringSchedulingIgnoredDuringExecution,omitempty"`
					} `json:"podAffinity,omitempty"`

					// PodAntiAffinity Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
					PodAntiAffinity *struct {
						// PreferredDuringSchedulingIgnoredDuringExecution The scheduler will prefer to schedule pods to nodes that satisfy
						// the anti-affinity expressions specified by this field, but it may choose
						// a node that violates one or more of the expressions. The node that is
						// most preferred is the one with the greatest sum of weights, i.e.
						// for each node that meets all of the scheduling requirements (resource
						// request, requiredDuringScheduling anti-affinity expressions, etc.),
						// compute a sum by iterating through the elements of this field and adding
						// "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the
						// node(s) with the highest sum are the most preferred.
						PreferredDuringSchedulingIgnoredDuringExecution *[]struct {
							// PodAffinityTerm Required. A pod affinity term, associated with the corresponding weight.
							PodAffinityTerm struct {
								// LabelSelector A label query over a set of resources, in this case pods.
								// If it's null, this PodAffinityTerm matches with no Pods.
								LabelSelector *struct {
									// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
									MatchExpressions *[]struct {
										// Key key is the label key that the selector applies to.
										Key string `json:"key"`

										// Operator operator represents a key's relationship to a set of values.
										// Valid operators are In, NotIn, Exists and DoesNotExist.
										Operator string `json:"operator"`

										// Values values is an array of string values. If the operator is In or NotIn,
										// the values array must be non-empty. If the operator is Exists or DoesNotExist,
										// the values array must be empty. This array is replaced during a strategic
										// merge patch.
										Values *[]string `json:"values,omitempty"`
									} `json:"matchExpressions,omitempty"`

									// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
									// map is equivalent to an element of matchExpressions, whose key field is "key", the
									// operator is "In", and the values array contains only "value". The requirements are ANDed.
									MatchLabels *map[string]string `json:"matchLabels,omitempty"`
								} `json:"labelSelector,omitempty"`

								// MatchLabelKeys MatchLabelKeys is a set of pod label keys to select which pods will
								// be taken into consideration. The keys are used to lookup values from the
								// incoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`
								// to select the group of existing pods which pods will be taken into consideration
								// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
								// pod labels will be ignored. The default value is empty.
								// The same key is forbidden to exist in both matchLabelKeys and labelSelector.
								// Also, matchLabelKeys cannot be set when labelSelector isn't set.
								MatchLabelKeys *[]string `json:"matchLabelKeys,omitempty"`

								// MismatchLabelKeys MismatchLabelKeys is a set of pod label keys to select which pods will
								// be taken into consideration. The keys are used to lookup values from the
								// incoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`
								// to select the group of existing pods which pods will be taken into consideration
								// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
								// pod labels will be ignored. The default value is empty.
								// The same key is forbidden to exist in both mismatchLabelKeys and labelSelector.
								// Also, mismatchLabelKeys cannot be set when labelSelector isn't set.
								MismatchLabelKeys *[]string `json:"mismatchLabelKeys,omitempty"`

								// NamespaceSelector A label query over the set of namespaces that the term applies to.
								// The term is applied to the union of the namespaces selected by this field
								// and the ones listed in the namespaces field.
								// null selector and null or empty namespaces list means "this pod's namespace".
								// An empty selector ({}) matches all namespaces.
								NamespaceSelector *struct {
									// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
									MatchExpressions *[]struct {
										// Key key is the label key that the selector applies to.
										Key string `json:"key"`

										// Operator operator represents a key's relationship to a set of values.
										// Valid operators are In, NotIn, Exists and DoesNotExist.
										Operator string `json:"operator"`

										// Values values is an array of string values. If the operator is In or NotIn,
										// the values array must be non-empty. If the operator is Exists or DoesNotExist,
										// the values array must be empty. This array is replaced during a strategic
										// merge patch.
										Values *[]string `json:"values,omitempty"`
									} `json:"matchExpressions,omitempty"`

									// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
									// map is equivalent to an element of matchExpressions, whose key field is "key", the
									// operator is "In", and the values array contains only "value". The requirements are ANDed.
									MatchLabels *map[string]string `json:"matchLabels,omitempty"`
								} `json:"namespaceSelector,omitempty"`

								// Namespaces namespaces specifies a static list of namespace names that the term applies to.
								// The term is applied to the union of the namespaces listed in this field
								// and the ones selected by namespaceSelector.
								// null or empty namespaces list and null namespaceSelector means "this pod's namespace".
								Namespaces *[]string `json:"namespaces,omitempty"`

								// TopologyKey This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
								// the labelSelector in the specified namespaces, where co-located is defined as running on a node
								// whose value of the label with key topologyKey matches that of any node on which any of the
								// selected pods is running.
								// Empty topologyKey is not allowed.
								TopologyKey string `json:"topologyKey"`
							} `json:"podAffinityTerm"`

							// Weight weight associated with matching the corresponding podAffinityTerm,
							// in the range 1-100.
							Weight int32 `json:"weight"`
						} `json:"preferredDuringSchedulingIgnoredDuringExecution,omitempty"`

						// RequiredDuringSchedulingIgnoredDuringExecution If the anti-affinity requirements specified by this field are not met at
						// scheduling time, the pod will not be scheduled onto the node.
						// If the anti-affinity requirements specified by this field cease to be met
						// at some point during pod execution (e.g. due to a pod label update), the
						// system may or may not try to eventually evict the pod from its node.
						// When there are multiple elements, the lists of nodes corresponding to each
						// podAffinityTerm are intersected, i.e. all terms must be satisfied.
						RequiredDuringSchedulingIgnoredDuringExecution *[]struct {
							// LabelSelector A label query over a set of resources, in this case pods.
							// If it's null, this PodAffinityTerm matches with no Pods.
							LabelSelector *struct {
								// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
								MatchExpressions *[]struct {
									// Key key is the label key that the selector applies to.
									Key string `json:"key"`

									// Operator operator represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists and DoesNotExist.
									Operator string `json:"operator"`

									// Values values is an array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. This array is replaced during a strategic
									// merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
								// map is equivalent to an element of matchExpressions, whose key field is "key", the
								// operator is "In", and the values array contains only "value". The requirements are ANDed.
								MatchLabels *map[string]string `json:"matchLabels,omitempty"`
							} `json:"labelSelector,omitempty"`

							// MatchLabelKeys MatchLabelKeys is a set of pod label keys to select which pods will
							// be taken into consideration. The keys are used to lookup values from the
							// incoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`
							// to select the group of existing pods which pods will be taken into consideration
							// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
							// pod labels will be ignored. The default value is empty.
							// The same key is forbidden to exist in both matchLabelKeys and labelSelector.
							// Also, matchLabelKeys cannot be set when labelSelector isn't set.
							MatchLabelKeys *[]string `json:"matchLabelKeys,omitempty"`

							// MismatchLabelKeys MismatchLabelKeys is a set of pod label keys to select which pods will
							// be taken into consideration. The keys are used to lookup values from the
							// incoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`
							// to select the group of existing pods which pods will be taken into consideration
							// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
							// pod labels will be ignored. The default value is empty.
							// The same key is forbidden to exist in both mismatchLabelKeys and labelSelector.
							// Also, mismatchLabelKeys cannot be set when labelSelector isn't set.
							MismatchLabelKeys *[]string `json:"mismatchLabelKeys,omitempty"`

							// NamespaceSelector A label query over the set of namespaces that the term applies to.
							// The term is applied to the union of the namespaces selected by this field
							// and the ones listed in the namespaces field.
							// null selector and null or empty namespaces list means "this pod's namespace".
							// An empty selector ({}) matches all namespaces.
							NamespaceSelector *struct {
								// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
								MatchExpressions *[]struct {
									// Key key is the label key that the selector applies to.
									Key string `json:"key"`

									// Operator operator represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists and DoesNotExist.
									Operator string `json:"operator"`

									// Values values is an array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. This array is replaced during a strategic
									// merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
								// map is equivalent to an element of matchExpressions, whose key field is "key", the
								// operator is "In", and the values array contains only "value". The requirements are ANDed.
								MatchLabels *map[string]string `json:"matchLabels,omitempty"`
							} `json:"namespaceSelector,omitempty"`

							// Namespaces namespaces specifies a static list of namespace names that the term applies to.
							// The term is applied to the union of the namespaces listed in this field
							// and the ones selected by namespaceSelector.
							// null or empty namespaces list and null namespaceSelector means "this pod's namespace".
							Namespaces *[]string `json:"namespaces,omitempty"`

							// TopologyKey This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
							// the labelSelector in the specified namespaces, where co-located is defined as running on a node
							// whose value of the label with key topologyKey matches that of any node on which any of the
							// selected pods is running.
							// Empty topologyKey is not allowed.
							TopologyKey string `json:"topologyKey"`
						} `json:"requiredDuringSchedulingIgnoredDuringExecution,omitempty"`
					} `json:"podAntiAffinity,omitempty"`
				} `json:"engine,omitempty"`

				// Proxy Proxy is the affinity configuration for the DB Proxy pods.
				Proxy *struct {
					// NodeAffinity Describes node affinity scheduling rules for the pod.
					NodeAffinity *struct {
						// PreferredDuringSchedulingIgnoredDuringExecution The scheduler will prefer to schedule pods to nodes that satisfy
						// the affinity expressions specified by this field, but it may choose
						// a node that violates one or more of the expressions. The node that is
						// most preferred is the one with the greatest sum of weights, i.e.
						// for each node that meets all of the scheduling requirements (resource
						// request, requiredDuringScheduling affinity expressions, etc.),
						// compute a sum by iterating through the elements of this field and adding
						// "weight" to the sum if the node matches the corresponding matchExpressions; the
						// node(s) with the highest sum are the most preferred.
						PreferredDuringSchedulingIgnoredDuringExecution *[]struct {
							// Preference A node selector term, associated with the corresponding weight.
							Preference struct {
								// MatchExpressions A list of node selector requirements by node's labels.
								MatchExpressions *[]struct {
									// Key The label key that the selector applies to.
									Key string `json:"key"`

									// Operator Represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
									Operator string `json:"operator"`

									// Values An array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. If the operator is Gt or Lt, the values
									// array must have a single element, which will be interpreted as an integer.
									// This array is replaced during a strategic merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchFields A list of node selector requirements by node's fields.
								MatchFields *[]struct {
									// Key The label key that the selector applies to.
									Key string `json:"key"`

									// Operator Represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
									Operator string `json:"operator"`

									// Values An array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. If the operator is Gt or Lt, the values
									// array must have a single element, which will be interpreted as an integer.
									// This array is replaced during a strategic merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchFields,omitempty"`
							} `json:"preference"`

							// Weight Weight associated with matching the corresponding nodeSelectorTerm, in the range 1-100.
							Weight int32 `json:"weight"`
						} `json:"preferredDuringSchedulingIgnoredDuringExecution,omitempty"`

						// RequiredDuringSchedulingIgnoredDuringExecution If the affinity requirements specified by this field are not met at
						// scheduling time, the pod will not be scheduled onto the node.
						// If the affinity requirements specified by this field cease to be met
						// at some point during pod execution (e.g. due to an update), the system
						// may or may not try to eventually evict the pod from its node.
						RequiredDuringSchedulingIgnoredDuringExecution *struct {
							// NodeSelectorTerms Required. A list of node selector terms. The terms are ORed.
							NodeSelectorTerms []struct {
								// MatchExpressions A list of node selector requirements by node's labels.
								MatchExpressions *[]struct {
									// Key The label key that the selector applies to.
									Key string `json:"key"`

									// Operator Represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
									Operator string `json:"operator"`

									// Values An array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. If the operator is Gt or Lt, the values
									// array must have a single element, which will be interpreted as an integer.
									// This array is replaced during a strategic merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchFields A list of node selector requirements by node's fields.
								MatchFields *[]struct {
									// Key The label key that the selector applies to.
									Key string `json:"key"`

									// Operator Represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
									Operator string `json:"operator"`

									// Values An array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. If the operator is Gt or Lt, the values
									// array must have a single element, which will be interpreted as an integer.
									// This array is replaced during a strategic merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchFields,omitempty"`
							} `json:"nodeSelectorTerms"`
						} `json:"requiredDuringSchedulingIgnoredDuringExecution,omitempty"`
					} `json:"nodeAffinity,omitempty"`

					// PodAffinity Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
					PodAffinity *struct {
						// PreferredDuringSchedulingIgnoredDuringExecution The scheduler will prefer to schedule pods to nodes that satisfy
						// the affinity expressions specified by this field, but it may choose
						// a node that violates one or more of the expressions. The node that is
						// most preferred is the one with the greatest sum of weights, i.e.
						// for each node that meets all of the scheduling requirements (resource
						// request, requiredDuringScheduling affinity expressions, etc.),
						// compute a sum by iterating through the elements of this field and adding
						// "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the
						// node(s) with the highest sum are the most preferred.
						PreferredDuringSchedulingIgnoredDuringExecution *[]struct {
							// PodAffinityTerm Required. A pod affinity term, associated with the corresponding weight.
							PodAffinityTerm struct {
								// LabelSelector A label query over a set of resources, in this case pods.
								// If it's null, this PodAffinityTerm matches with no Pods.
								LabelSelector *struct {
									// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
									MatchExpressions *[]struct {
										// Key key is the label key that the selector applies to.
										Key string `json:"key"`

										// Operator operator represents a key's relationship to a set of values.
										// Valid operators are In, NotIn, Exists and DoesNotExist.
										Operator string `json:"operator"`

										// Values values is an array of string values. If the operator is In or NotIn,
										// the values array must be non-empty. If the operator is Exists or DoesNotExist,
										// the values array must be empty. This array is replaced during a strategic
										// merge patch.
										Values *[]string `json:"values,omitempty"`
									} `json:"matchExpressions,omitempty"`

									// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
									// map is equivalent to an element of matchExpressions, whose key field is "key", the
									// operator is "In", and the values array contains only "value". The requirements are ANDed.
									MatchLabels *map[string]string `json:"matchLabels,omitempty"`
								} `json:"labelSelector,omitempty"`

								// MatchLabelKeys MatchLabelKeys is a set of pod label keys to select which pods will
								// be taken into consideration. The keys are used to lookup values from the
								// incoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`
								// to select the group of existing pods which pods will be taken into consideration
								// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
								// pod labels will be ignored. The default value is empty.
								// The same key is forbidden to exist in both matchLabelKeys and labelSelector.
								// Also, matchLabelKeys cannot be set when labelSelector isn't set.
								MatchLabelKeys *[]string `json:"matchLabelKeys,omitempty"`

								// MismatchLabelKeys MismatchLabelKeys is a set of pod label keys to select which pods will
								// be taken into consideration. The keys are used to lookup values from the
								// incoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`
								// to select the group of existing pods which pods will be taken into consideration
								// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
								// pod labels will be ignored. The default value is empty.
								// The same key is forbidden to exist in both mismatchLabelKeys and labelSelector.
								// Also, mismatchLabelKeys cannot be set when labelSelector isn't set.
								MismatchLabelKeys *[]string `json:"mismatchLabelKeys,omitempty"`

								// NamespaceSelector A label query over the set of namespaces that the term applies to.
								// The term is applied to the union of the namespaces selected by this field
								// and the ones listed in the namespaces field.
								// null selector and null or empty namespaces list means "this pod's namespace".
								// An empty selector ({}) matches all namespaces.
								NamespaceSelector *struct {
									// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
									MatchExpressions *[]struct {
										// Key key is the label key that the selector applies to.
										Key string `json:"key"`

										// Operator operator represents a key's relationship to a set of values.
										// Valid operators are In, NotIn, Exists and DoesNotExist.
										Operator string `json:"operator"`

										// Values values is an array of string values. If the operator is In or NotIn,
										// the values array must be non-empty. If the operator is Exists or DoesNotExist,
										// the values array must be empty. This array is replaced during a strategic
										// merge patch.
										Values *[]string `json:"values,omitempty"`
									} `json:"matchExpressions,omitempty"`

									// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
									// map is equivalent to an element of matchExpressions, whose key field is "key", the
									// operator is "In", and the values array contains only "value". The requirements are ANDed.
									MatchLabels *map[string]string `json:"matchLabels,omitempty"`
								} `json:"namespaceSelector,omitempty"`

								// Namespaces namespaces specifies a static list of namespace names that the term applies to.
								// The term is applied to the union of the namespaces listed in this field
								// and the ones selected by namespaceSelector.
								// null or empty namespaces list and null namespaceSelector means "this pod's namespace".
								Namespaces *[]string `json:"namespaces,omitempty"`

								// TopologyKey This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
								// the labelSelector in the specified namespaces, where co-located is defined as running on a node
								// whose value of the label with key topologyKey matches that of any node on which any of the
								// selected pods is running.
								// Empty topologyKey is not allowed.
								TopologyKey string `json:"topologyKey"`
							} `json:"podAffinityTerm"`

							// Weight weight associated with matching the corresponding podAffinityTerm,
							// in the range 1-100.
							Weight int32 `json:"weight"`
						} `json:"preferredDuringSchedulingIgnoredDuringExecution,omitempty"`

						// RequiredDuringSchedulingIgnoredDuringExecution If the affinity requirements specified by this field are not met at
						// scheduling time, the pod will not be scheduled onto the node.
						// If the affinity requirements specified by this field cease to be met
						// at some point during pod execution (e.g. due to a pod label update), the
						// system may or may not try to eventually evict the pod from its node.
						// When there are multiple elements, the lists of nodes corresponding to each
						// podAffinityTerm are intersected, i.e. all terms must be satisfied.
						RequiredDuringSchedulingIgnoredDuringExecution *[]struct {
							// LabelSelector A label query over a set of resources, in this case pods.
							// If it's null, this PodAffinityTerm matches with no Pods.
							LabelSelector *struct {
								// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
								MatchExpressions *[]struct {
									// Key key is the label key that the selector applies to.
									Key string `json:"key"`

									// Operator operator represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists and DoesNotExist.
									Operator string `json:"operator"`

									// Values values is an array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. This array is replaced during a strategic
									// merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
								// map is equivalent to an element of matchExpressions, whose key field is "key", the
								// operator is "In", and the values array contains only "value". The requirements are ANDed.
								MatchLabels *map[string]string `json:"matchLabels,omitempty"`
							} `json:"labelSelector,omitempty"`

							// MatchLabelKeys MatchLabelKeys is a set of pod label keys to select which pods will
							// be taken into consideration. The keys are used to lookup values from the
							// incoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`
							// to select the group of existing pods which pods will be taken into consideration
							// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
							// pod labels will be ignored. The default value is empty.
							// The same key is forbidden to exist in both matchLabelKeys and labelSelector.
							// Also, matchLabelKeys cannot be set when labelSelector isn't set.
							MatchLabelKeys *[]string `json:"matchLabelKeys,omitempty"`

							// MismatchLabelKeys MismatchLabelKeys is a set of pod label keys to select which pods will
							// be taken into consideration. The keys are used to lookup values from the
							// incoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`
							// to select the group of existing pods which pods will be taken into consideration
							// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
							// pod labels will be ignored. The default value is empty.
							// The same key is forbidden to exist in both mismatchLabelKeys and labelSelector.
							// Also, mismatchLabelKeys cannot be set when labelSelector isn't set.
							MismatchLabelKeys *[]string `json:"mismatchLabelKeys,omitempty"`

							// NamespaceSelector A label query over the set of namespaces that the term applies to.
							// The term is applied to the union of the namespaces selected by this field
							// and the ones listed in the namespaces field.
							// null selector and null or empty namespaces list means "this pod's namespace".
							// An empty selector ({}) matches all namespaces.
							NamespaceSelector *struct {
								// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
								MatchExpressions *[]struct {
									// Key key is the label key that the selector applies to.
									Key string `json:"key"`

									// Operator operator represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists and DoesNotExist.
									Operator string `json:"operator"`

									// Values values is an array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. This array is replaced during a strategic
									// merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
								// map is equivalent to an element of matchExpressions, whose key field is "key", the
								// operator is "In", and the values array contains only "value". The requirements are ANDed.
								MatchLabels *map[string]string `json:"matchLabels,omitempty"`
							} `json:"namespaceSelector,omitempty"`

							// Namespaces namespaces specifies a static list of namespace names that the term applies to.
							// The term is applied to the union of the namespaces listed in this field
							// and the ones selected by namespaceSelector.
							// null or empty namespaces list and null namespaceSelector means "this pod's namespace".
							Namespaces *[]string `json:"namespaces,omitempty"`

							// TopologyKey This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
							// the labelSelector in the specified namespaces, where co-located is defined as running on a node
							// whose value of the label with key topologyKey matches that of any node on which any of the
							// selected pods is running.
							// Empty topologyKey is not allowed.
							TopologyKey string `json:"topologyKey"`
						} `json:"requiredDuringSchedulingIgnoredDuringExecution,omitempty"`
					} `json:"podAffinity,omitempty"`

					// PodAntiAffinity Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
					PodAntiAffinity *struct {
						// PreferredDuringSchedulingIgnoredDuringExecution The scheduler will prefer to schedule pods to nodes that satisfy
						// the anti-affinity expressions specified by this field, but it may choose
						// a node that violates one or more of the expressions. The node that is
						// most preferred is the one with the greatest sum of weights, i.e.
						// for each node that meets all of the scheduling requirements (resource
						// request, requiredDuringScheduling anti-affinity expressions, etc.),
						// compute a sum by iterating through the elements of this field and adding
						// "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the
						// node(s) with the highest sum are the most preferred.
						PreferredDuringSchedulingIgnoredDuringExecution *[]struct {
							// PodAffinityTerm Required. A pod affinity term, associated with the corresponding weight.
							PodAffinityTerm struct {
								// LabelSelector A label query over a set of resources, in this case pods.
								// If it's null, this PodAffinityTerm matches with no Pods.
								LabelSelector *struct {
									// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
									MatchExpressions *[]struct {
										// Key key is the label key that the selector applies to.
										Key string `json:"key"`

										// Operator operator represents a key's relationship to a set of values.
										// Valid operators are In, NotIn, Exists and DoesNotExist.
										Operator string `json:"operator"`

										// Values values is an array of string values. If the operator is In or NotIn,
										// the values array must be non-empty. If the operator is Exists or DoesNotExist,
										// the values array must be empty. This array is replaced during a strategic
										// merge patch.
										Values *[]string `json:"values,omitempty"`
									} `json:"matchExpressions,omitempty"`

									// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
									// map is equivalent to an element of matchExpressions, whose key field is "key", the
									// operator is "In", and the values array contains only "value". The requirements are ANDed.
									MatchLabels *map[string]string `json:"matchLabels,omitempty"`
								} `json:"labelSelector,omitempty"`

								// MatchLabelKeys MatchLabelKeys is a set of pod label keys to select which pods will
								// be taken into consideration. The keys are used to lookup values from the
								// incoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`
								// to select the group of existing pods which pods will be taken into consideration
								// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
								// pod labels will be ignored. The default value is empty.
								// The same key is forbidden to exist in both matchLabelKeys and labelSelector.
								// Also, matchLabelKeys cannot be set when labelSelector isn't set.
								MatchLabelKeys *[]string `json:"matchLabelKeys,omitempty"`

								// MismatchLabelKeys MismatchLabelKeys is a set of pod label keys to select which pods will
								// be taken into consideration. The keys are used to lookup values from the
								// incoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`
								// to select the group of existing pods which pods will be taken into consideration
								// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
								// pod labels will be ignored. The default value is empty.
								// The same key is forbidden to exist in both mismatchLabelKeys and labelSelector.
								// Also, mismatchLabelKeys cannot be set when labelSelector isn't set.
								MismatchLabelKeys *[]string `json:"mismatchLabelKeys,omitempty"`

								// NamespaceSelector A label query over the set of namespaces that the term applies to.
								// The term is applied to the union of the namespaces selected by this field
								// and the ones listed in the namespaces field.
								// null selector and null or empty namespaces list means "this pod's namespace".
								// An empty selector ({}) matches all namespaces.
								NamespaceSelector *struct {
									// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
									MatchExpressions *[]struct {
										// Key key is the label key that the selector applies to.
										Key string `json:"key"`

										// Operator operator represents a key's relationship to a set of values.
										// Valid operators are In, NotIn, Exists and DoesNotExist.
										Operator string `json:"operator"`

										// Values values is an array of string values. If the operator is In or NotIn,
										// the values array must be non-empty. If the operator is Exists or DoesNotExist,
										// the values array must be empty. This array is replaced during a strategic
										// merge patch.
										Values *[]string `json:"values,omitempty"`
									} `json:"matchExpressions,omitempty"`

									// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
									// map is equivalent to an element of matchExpressions, whose key field is "key", the
									// operator is "In", and the values array contains only "value". The requirements are ANDed.
									MatchLabels *map[string]string `json:"matchLabels,omitempty"`
								} `json:"namespaceSelector,omitempty"`

								// Namespaces namespaces specifies a static list of namespace names that the term applies to.
								// The term is applied to the union of the namespaces listed in this field
								// and the ones selected by namespaceSelector.
								// null or empty namespaces list and null namespaceSelector means "this pod's namespace".
								Namespaces *[]string `json:"namespaces,omitempty"`

								// TopologyKey This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
								// the labelSelector in the specified namespaces, where co-located is defined as running on a node
								// whose value of the label with key topologyKey matches that of any node on which any of the
								// selected pods is running.
								// Empty topologyKey is not allowed.
								TopologyKey string `json:"topologyKey"`
							} `json:"podAffinityTerm"`

							// Weight weight associated with matching the corresponding podAffinityTerm,
							// in the range 1-100.
							Weight int32 `json:"weight"`
						} `json:"preferredDuringSchedulingIgnoredDuringExecution,omitempty"`

						// RequiredDuringSchedulingIgnoredDuringExecution If the anti-affinity requirements specified by this field are not met at
						// scheduling time, the pod will not be scheduled onto the node.
						// If the anti-affinity requirements specified by this field cease to be met
						// at some point during pod execution (e.g. due to a pod label update), the
						// system may or may not try to eventually evict the pod from its node.
						// When there are multiple elements, the lists of nodes corresponding to each
						// podAffinityTerm are intersected, i.e. all terms must be satisfied.
						RequiredDuringSchedulingIgnoredDuringExecution *[]struct {
							// LabelSelector A label query over a set of resources, in this case pods.
							// If it's null, this PodAffinityTerm matches with no Pods.
							LabelSelector *struct {
								// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
								MatchExpressions *[]struct {
									// Key key is the label key that the selector applies to.
									Key string `json:"key"`

									// Operator operator represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists and DoesNotExist.
									Operator string `json:"operator"`

									// Values values is an array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. This array is replaced during a strategic
									// merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
								// map is equivalent to an element of matchExpressions, whose key field is "key", the
								// operator is "In", and the values array contains only "value". The requirements are ANDed.
								MatchLabels *map[string]string `json:"matchLabels,omitempty"`
							} `json:"labelSelector,omitempty"`

							// MatchLabelKeys MatchLabelKeys is a set of pod label keys to select which pods will
							// be taken into consideration. The keys are used to lookup values from the
							// incoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`
							// to select the group of existing pods which pods will be taken into consideration
							// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
							// pod labels will be ignored. The default value is empty.
							// The same key is forbidden to exist in both matchLabelKeys and labelSelector.
							// Also, matchLabelKeys cannot be set when labelSelector isn't set.
							MatchLabelKeys *[]string `json:"matchLabelKeys,omitempty"`

							// MismatchLabelKeys MismatchLabelKeys is a set of pod label keys to select which pods will
							// be taken into consideration. The keys are used to lookup values from the
							// incoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`
							// to select the group of existing pods which pods will be taken into consideration
							// for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming
							// pod labels will be ignored. The default value is empty.
							// The same key is forbidden to exist in both mismatchLabelKeys and labelSelector.
							// Also, mismatchLabelKeys cannot be set when labelSelector isn't set.
							MismatchLabelKeys *[]string `json:"mismatchLabelKeys,omitempty"`

							// NamespaceSelector A label query over the set of namespaces that the term applies to.
							// The term is applied to the union of the namespaces selected by this field
							// and the ones listed in the namespaces field.
							// null selector and null or empty namespaces list means "this pod's namespace".
							// An empty selector ({}) matches all namespaces.
							NamespaceSelector *struct {
								// MatchExpressions matchExpressions is a list of label selector requirements. The requirements are ANDed.
								MatchExpressions *[]struct {
									// Key key is the label key that the selector applies to.
									Key string `json:"key"`

									// Operator operator represents a key's relationship to a set of values.
									// Valid operators are In, NotIn, Exists and DoesNotExist.
									Operator string `json:"operator"`

									// Values values is an array of string values. If the operator is In or NotIn,
									// the values array must be non-empty. If the operator is Exists or DoesNotExist,
									// the values array must be empty. This array is replaced during a strategic
									// merge patch.
									Values *[]string `json:"values,omitempty"`
								} `json:"matchExpressions,omitempty"`

								// MatchLabels matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels
								// map is equivalent to an element of matchExpressions, whose key field is "key", the
								// operator is "In", and the values array contains only "value". The requirements are ANDed.
								MatchLabels *map[string]string `json:"matchLabels,omitempty"`
							} `json:"namespaceSelector,omitempty"`

							// Namespaces namespaces specifies a static list of namespace names that the term applies to.
							// The term is applied to the union of the namespaces listed in this field
							// and the ones selected by namespaceSelector.
							// null or empty namespaces list and null namespaceSelector means "this pod's namespace".
							Namespaces *[]string `json:"namespaces,omitempty"`

							// TopologyKey This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching
							// the labelSelector in the specified namespaces, where co-located is defined as running on a node
							// whose value of the label with key topologyKey matches that of any node on which any of the
							// selected pods is running.
							// Empty topologyKey is not allowed.
							TopologyKey string `json:"topologyKey"`
						} `json:"requiredDuringSchedulingIgnoredDuringExecution,omitempty"`
					} `json:"podAntiAffinity,omitempty"`
				} `json:"proxy,omitempty"`
			} `json:"pxc,omitempty"`
		} `json:"affinityConfig,omitempty"`

		// EngineType EngineType is type of DB engine that this policy can be applied to.
		EngineType PodSchedulingPolicySpecEngineType `json:"engineType"`
	} `json:"spec,omitempty"`

	// Status PodSchedulingPolicyStatus defines the observed state of PodSchedulingPolicy.
	Status *struct {
		// InUse InUse is a flag that indicates if the policy is used by any DB cluster.
		InUse *bool `json:"inUse,omitempty"`

		// LastObservedGeneration LastObservedGeneration is the most recent generation observed for this PodSchedulingPolicy.
		LastObservedGeneration *int64 `json:"lastObservedGeneration,omitempty"`
	} `json:"status,omitempty"`
}

// PodSchedulingPolicySpecEngineType EngineType is type of DB engine that this policy can be applied to.
type PodSchedulingPolicySpecEngineType string

// PodSchedulingPolicyList PodSchedulingPolicyList is an object that contains the list of the existing pod scheduling policies.
type PodSchedulingPolicyList struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string                `json:"apiVersion,omitempty"`
	Items      *[]PodSchedulingPolicy `json:"items,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`
}

// Secret Secret holds secret data of a certain type. The total bytes of the values in the Data field must be less than MaxSecretSize bytes.
type Secret struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string `json:"apiVersion,omitempty"`

	// Data Data contains the secret data. Each key must consist of alphanumeric characters, '-', '_' or '.'. The serialized form of the secret data is a base64 encoded string, representing the arbitrary (possibly non-string) data value here. Described in https://tools.ietf.org/html/rfc4648#section-4
	Data *map[string][]byte `json:"data,omitempty"`

	// Immutable Immutable, if set to true, ensures that data stored in the Secret cannot be updated (only object metadata can be modified). If not set to true, the field can be modified at any time. Defaulted to nil.
	Immutable *bool `json:"immutable,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind *string `json:"kind,omitempty"`

	// Metadata Standard object's metadata. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata
	Metadata *map[string]interface{} `json:"metadata,omitempty"`

	// StringData stringData allows specifying non-binary secret data in string form. It is provided as a write-only input field for convenience. All keys and values are merged into the data field on write, overwriting any existing values. The stringData field is never output when reading from the API.
	StringData *map[string]string `json:"stringData,omitempty"`

	// Type Used to facilitate programmatic handling of secret data. More info: https://kubernetes.io/docs/concepts/configuration/secret/#secret-types
	Type *string `json:"type,omitempty"`
}

// Settings Everest global settings
type Settings struct {
	// OidcConfig Everest OIDC provider configuration
	OidcConfig OIDCConfig `json:"oidcConfig"`
}

// SplitHorizonDNSConfig SplitHorizonDNSConfig is the Schema for the splithorizondnsconfigs API.
type SplitHorizonDNSConfig struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object.
	// Servers should convert recognized schemas to the latest internal value, and
	// may reject unrecognized values.
	// More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string `json:"apiVersion,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents.
	// Servers may infer this from the endpoint the client submits requests to.
	// Cannot be updated.
	// In CamelCase.
	// More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`

	// Spec Spec defines the desired state of SplitHorizonDNSConfig
	Spec struct {
		// BaseDomainNameSuffix BaseDomainNameSuffix is the base domain name suffix for generating domain names for each Pod in ReplicaSet.
		// It should be a valid domain name suffix.
		BaseDomainNameSuffix string `json:"baseDomainNameSuffix"`

		// Tls TLS is the TLS configuration for the split-horizon DNS configuration.
		Tls struct {
			// Certificate Certificate is the TLS certificate and key for the split-horizon DNS configuration.
			Certificate *struct {
				// CaCrt CACert is based64 encoded ca.pem file content.
				// It is provided as a write-only input field for convenience.
				// When this field is set, a webhook writes this value in the Secret specified by `.spec.tls.secretName`
				// and empties this field.
				// This field is not stored in the API.
				CaCrt string `json:"ca.crt"`

				// CaKey CA Private Key is based64 encoded ca-key.pem file content.
				// It is provided as a write-only input field for convenience.
				// When this field is set, a webhook writes this value in the Secret specified by `.spec.tls.secretName`
				// and empties this field.
				// This field is not stored in the API.
				CaKey string `json:"ca.key"`
			} `json:"certificate,omitempty"`

			// SecretName SecretName is the name of the secret containing the TLS certificate and key for the split-horizon DNS configuration.
			SecretName string `json:"secretName"`
		} `json:"tls"`
	} `json:"spec"`

	// Status Status defines the observed state of SplitHorizonDNSConfig
	Status *struct {
		// InUse InUse is a flag that indicates if the config is used by any DB cluster.
		InUse *bool `json:"inUse,omitempty"`

		// LastObservedGeneration LastObservedGeneration is the most recent generation observed for this SplitHorizonDNSConfig.
		LastObservedGeneration *int64 `json:"lastObservedGeneration,omitempty"`
	} `json:"status,omitempty"`
}

// SplitHorizonDNSConfigList SplitHorizonDNSConfigList is an object that contains the list of the existing split-horizon dns configs.
type SplitHorizonDNSConfigList struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string                  `json:"apiVersion,omitempty"`
	Items      *[]SplitHorizonDNSConfig `json:"items,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind     *string                 `json:"kind,omitempty"`
	Metadata *map[string]interface{} `json:"metadata,omitempty"`
}

// SplitHorizonDNSConfigUpdateParams SplitHorizonDNSConfigUpdateParams is the Schema for the splithorizondnsconfigs update API.
type SplitHorizonDNSConfigUpdateParams struct {
	// BaseDomainNameSuffix BaseDomainNameSuffix is the base domain name suffix for generating domain names for each Pod in ReplicaSet.
	// It should be a valid domain name suffix.
	BaseDomainNameSuffix *string `json:"baseDomainNameSuffix,omitempty"`

	// Certificate Certificate is the TLS certificate and key for the split-horizon DNS configuration.
	Certificate *struct {
		// CaCrt CACert is based64 encoded ca.pem file content.
		// It is provided as a write-only input field for convenience.
		// When this field is set, a webhook writes this value in the Secret specified by `.spec.tls.secretName`
		// and empties this field.
		// This field is not stored in the API.
		CaCrt string `json:"ca.crt"`

		// CaKey CAKey is based64 encoded ca-key.pem file content.
		// It is provided as a write-only input field for convenience.
		// When this field is set, a webhook writes this value in the Secret specified by `.spec.tls.secretName`
		// and empties this field.
		// This field is not stored in the API.
		CaKey string `json:"ca.key"`
	} `json:"certificate,omitempty"`
}

// StorageClass StorageClass describes the parameters for a class of storage for which PersistentVolumes can be dynamically provisioned.
//
// StorageClasses are non-namespaced; the name of the storage class according to etcd is in ObjectMeta.Name.
type StorageClass struct {
	// AllowVolumeExpansion allowVolumeExpansion shows whether the storage class allow volume expand.
	AllowVolumeExpansion *bool `json:"allowVolumeExpansion,omitempty"`

	// Metadata Standard object's metadata. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata
	Metadata *map[string]interface{} `json:"metadata,omitempty"`
}

// UpdateBackupStorageParams Backup storage parameters
type UpdateBackupStorageParams struct {
	AccessKey *string `json:"accessKey,omitempty"`

	// AllowedNamespaces List of namespaces allowed to use this backup storage
	// Deprecated: this property has been marked as deprecated upstream, but no `x-deprecated-reason` was set
	AllowedNamespaces *[]string `json:"allowedNamespaces,omitempty"`

	// BucketName The cloud storage bucket/container name
	BucketName     *string `json:"bucketName,omitempty"`
	Description    *string `json:"description,omitempty"`
	ForcePathStyle *bool   `json:"forcePathStyle,omitempty"`
	Region         *string `json:"region,omitempty"`
	SecretKey      *string `json:"secretKey,omitempty"`
	Url            *string `json:"url,omitempty"`
	VerifyTLS      *bool   `json:"verifyTLS,omitempty"`
}

// Upgrade defines model for Upgrade.
type Upgrade struct {
	// CurrentVersion The current operator version
	CurrentVersion *string `json:"currentVersion,omitempty"`

	// Name Name of the operator
	Name *string `json:"name,omitempty"`

	// TargetVersion The next version of the operator to upgrade to.
	TargetVersion *string `json:"targetVersion,omitempty"`
}

// UpgradePlan Operators upgrade plan
type UpgradePlan struct {
	PendingActions *[]UpgradeTask `json:"pendingActions,omitempty"`
	Upgrades       *[]Upgrade     `json:"upgrades,omitempty"`
}

// UpgradePlanApproval This no-op object is used to trigger the operator upgrade in a namespace.
type UpgradePlanApproval = map[string]interface{}

// UpgradeTask defines model for UpgradeTask.
type UpgradeTask struct {
	Message *string `json:"message,omitempty"`

	// Name Name of the database cluster
	Name *string `json:"name,omitempty"`

	// PendingTask Pending task for the database cluster
	PendingTask *UpgradeTaskPendingTask `json:"pendingTask,omitempty"`
}

// UpgradeTaskPendingTask Pending task for the database cluster
type UpgradeTaskPendingTask string

// UserCredentials defines model for UserCredentials.
type UserCredentials struct {
	Password *string `json:"password,omitempty"`
	Username *string `json:"username,omitempty"`
}

// UserPermissions defines model for UserPermissions.
type UserPermissions struct {
	Enabled     bool        `json:"enabled"`
	Permissions *[][]string `json:"permissions,omitempty"`
}

// Version Everest version info
type Version struct {
	FullCommit  string `json:"fullCommit"`
	ProjectName string `json:"projectName"`
	Version     string `json:"version"`
}

// IoK8sApimachineryPkgApisMetaV1ListMeta ListMeta describes metadata that synthetic resources must have, including lists and various status objects. A resource may have only one of {ObjectMeta, ListMeta}.
type IoK8sApimachineryPkgApisMetaV1ListMeta struct {
	// Continue continue may be set if the user set a limit on the number of items returned, and indicates that the server has more data available. The value is opaque and may be used to issue another request to the endpoint that served this list to retrieve the next set of available objects. Continuing a consistent list may not be possible if the server configuration has changed or more than a few minutes have passed. The resourceVersion field returned when using this continue value will be identical to the value in the first response, unless you have received this token from an error message.
	Continue *string `json:"continue,omitempty"`

	// RemainingItemCount remainingItemCount is the number of subsequent items in the list which are not included in this list response. If the list request contained label or field selectors, then the number of remaining items is unknown and the field will be left unset and omitted during serialization. If the list is complete (either because it is not chunking or because this is the last chunk), then there are no more remaining items and this field will be left unset and omitted during serialization. Servers older than v1.15 do not set this field. The intended use of the remainingItemCount is *estimating* the size of a collection. Clients should not rely on the remainingItemCount to be set or to be exact.
	RemainingItemCount *int64 `json:"remainingItemCount,omitempty"`

	// ResourceVersion String that identifies the server's internal version of this object that can be used by clients to determine when objects have changed. Value must be treated as opaque by clients and passed unmodified back to the server. Populated by the system. Read-only. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency
	ResourceVersion *string `json:"resourceVersion,omitempty"`

	// SelfLink selfLink is a URL representing this object. Populated by the system. Read-only.
	//
	// DEPRECATED Kubernetes will stop propagating this field in 1.20 release and the field is planned to be removed in 1.21 release.
	SelfLink *string `json:"selfLink,omitempty"`
}

// IoK8sApimachineryPkgApisMetaV1StatusCause StatusCause provides more information about an api.Status failure, including cases when multiple errors are encountered.
type IoK8sApimachineryPkgApisMetaV1StatusCause struct {
	// Field The field of the resource that has caused this error, as named by its JSON serialization. May include dot and postfix notation for nested attributes. Arrays are zero-indexed.  Fields may appear more than once in an array of causes due to fields having multiple errors. Optional.
	//
	// Examples:
	//   "name" - the field "name" on the current resource
	//   "items[0].name" - the field "name" on the first array entry in "items"
	Field *string `json:"field,omitempty"`

	// Message A human-readable description of the cause of the error.  This field may be presented as-is to a reader.
	Message *string `json:"message,omitempty"`

	// Reason A machine-readable description of the cause of the error. If this value is empty there is no information available.
	Reason *string `json:"reason,omitempty"`
}

// IoK8sApimachineryPkgApisMetaV1StatusDetailsV2 StatusDetails is a set of additional properties that MAY be set by the server to provide additional information about a response. The Reason field of a Status object defines what attributes will be set. Clients must ignore fields that do not match the defined type of each attribute, and should assume that any attribute may be empty, invalid, or under defined.
type IoK8sApimachineryPkgApisMetaV1StatusDetailsV2 struct {
	// Causes The Causes array includes more details associated with the StatusReason failure. Not all StatusReasons may provide detailed causes.
	Causes *[]IoK8sApimachineryPkgApisMetaV1StatusCause `json:"causes,omitempty"`

	// Group The group attribute of the resource associated with the status StatusReason.
	Group *string `json:"group,omitempty"`

	// Kind The kind attribute of the resource associated with the status StatusReason. On some operations may differ from the requested resource Kind. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind *string `json:"kind,omitempty"`

	// Name The name attribute of the resource associated with the status StatusReason (when there is a single name which can be described).
	Name *string `json:"name,omitempty"`

	// RetryAfterSeconds If specified, the time in seconds before the operation should be retried. Some errors may indicate the client must take an alternate action - for those errors this field may indicate how long to wait before taking the alternate action.
	RetryAfterSeconds *int32 `json:"retryAfterSeconds,omitempty"`

	// Uid UID of the resource. (when there is a single resource which can be described). More info: http://kubernetes.io/docs/user-guide/identifiers#uids
	Uid *string `json:"uid,omitempty"`
}

// IoK8sApimachineryPkgApisMetaV1StatusV2 Status is a return value for calls that don't return other objects.
type IoK8sApimachineryPkgApisMetaV1StatusV2 struct {
	// ApiVersion APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
	ApiVersion *string `json:"apiVersion,omitempty"`

	// Code Suggested HTTP return code for this status, 0 if not set.
	Code *int32 `json:"code,omitempty"`

	// Details StatusDetails is a set of additional properties that MAY be set by the server to provide additional information about a response. The Reason field of a Status object defines what attributes will be set. Clients must ignore fields that do not match the defined type of each attribute, and should assume that any attribute may be empty, invalid, or under defined.
	Details *IoK8sApimachineryPkgApisMetaV1StatusDetailsV2 `json:"details,omitempty"`

	// Kind Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
	Kind *string `json:"kind,omitempty"`

	// Message A human-readable description of the status of this operation.
	Message *string `json:"message,omitempty"`

	// Metadata ListMeta describes metadata that synthetic resources must have, including lists and various status objects. A resource may have only one of {ObjectMeta, ListMeta}.
	Metadata *IoK8sApimachineryPkgApisMetaV1ListMeta `json:"metadata,omitempty"`

	// Reason A machine-readable description of why this operation is in the "Failure" status. If this value is empty there is no information available. A Reason clarifies an HTTP status code but does not override it.
	Reason *string `json:"reason,omitempty"`

	// Status Status of the operation. One of: "Success" or "Failure". More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status
	Status *string `json:"status,omitempty"`
}

// ListDataImportersParams defines parameters for ListDataImporters.
type ListDataImportersParams struct {
	// SupportedEngines Filter data importers by supported database engine type. Accepts a comma-separated list.
	SupportedEngines *[]string `form:"supportedEngines,omitempty" json:"supportedEngines,omitempty"`
}

// DeleteDatabaseClusterBackupParams defines parameters for DeleteDatabaseClusterBackup.
type DeleteDatabaseClusterBackupParams struct {
	// CleanupBackupStorage If set, remove the backed up data from storage
	CleanupBackupStorage *bool `form:"cleanupBackupStorage,omitempty" json:"cleanupBackupStorage,omitempty"`
}

// CreateDatabaseClusterSecretParams defines parameters for CreateDatabaseClusterSecret.
type CreateDatabaseClusterSecretParams struct {
	// SecretName Optional name of the secret to be created. If not provided, a random name will be generated.
	SecretName *string `form:"secretName,omitempty" json:"secretName,omitempty"`
}

// DeleteDatabaseClusterParams defines parameters for DeleteDatabaseCluster.
type DeleteDatabaseClusterParams struct {
	// CleanupBackupStorage If set, remove the backed up data from storage
	CleanupBackupStorage *bool `form:"cleanupBackupStorage,omitempty" json:"cleanupBackupStorage,omitempty"`
}

// ListPodSchedulingPolicyParams defines parameters for ListPodSchedulingPolicy.
type ListPodSchedulingPolicyParams struct {
	// EngineType Database engine type that Pod Scheduling Policy is applicable to.
	EngineType *ListPodSchedulingPolicyParamsEngineType `form:"engineType,omitempty" json:"engineType,omitempty"`

	// HasRules Return list of Pod Scheduling Policy that has at least 1 rule.
	HasRules *bool `form:"hasRules,omitempty" json:"hasRules,omitempty"`
}

// ListPodSchedulingPolicyParamsEngineType defines parameters for ListPodSchedulingPolicy.
type ListPodSchedulingPolicyParamsEngineType string

// CreateLoadBalancerConfigJSONRequestBody defines body for CreateLoadBalancerConfig for application/json ContentType.
type CreateLoadBalancerConfigJSONRequestBody = LoadBalancerConfig

// UpdateLoadBalancerConfigJSONRequestBody defines body for UpdateLoadBalancerConfig for application/json ContentType.
type UpdateLoadBalancerConfigJSONRequestBody = LoadBalancerConfig

// CreateBackupStorageJSONRequestBody defines body for CreateBackupStorage for application/json ContentType.
type CreateBackupStorageJSONRequestBody = CreateBackupStorageParams

// UpdateBackupStorageJSONRequestBody defines body for UpdateBackupStorage for application/json ContentType.
type UpdateBackupStorageJSONRequestBody = UpdateBackupStorageParams

// CreateDatabaseClusterBackupJSONRequestBody defines body for CreateDatabaseClusterBackup for application/json ContentType.
type CreateDatabaseClusterBackupJSONRequestBody = DatabaseClusterBackup

// CreateDatabaseClusterRestoreJSONRequestBody defines body for CreateDatabaseClusterRestore for application/json ContentType.
type CreateDatabaseClusterRestoreJSONRequestBody = DatabaseClusterRestore

// UpdateDatabaseClusterRestoreJSONRequestBody defines body for UpdateDatabaseClusterRestore for application/json ContentType.
type UpdateDatabaseClusterRestoreJSONRequestBody = DatabaseClusterRestore

// CreateDatabaseClusterJSONRequestBody defines body for CreateDatabaseCluster for application/json ContentType.
type CreateDatabaseClusterJSONRequestBody = DatabaseCluster

// CreateDatabaseClusterSecretJSONRequestBody defines body for CreateDatabaseClusterSecret for application/json ContentType.
type CreateDatabaseClusterSecretJSONRequestBody = Secret

// UpdateDatabaseClusterJSONRequestBody defines body for UpdateDatabaseCluster for application/json ContentType.
type UpdateDatabaseClusterJSONRequestBody = DatabaseCluster

// ApproveUpgradePlanJSONRequestBody defines body for ApproveUpgradePlan for application/json ContentType.
type ApproveUpgradePlanJSONRequestBody = UpgradePlanApproval

// UpdateDatabaseEngineJSONRequestBody defines body for UpdateDatabaseEngine for application/json ContentType.
type UpdateDatabaseEngineJSONRequestBody = DatabaseEngine

// CreateSplitHorizonDNSConfigJSONRequestBody defines body for CreateSplitHorizonDNSConfig for application/json ContentType.
type CreateSplitHorizonDNSConfigJSONRequestBody = SplitHorizonDNSConfig

// UpdateSplitHorizonDNSConfigJSONRequestBody defines body for UpdateSplitHorizonDNSConfig for application/json ContentType.
type UpdateSplitHorizonDNSConfigJSONRequestBody = SplitHorizonDNSConfigUpdateParams

// CreateMonitoringInstanceJSONRequestBody defines body for CreateMonitoringInstance for application/json ContentType.
type CreateMonitoringInstanceJSONRequestBody = MonitoringInstanceCreateParams

// UpdateMonitoringInstanceJSONRequestBody defines body for UpdateMonitoringInstance for application/json ContentType.
type UpdateMonitoringInstanceJSONRequestBody = MonitoringInstanceUpdateParams

// CreatePodSchedulingPolicyJSONRequestBody defines body for CreatePodSchedulingPolicy for application/json ContentType.
type CreatePodSchedulingPolicyJSONRequestBody = PodSchedulingPolicy

// UpdatePodSchedulingPolicyJSONRequestBody defines body for UpdatePodSchedulingPolicy for application/json ContentType.
type UpdatePodSchedulingPolicyJSONRequestBody = PodSchedulingPolicy

// CreateSessionJSONRequestBody defines body for CreateSession for application/json ContentType.
type CreateSessionJSONRequestBody = UserCredentials

// AsDatabaseClusterSpecEngineResourcesCpu0 returns the union data inside the DatabaseCluster_Spec_Engine_Resources_Cpu as a DatabaseClusterSpecEngineResourcesCpu0
func (t DatabaseCluster_Spec_Engine_Resources_Cpu) AsDatabaseClusterSpecEngineResourcesCpu0() (DatabaseClusterSpecEngineResourcesCpu0, error) {
	var body DatabaseClusterSpecEngineResourcesCpu0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecEngineResourcesCpu0 overwrites any union data inside the DatabaseCluster_Spec_Engine_Resources_Cpu as the provided DatabaseClusterSpecEngineResourcesCpu0
func (t *DatabaseCluster_Spec_Engine_Resources_Cpu) FromDatabaseClusterSpecEngineResourcesCpu0(v DatabaseClusterSpecEngineResourcesCpu0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecEngineResourcesCpu0 performs a merge with any union data inside the DatabaseCluster_Spec_Engine_Resources_Cpu, using the provided DatabaseClusterSpecEngineResourcesCpu0
func (t *DatabaseCluster_Spec_Engine_Resources_Cpu) MergeDatabaseClusterSpecEngineResourcesCpu0(v DatabaseClusterSpecEngineResourcesCpu0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsDatabaseClusterSpecEngineResourcesCpu1 returns the union data inside the DatabaseCluster_Spec_Engine_Resources_Cpu as a DatabaseClusterSpecEngineResourcesCpu1
func (t DatabaseCluster_Spec_Engine_Resources_Cpu) AsDatabaseClusterSpecEngineResourcesCpu1() (DatabaseClusterSpecEngineResourcesCpu1, error) {
	var body DatabaseClusterSpecEngineResourcesCpu1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecEngineResourcesCpu1 overwrites any union data inside the DatabaseCluster_Spec_Engine_Resources_Cpu as the provided DatabaseClusterSpecEngineResourcesCpu1
func (t *DatabaseCluster_Spec_Engine_Resources_Cpu) FromDatabaseClusterSpecEngineResourcesCpu1(v DatabaseClusterSpecEngineResourcesCpu1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecEngineResourcesCpu1 performs a merge with any union data inside the DatabaseCluster_Spec_Engine_Resources_Cpu, using the provided DatabaseClusterSpecEngineResourcesCpu1
func (t *DatabaseCluster_Spec_Engine_Resources_Cpu) MergeDatabaseClusterSpecEngineResourcesCpu1(v DatabaseClusterSpecEngineResourcesCpu1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t DatabaseCluster_Spec_Engine_Resources_Cpu) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseCluster_Spec_Engine_Resources_Cpu) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterSpecEngineResourcesMemory0 returns the union data inside the DatabaseCluster_Spec_Engine_Resources_Memory as a DatabaseClusterSpecEngineResourcesMemory0
func (t DatabaseCluster_Spec_Engine_Resources_Memory) AsDatabaseClusterSpecEngineResourcesMemory0() (DatabaseClusterSpecEngineResourcesMemory0, error) {
	var body DatabaseClusterSpecEngineResourcesMemory0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecEngineResourcesMemory0 overwrites any union data inside the DatabaseCluster_Spec_Engine_Resources_Memory as the provided DatabaseClusterSpecEngineResourcesMemory0
func (t *DatabaseCluster_Spec_Engine_Resources_Memory) FromDatabaseClusterSpecEngineResourcesMemory0(v DatabaseClusterSpecEngineResourcesMemory0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecEngineResourcesMemory0 performs a merge with any union data inside the DatabaseCluster_Spec_Engine_Resources_Memory, using the provided DatabaseClusterSpecEngineResourcesMemory0
func (t *DatabaseCluster_Spec_Engine_Resources_Memory) MergeDatabaseClusterSpecEngineResourcesMemory0(v DatabaseClusterSpecEngineResourcesMemory0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsDatabaseClusterSpecEngineResourcesMemory1 returns the union data inside the DatabaseCluster_Spec_Engine_Resources_Memory as a DatabaseClusterSpecEngineResourcesMemory1
func (t DatabaseCluster_Spec_Engine_Resources_Memory) AsDatabaseClusterSpecEngineResourcesMemory1() (DatabaseClusterSpecEngineResourcesMemory1, error) {
	var body DatabaseClusterSpecEngineResourcesMemory1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecEngineResourcesMemory1 overwrites any union data inside the DatabaseCluster_Spec_Engine_Resources_Memory as the provided DatabaseClusterSpecEngineResourcesMemory1
func (t *DatabaseCluster_Spec_Engine_Resources_Memory) FromDatabaseClusterSpecEngineResourcesMemory1(v DatabaseClusterSpecEngineResourcesMemory1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecEngineResourcesMemory1 performs a merge with any union data inside the DatabaseCluster_Spec_Engine_Resources_Memory, using the provided DatabaseClusterSpecEngineResourcesMemory1
func (t *DatabaseCluster_Spec_Engine_Resources_Memory) MergeDatabaseClusterSpecEngineResourcesMemory1(v DatabaseClusterSpecEngineResourcesMemory1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t DatabaseCluster_Spec_Engine_Resources_Memory) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseCluster_Spec_Engine_Resources_Memory) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterSpecEngineStorageSize0 returns the union data inside the DatabaseCluster_Spec_Engine_Storage_Size as a DatabaseClusterSpecEngineStorageSize0
func (t DatabaseCluster_Spec_Engine_Storage_Size) AsDatabaseClusterSpecEngineStorageSize0() (DatabaseClusterSpecEngineStorageSize0, error) {
	var body DatabaseClusterSpecEngineStorageSize0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecEngineStorageSize0 overwrites any union data inside the DatabaseCluster_Spec_Engine_Storage_Size as the provided DatabaseClusterSpecEngineStorageSize0
func (t *DatabaseCluster_Spec_Engine_Storage_Size) FromDatabaseClusterSpecEngineStorageSize0(v DatabaseClusterSpecEngineStorageSize0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecEngineStorageSize0 performs a merge with any union data inside the DatabaseCluster_Spec_Engine_Storage_Size, using the provided DatabaseClusterSpecEngineStorageSize0
func (t *DatabaseCluster_Spec_Engine_Storage_Size) MergeDatabaseClusterSpecEngineStorageSize0(v DatabaseClusterSpecEngineStorageSize0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsDatabaseClusterSpecEngineStorageSize1 returns the union data inside the DatabaseCluster_Spec_Engine_Storage_Size as a DatabaseClusterSpecEngineStorageSize1
func (t DatabaseCluster_Spec_Engine_Storage_Size) AsDatabaseClusterSpecEngineStorageSize1() (DatabaseClusterSpecEngineStorageSize1, error) {
	var body DatabaseClusterSpecEngineStorageSize1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecEngineStorageSize1 overwrites any union data inside the DatabaseCluster_Spec_Engine_Storage_Size as the provided DatabaseClusterSpecEngineStorageSize1
func (t *DatabaseCluster_Spec_Engine_Storage_Size) FromDatabaseClusterSpecEngineStorageSize1(v DatabaseClusterSpecEngineStorageSize1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecEngineStorageSize1 performs a merge with any union data inside the DatabaseCluster_Spec_Engine_Storage_Size, using the provided DatabaseClusterSpecEngineStorageSize1
func (t *DatabaseCluster_Spec_Engine_Storage_Size) MergeDatabaseClusterSpecEngineStorageSize1(v DatabaseClusterSpecEngineStorageSize1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t DatabaseCluster_Spec_Engine_Storage_Size) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseCluster_Spec_Engine_Storage_Size) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterSpecMonitoringResourcesLimits0 returns the union data inside the DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties as a DatabaseClusterSpecMonitoringResourcesLimits0
func (t DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) AsDatabaseClusterSpecMonitoringResourcesLimits0() (DatabaseClusterSpecMonitoringResourcesLimits0, error) {
	var body DatabaseClusterSpecMonitoringResourcesLimits0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecMonitoringResourcesLimits0 overwrites any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties as the provided DatabaseClusterSpecMonitoringResourcesLimits0
func (t *DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) FromDatabaseClusterSpecMonitoringResourcesLimits0(v DatabaseClusterSpecMonitoringResourcesLimits0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecMonitoringResourcesLimits0 performs a merge with any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties, using the provided DatabaseClusterSpecMonitoringResourcesLimits0
func (t *DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) MergeDatabaseClusterSpecMonitoringResourcesLimits0(v DatabaseClusterSpecMonitoringResourcesLimits0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsDatabaseClusterSpecMonitoringResourcesLimits1 returns the union data inside the DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties as a DatabaseClusterSpecMonitoringResourcesLimits1
func (t DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) AsDatabaseClusterSpecMonitoringResourcesLimits1() (DatabaseClusterSpecMonitoringResourcesLimits1, error) {
	var body DatabaseClusterSpecMonitoringResourcesLimits1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecMonitoringResourcesLimits1 overwrites any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties as the provided DatabaseClusterSpecMonitoringResourcesLimits1
func (t *DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) FromDatabaseClusterSpecMonitoringResourcesLimits1(v DatabaseClusterSpecMonitoringResourcesLimits1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecMonitoringResourcesLimits1 performs a merge with any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties, using the provided DatabaseClusterSpecMonitoringResourcesLimits1
func (t *DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) MergeDatabaseClusterSpecMonitoringResourcesLimits1(v DatabaseClusterSpecMonitoringResourcesLimits1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseCluster_Spec_Monitoring_Resources_Limits_AdditionalProperties) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterSpecMonitoringResourcesRequests0 returns the union data inside the DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties as a DatabaseClusterSpecMonitoringResourcesRequests0
func (t DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) AsDatabaseClusterSpecMonitoringResourcesRequests0() (DatabaseClusterSpecMonitoringResourcesRequests0, error) {
	var body DatabaseClusterSpecMonitoringResourcesRequests0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecMonitoringResourcesRequests0 overwrites any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties as the provided DatabaseClusterSpecMonitoringResourcesRequests0
func (t *DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) FromDatabaseClusterSpecMonitoringResourcesRequests0(v DatabaseClusterSpecMonitoringResourcesRequests0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecMonitoringResourcesRequests0 performs a merge with any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties, using the provided DatabaseClusterSpecMonitoringResourcesRequests0
func (t *DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) MergeDatabaseClusterSpecMonitoringResourcesRequests0(v DatabaseClusterSpecMonitoringResourcesRequests0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsDatabaseClusterSpecMonitoringResourcesRequests1 returns the union data inside the DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties as a DatabaseClusterSpecMonitoringResourcesRequests1
func (t DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) AsDatabaseClusterSpecMonitoringResourcesRequests1() (DatabaseClusterSpecMonitoringResourcesRequests1, error) {
	var body DatabaseClusterSpecMonitoringResourcesRequests1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecMonitoringResourcesRequests1 overwrites any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties as the provided DatabaseClusterSpecMonitoringResourcesRequests1
func (t *DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) FromDatabaseClusterSpecMonitoringResourcesRequests1(v DatabaseClusterSpecMonitoringResourcesRequests1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecMonitoringResourcesRequests1 performs a merge with any union data inside the DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties, using the provided DatabaseClusterSpecMonitoringResourcesRequests1
func (t *DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) MergeDatabaseClusterSpecMonitoringResourcesRequests1(v DatabaseClusterSpecMonitoringResourcesRequests1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseCluster_Spec_Monitoring_Resources_Requests_AdditionalProperties) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterSpecProxyResourcesCpu0 returns the union data inside the DatabaseCluster_Spec_Proxy_Resources_Cpu as a DatabaseClusterSpecProxyResourcesCpu0
func (t DatabaseCluster_Spec_Proxy_Resources_Cpu) AsDatabaseClusterSpecProxyResourcesCpu0() (DatabaseClusterSpecProxyResourcesCpu0, error) {
	var body DatabaseClusterSpecProxyResourcesCpu0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecProxyResourcesCpu0 overwrites any union data inside the DatabaseCluster_Spec_Proxy_Resources_Cpu as the provided DatabaseClusterSpecProxyResourcesCpu0
func (t *DatabaseCluster_Spec_Proxy_Resources_Cpu) FromDatabaseClusterSpecProxyResourcesCpu0(v DatabaseClusterSpecProxyResourcesCpu0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecProxyResourcesCpu0 performs a merge with any union data inside the DatabaseCluster_Spec_Proxy_Resources_Cpu, using the provided DatabaseClusterSpecProxyResourcesCpu0
func (t *DatabaseCluster_Spec_Proxy_Resources_Cpu) MergeDatabaseClusterSpecProxyResourcesCpu0(v DatabaseClusterSpecProxyResourcesCpu0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsDatabaseClusterSpecProxyResourcesCpu1 returns the union data inside the DatabaseCluster_Spec_Proxy_Resources_Cpu as a DatabaseClusterSpecProxyResourcesCpu1
func (t DatabaseCluster_Spec_Proxy_Resources_Cpu) AsDatabaseClusterSpecProxyResourcesCpu1() (DatabaseClusterSpecProxyResourcesCpu1, error) {
	var body DatabaseClusterSpecProxyResourcesCpu1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecProxyResourcesCpu1 overwrites any union data inside the DatabaseCluster_Spec_Proxy_Resources_Cpu as the provided DatabaseClusterSpecProxyResourcesCpu1
func (t *DatabaseCluster_Spec_Proxy_Resources_Cpu) FromDatabaseClusterSpecProxyResourcesCpu1(v DatabaseClusterSpecProxyResourcesCpu1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecProxyResourcesCpu1 performs a merge with any union data inside the DatabaseCluster_Spec_Proxy_Resources_Cpu, using the provided DatabaseClusterSpecProxyResourcesCpu1
func (t *DatabaseCluster_Spec_Proxy_Resources_Cpu) MergeDatabaseClusterSpecProxyResourcesCpu1(v DatabaseClusterSpecProxyResourcesCpu1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t DatabaseCluster_Spec_Proxy_Resources_Cpu) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseCluster_Spec_Proxy_Resources_Cpu) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDatabaseClusterSpecProxyResourcesMemory0 returns the union data inside the DatabaseCluster_Spec_Proxy_Resources_Memory as a DatabaseClusterSpecProxyResourcesMemory0
func (t DatabaseCluster_Spec_Proxy_Resources_Memory) AsDatabaseClusterSpecProxyResourcesMemory0() (DatabaseClusterSpecProxyResourcesMemory0, error) {
	var body DatabaseClusterSpecProxyResourcesMemory0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecProxyResourcesMemory0 overwrites any union data inside the DatabaseCluster_Spec_Proxy_Resources_Memory as the provided DatabaseClusterSpecProxyResourcesMemory0
func (t *DatabaseCluster_Spec_Proxy_Resources_Memory) FromDatabaseClusterSpecProxyResourcesMemory0(v DatabaseClusterSpecProxyResourcesMemory0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecProxyResourcesMemory0 performs a merge with any union data inside the DatabaseCluster_Spec_Proxy_Resources_Memory, using the provided DatabaseClusterSpecProxyResourcesMemory0
func (t *DatabaseCluster_Spec_Proxy_Resources_Memory) MergeDatabaseClusterSpecProxyResourcesMemory0(v DatabaseClusterSpecProxyResourcesMemory0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsDatabaseClusterSpecProxyResourcesMemory1 returns the union data inside the DatabaseCluster_Spec_Proxy_Resources_Memory as a DatabaseClusterSpecProxyResourcesMemory1
func (t DatabaseCluster_Spec_Proxy_Resources_Memory) AsDatabaseClusterSpecProxyResourcesMemory1() (DatabaseClusterSpecProxyResourcesMemory1, error) {
	var body DatabaseClusterSpecProxyResourcesMemory1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDatabaseClusterSpecProxyResourcesMemory1 overwrites any union data inside the DatabaseCluster_Spec_Proxy_Resources_Memory as the provided DatabaseClusterSpecProxyResourcesMemory1
func (t *DatabaseCluster_Spec_Proxy_Resources_Memory) FromDatabaseClusterSpecProxyResourcesMemory1(v DatabaseClusterSpecProxyResourcesMemory1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDatabaseClusterSpecProxyResourcesMemory1 performs a merge with any union data inside the DatabaseCluster_Spec_Proxy_Resources_Memory, using the provided DatabaseClusterSpecProxyResourcesMemory1
func (t *DatabaseCluster_Spec_Proxy_Resources_Memory) MergeDatabaseClusterSpecProxyResourcesMemory1(v DatabaseClusterSpecProxyResourcesMemory1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t DatabaseCluster_Spec_Proxy_Resources_Memory) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DatabaseCluster_Spec_Proxy_Resources_Memory) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// RequestEditorFn  is the function signature for the RequestEditor callback function
type RequestEditorFn func(ctx context.Context, req *http.Request) error

// Doer performs HTTP requests.
//
// The standard http.Client implements this interface.
type HttpRequestDoer interface {
	Do(req *http.Request) (*http.Response, error)
}

// Client which conforms to the OpenAPI3 specification for this service.
type Client struct {
	// The endpoint of the server conforming to this interface, with scheme,
	// https://api.deepmap.com for example. This can contain a path relative
	// to the server, such as https://api.deepmap.com/dev-test, and all the
	// paths in the swagger spec will be appended to the server.
	Server string

	// Doer for performing requests, typically a *http.Client with any
	// customized settings, such as certificate chains.
	Client HttpRequestDoer

	// A list of callbacks for modifying requests which are generated before sending over
	// the network.
	RequestEditors []RequestEditorFn
}

// ClientOption allows setting custom parameters during construction
type ClientOption func(*Client) error

// Creates a new Client, with reasonable defaults
func NewClient(server string, opts ...ClientOption) (*Client, error) {
	// create a client with sane default values
	client := Client{
		Server: server,
	}
	// mutate client and add all optional params
	for _, o := range opts {
		if err := o(&client); err != nil {
			return nil, err
		}
	}
	// ensure the server URL always has a trailing slash
	if !strings.HasSuffix(client.Server, "/") {
		client.Server += "/"
	}
	// create httpClient, if not already present
	if client.Client == nil {
		client.Client = &http.Client{}
	}
	return &client, nil
}

// WithHTTPClient allows overriding the default Doer, which is
// automatically created using http.Client. This is useful for tests.
func WithHTTPClient(doer HttpRequestDoer) ClientOption {
	return func(c *Client) error {
		c.Client = doer
		return nil
	}
}

// WithRequestEditorFn allows setting up a callback function, which will be
// called right before sending the request. This can be used to mutate the request.
func WithRequestEditorFn(fn RequestEditorFn) ClientOption {
	return func(c *Client) error {
		c.RequestEditors = append(c.RequestEditors, fn)
		return nil
	}
}

// The interface specification for the client above.
type ClientInterface interface {
	// GetKubernetesClusterInfo request
	GetKubernetesClusterInfo(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListDataImporters request
	ListDataImporters(ctx context.Context, params *ListDataImportersParams, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListLoadBalancerConfig request
	ListLoadBalancerConfig(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error)

	// CreateLoadBalancerConfigWithBody request with any body
	CreateLoadBalancerConfigWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	CreateLoadBalancerConfig(ctx context.Context, body CreateLoadBalancerConfigJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// DeleteLoadBalancerConfig request
	DeleteLoadBalancerConfig(ctx context.Context, configName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetLoadBalancerConfig request
	GetLoadBalancerConfig(ctx context.Context, configName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// UpdateLoadBalancerConfigWithBody request with any body
	UpdateLoadBalancerConfigWithBody(ctx context.Context, configName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	UpdateLoadBalancerConfig(ctx context.Context, configName string, body UpdateLoadBalancerConfigJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListNamespaces request
	ListNamespaces(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListBackupStorages request
	ListBackupStorages(ctx context.Context, namespace string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// CreateBackupStorageWithBody request with any body
	CreateBackupStorageWithBody(ctx context.Context, namespace string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	CreateBackupStorage(ctx context.Context, namespace string, body CreateBackupStorageJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// DeleteBackupStorage request
	DeleteBackupStorage(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetBackupStorage request
	GetBackupStorage(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// UpdateBackupStorageWithBody request with any body
	UpdateBackupStorageWithBody(ctx context.Context, namespace string, name string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	UpdateBackupStorage(ctx context.Context, namespace string, name string, body UpdateBackupStorageJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// CreateDatabaseClusterBackupWithBody request with any body
	CreateDatabaseClusterBackupWithBody(ctx context.Context, namespace string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	CreateDatabaseClusterBackup(ctx context.Context, namespace string, body CreateDatabaseClusterBackupJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// DeleteDatabaseClusterBackup request
	DeleteDatabaseClusterBackup(ctx context.Context, namespace string, name string, params *DeleteDatabaseClusterBackupParams, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetDatabaseClusterBackup request
	GetDatabaseClusterBackup(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// CreateDatabaseClusterRestoreWithBody request with any body
	CreateDatabaseClusterRestoreWithBody(ctx context.Context, namespace string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	CreateDatabaseClusterRestore(ctx context.Context, namespace string, body CreateDatabaseClusterRestoreJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// DeleteDatabaseClusterRestore request
	DeleteDatabaseClusterRestore(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetDatabaseClusterRestore request
	GetDatabaseClusterRestore(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// UpdateDatabaseClusterRestoreWithBody request with any body
	UpdateDatabaseClusterRestoreWithBody(ctx context.Context, namespace string, name string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	UpdateDatabaseClusterRestore(ctx context.Context, namespace string, name string, body UpdateDatabaseClusterRestoreJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListDatabaseClusters request
	ListDatabaseClusters(ctx context.Context, namespace string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// CreateDatabaseClusterWithBody request with any body
	CreateDatabaseClusterWithBody(ctx context.Context, namespace string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	CreateDatabaseCluster(ctx context.Context, namespace string, body CreateDatabaseClusterJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListDatabaseClusterBackups request
	ListDatabaseClusterBackups(ctx context.Context, namespace string, clusterName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListDatabaseClusterRestores request
	ListDatabaseClusterRestores(ctx context.Context, namespace string, clusterName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListDataImportJobs request
	ListDataImportJobs(ctx context.Context, namespace string, dbName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// CreateDatabaseClusterSecretWithBody request with any body
	CreateDatabaseClusterSecretWithBody(ctx context.Context, namespace string, dbName string, params *CreateDatabaseClusterSecretParams, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	CreateDatabaseClusterSecret(ctx context.Context, namespace string, dbName string, params *CreateDatabaseClusterSecretParams, body CreateDatabaseClusterSecretJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// DeleteDatabaseCluster request
	DeleteDatabaseCluster(ctx context.Context, namespace string, name string, params *DeleteDatabaseClusterParams, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetDatabaseCluster request
	GetDatabaseCluster(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// UpdateDatabaseClusterWithBody request with any body
	UpdateDatabaseClusterWithBody(ctx context.Context, namespace string, name string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	UpdateDatabaseCluster(ctx context.Context, namespace string, name string, body UpdateDatabaseClusterJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetDatabaseClusterComponents request
	GetDatabaseClusterComponents(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetDatabaseClusterCredentials request
	GetDatabaseClusterCredentials(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetDatabaseClusterPitr request
	GetDatabaseClusterPitr(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListDatabaseEngines request
	ListDatabaseEngines(ctx context.Context, namespace string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetUpgradePlan request
	GetUpgradePlan(ctx context.Context, namespace string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ApproveUpgradePlanWithBody request with any body
	ApproveUpgradePlanWithBody(ctx context.Context, namespace string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	ApproveUpgradePlan(ctx context.Context, namespace string, body ApproveUpgradePlanJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetDatabaseEngine request
	GetDatabaseEngine(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// UpdateDatabaseEngineWithBody request with any body
	UpdateDatabaseEngineWithBody(ctx context.Context, namespace string, name string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	UpdateDatabaseEngine(ctx context.Context, namespace string, name string, body UpdateDatabaseEngineJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListSplitHorizonDNSConfigs request
	ListSplitHorizonDNSConfigs(ctx context.Context, namespace string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// CreateSplitHorizonDNSConfigWithBody request with any body
	CreateSplitHorizonDNSConfigWithBody(ctx context.Context, namespace string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	CreateSplitHorizonDNSConfig(ctx context.Context, namespace string, body CreateSplitHorizonDNSConfigJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// DeleteSplitHorizonDNSConfig request
	DeleteSplitHorizonDNSConfig(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetSplitHorizonDNSConfig request
	GetSplitHorizonDNSConfig(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// UpdateSplitHorizonDNSConfigWithBody request with any body
	UpdateSplitHorizonDNSConfigWithBody(ctx context.Context, namespace string, name string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	UpdateSplitHorizonDNSConfig(ctx context.Context, namespace string, name string, body UpdateSplitHorizonDNSConfigJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListMonitoringInstances request
	ListMonitoringInstances(ctx context.Context, namespace string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// CreateMonitoringInstanceWithBody request with any body
	CreateMonitoringInstanceWithBody(ctx context.Context, namespace string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	CreateMonitoringInstance(ctx context.Context, namespace string, body CreateMonitoringInstanceJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// DeleteMonitoringInstance request
	DeleteMonitoringInstance(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetMonitoringInstance request
	GetMonitoringInstance(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// UpdateMonitoringInstanceWithBody request with any body
	UpdateMonitoringInstanceWithBody(ctx context.Context, namespace string, name string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	UpdateMonitoringInstance(ctx context.Context, namespace string, name string, body UpdateMonitoringInstanceJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetUserPermissions request
	GetUserPermissions(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error)

	// ListPodSchedulingPolicy request
	ListPodSchedulingPolicy(ctx context.Context, params *ListPodSchedulingPolicyParams, reqEditors ...RequestEditorFn) (*http.Response, error)

	// CreatePodSchedulingPolicyWithBody request with any body
	CreatePodSchedulingPolicyWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	CreatePodSchedulingPolicy(ctx context.Context, body CreatePodSchedulingPolicyJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// DeletePodSchedulingPolicy request
	DeletePodSchedulingPolicy(ctx context.Context, policyName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetPodSchedulingPolicy request
	GetPodSchedulingPolicy(ctx context.Context, policyName string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// UpdatePodSchedulingPolicyWithBody request with any body
	UpdatePodSchedulingPolicyWithBody(ctx context.Context, policyName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	UpdatePodSchedulingPolicy(ctx context.Context, policyName string, body UpdatePodSchedulingPolicyJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetKubernetesClusterResources request
	GetKubernetesClusterResources(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error)

	// DeleteSession request
	DeleteSession(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error)

	// CreateSessionWithBody request with any body
	CreateSessionWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	CreateSession(ctx context.Context, body CreateSessionJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetSettings request
	GetSettings(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error)

	// VersionInfo request
	VersionInfo(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error)
}

func (c *Client) GetKubernetesClusterInfo(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetKubernetesClusterInfoRequest(c.Server)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListDataImporters(ctx context.Context, params *ListDataImportersParams, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListDataImportersRequest(c.Server, params)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListLoadBalancerConfig(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListLoadBalancerConfigRequest(c.Server)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateLoadBalancerConfigWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateLoadBalancerConfigRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateLoadBalancerConfig(ctx context.Context, body CreateLoadBalancerConfigJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateLoadBalancerConfigRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) DeleteLoadBalancerConfig(ctx context.Context, configName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewDeleteLoadBalancerConfigRequest(c.Server, configName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetLoadBalancerConfig(ctx context.Context, configName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetLoadBalancerConfigRequest(c.Server, configName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateLoadBalancerConfigWithBody(ctx context.Context, configName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateLoadBalancerConfigRequestWithBody(c.Server, configName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateLoadBalancerConfig(ctx context.Context, configName string, body UpdateLoadBalancerConfigJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateLoadBalancerConfigRequest(c.Server, configName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListNamespaces(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListNamespacesRequest(c.Server)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListBackupStorages(ctx context.Context, namespace string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListBackupStoragesRequest(c.Server, namespace)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateBackupStorageWithBody(ctx context.Context, namespace string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateBackupStorageRequestWithBody(c.Server, namespace, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateBackupStorage(ctx context.Context, namespace string, body CreateBackupStorageJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateBackupStorageRequest(c.Server, namespace, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) DeleteBackupStorage(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewDeleteBackupStorageRequest(c.Server, namespace, name)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetBackupStorage(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetBackupStorageRequest(c.Server, namespace, name)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateBackupStorageWithBody(ctx context.Context, namespace string, name string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateBackupStorageRequestWithBody(c.Server, namespace, name, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateBackupStorage(ctx context.Context, namespace string, name string, body UpdateBackupStorageJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateBackupStorageRequest(c.Server, namespace, name, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateDatabaseClusterBackupWithBody(ctx context.Context, namespace string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateDatabaseClusterBackupRequestWithBody(c.Server, namespace, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateDatabaseClusterBackup(ctx context.Context, namespace string, body CreateDatabaseClusterBackupJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateDatabaseClusterBackupRequest(c.Server, namespace, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) DeleteDatabaseClusterBackup(ctx context.Context, namespace string, name string, params *DeleteDatabaseClusterBackupParams, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewDeleteDatabaseClusterBackupRequest(c.Server, namespace, name, params)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetDatabaseClusterBackup(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetDatabaseClusterBackupRequest(c.Server, namespace, name)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateDatabaseClusterRestoreWithBody(ctx context.Context, namespace string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateDatabaseClusterRestoreRequestWithBody(c.Server, namespace, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateDatabaseClusterRestore(ctx context.Context, namespace string, body CreateDatabaseClusterRestoreJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateDatabaseClusterRestoreRequest(c.Server, namespace, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) DeleteDatabaseClusterRestore(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewDeleteDatabaseClusterRestoreRequest(c.Server, namespace, name)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetDatabaseClusterRestore(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetDatabaseClusterRestoreRequest(c.Server, namespace, name)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateDatabaseClusterRestoreWithBody(ctx context.Context, namespace string, name string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateDatabaseClusterRestoreRequestWithBody(c.Server, namespace, name, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateDatabaseClusterRestore(ctx context.Context, namespace string, name string, body UpdateDatabaseClusterRestoreJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateDatabaseClusterRestoreRequest(c.Server, namespace, name, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListDatabaseClusters(ctx context.Context, namespace string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListDatabaseClustersRequest(c.Server, namespace)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateDatabaseClusterWithBody(ctx context.Context, namespace string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateDatabaseClusterRequestWithBody(c.Server, namespace, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateDatabaseCluster(ctx context.Context, namespace string, body CreateDatabaseClusterJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateDatabaseClusterRequest(c.Server, namespace, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListDatabaseClusterBackups(ctx context.Context, namespace string, clusterName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListDatabaseClusterBackupsRequest(c.Server, namespace, clusterName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListDatabaseClusterRestores(ctx context.Context, namespace string, clusterName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListDatabaseClusterRestoresRequest(c.Server, namespace, clusterName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListDataImportJobs(ctx context.Context, namespace string, dbName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListDataImportJobsRequest(c.Server, namespace, dbName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateDatabaseClusterSecretWithBody(ctx context.Context, namespace string, dbName string, params *CreateDatabaseClusterSecretParams, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateDatabaseClusterSecretRequestWithBody(c.Server, namespace, dbName, params, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateDatabaseClusterSecret(ctx context.Context, namespace string, dbName string, params *CreateDatabaseClusterSecretParams, body CreateDatabaseClusterSecretJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateDatabaseClusterSecretRequest(c.Server, namespace, dbName, params, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) DeleteDatabaseCluster(ctx context.Context, namespace string, name string, params *DeleteDatabaseClusterParams, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewDeleteDatabaseClusterRequest(c.Server, namespace, name, params)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetDatabaseCluster(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetDatabaseClusterRequest(c.Server, namespace, name)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateDatabaseClusterWithBody(ctx context.Context, namespace string, name string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateDatabaseClusterRequestWithBody(c.Server, namespace, name, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateDatabaseCluster(ctx context.Context, namespace string, name string, body UpdateDatabaseClusterJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateDatabaseClusterRequest(c.Server, namespace, name, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetDatabaseClusterComponents(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetDatabaseClusterComponentsRequest(c.Server, namespace, name)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetDatabaseClusterCredentials(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetDatabaseClusterCredentialsRequest(c.Server, namespace, name)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetDatabaseClusterPitr(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetDatabaseClusterPitrRequest(c.Server, namespace, name)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListDatabaseEngines(ctx context.Context, namespace string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListDatabaseEnginesRequest(c.Server, namespace)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetUpgradePlan(ctx context.Context, namespace string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetUpgradePlanRequest(c.Server, namespace)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ApproveUpgradePlanWithBody(ctx context.Context, namespace string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewApproveUpgradePlanRequestWithBody(c.Server, namespace, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ApproveUpgradePlan(ctx context.Context, namespace string, body ApproveUpgradePlanJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewApproveUpgradePlanRequest(c.Server, namespace, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetDatabaseEngine(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetDatabaseEngineRequest(c.Server, namespace, name)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateDatabaseEngineWithBody(ctx context.Context, namespace string, name string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateDatabaseEngineRequestWithBody(c.Server, namespace, name, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateDatabaseEngine(ctx context.Context, namespace string, name string, body UpdateDatabaseEngineJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateDatabaseEngineRequest(c.Server, namespace, name, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListSplitHorizonDNSConfigs(ctx context.Context, namespace string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListSplitHorizonDNSConfigsRequest(c.Server, namespace)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateSplitHorizonDNSConfigWithBody(ctx context.Context, namespace string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateSplitHorizonDNSConfigRequestWithBody(c.Server, namespace, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateSplitHorizonDNSConfig(ctx context.Context, namespace string, body CreateSplitHorizonDNSConfigJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateSplitHorizonDNSConfigRequest(c.Server, namespace, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) DeleteSplitHorizonDNSConfig(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewDeleteSplitHorizonDNSConfigRequest(c.Server, namespace, name)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetSplitHorizonDNSConfig(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetSplitHorizonDNSConfigRequest(c.Server, namespace, name)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateSplitHorizonDNSConfigWithBody(ctx context.Context, namespace string, name string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateSplitHorizonDNSConfigRequestWithBody(c.Server, namespace, name, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateSplitHorizonDNSConfig(ctx context.Context, namespace string, name string, body UpdateSplitHorizonDNSConfigJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateSplitHorizonDNSConfigRequest(c.Server, namespace, name, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListMonitoringInstances(ctx context.Context, namespace string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListMonitoringInstancesRequest(c.Server, namespace)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateMonitoringInstanceWithBody(ctx context.Context, namespace string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateMonitoringInstanceRequestWithBody(c.Server, namespace, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateMonitoringInstance(ctx context.Context, namespace string, body CreateMonitoringInstanceJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateMonitoringInstanceRequest(c.Server, namespace, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) DeleteMonitoringInstance(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewDeleteMonitoringInstanceRequest(c.Server, namespace, name)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetMonitoringInstance(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetMonitoringInstanceRequest(c.Server, namespace, name)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateMonitoringInstanceWithBody(ctx context.Context, namespace string, name string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateMonitoringInstanceRequestWithBody(c.Server, namespace, name, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdateMonitoringInstance(ctx context.Context, namespace string, name string, body UpdateMonitoringInstanceJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdateMonitoringInstanceRequest(c.Server, namespace, name, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetUserPermissions(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetUserPermissionsRequest(c.Server)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) ListPodSchedulingPolicy(ctx context.Context, params *ListPodSchedulingPolicyParams, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewListPodSchedulingPolicyRequest(c.Server, params)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreatePodSchedulingPolicyWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreatePodSchedulingPolicyRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreatePodSchedulingPolicy(ctx context.Context, body CreatePodSchedulingPolicyJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreatePodSchedulingPolicyRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) DeletePodSchedulingPolicy(ctx context.Context, policyName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewDeletePodSchedulingPolicyRequest(c.Server, policyName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetPodSchedulingPolicy(ctx context.Context, policyName string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetPodSchedulingPolicyRequest(c.Server, policyName)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdatePodSchedulingPolicyWithBody(ctx context.Context, policyName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdatePodSchedulingPolicyRequestWithBody(c.Server, policyName, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) UpdatePodSchedulingPolicy(ctx context.Context, policyName string, body UpdatePodSchedulingPolicyJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewUpdatePodSchedulingPolicyRequest(c.Server, policyName, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetKubernetesClusterResources(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetKubernetesClusterResourcesRequest(c.Server)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) DeleteSession(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewDeleteSessionRequest(c.Server)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateSessionWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateSessionRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) CreateSession(ctx context.Context, body CreateSessionJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewCreateSessionRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetSettings(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetSettingsRequest(c.Server)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) VersionInfo(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewVersionInfoRequest(c.Server)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

// NewGetKubernetesClusterInfoRequest generates requests for GetKubernetesClusterInfo
func NewGetKubernetesClusterInfoRequest(server string) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/cluster-info")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewListDataImportersRequest generates requests for ListDataImporters
func NewListDataImportersRequest(server string, params *ListDataImportersParams) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/data-importers")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	if params != nil {
		queryValues := queryURL.Query()

		if params.SupportedEngines != nil {

			if queryFrag, err := runtime.StyleParamWithLocation("form", true, "supportedEngines", runtime.ParamLocationQuery, *params.SupportedEngines); err != nil {
				return nil, err
			} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
				return nil, err
			} else {
				for k, v := range parsed {
					for _, v2 := range v {
						queryValues.Add(k, v2)
					}
				}
			}

		}

		queryURL.RawQuery = queryValues.Encode()
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewListLoadBalancerConfigRequest generates requests for ListLoadBalancerConfig
func NewListLoadBalancerConfigRequest(server string) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/load-balancer-configs")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewCreateLoadBalancerConfigRequest calls the generic CreateLoadBalancerConfig builder with application/json body
func NewCreateLoadBalancerConfigRequest(server string, body CreateLoadBalancerConfigJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewCreateLoadBalancerConfigRequestWithBody(server, "application/json", bodyReader)
}

// NewCreateLoadBalancerConfigRequestWithBody generates requests for CreateLoadBalancerConfig with any type of body
func NewCreateLoadBalancerConfigRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/load-balancer-configs")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewDeleteLoadBalancerConfigRequest generates requests for DeleteLoadBalancerConfig
func NewDeleteLoadBalancerConfigRequest(server string, configName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "config-name", runtime.ParamLocationPath, configName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/load-balancer-configs/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetLoadBalancerConfigRequest generates requests for GetLoadBalancerConfig
func NewGetLoadBalancerConfigRequest(server string, configName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "config-name", runtime.ParamLocationPath, configName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/load-balancer-configs/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewUpdateLoadBalancerConfigRequest calls the generic UpdateLoadBalancerConfig builder with application/json body
func NewUpdateLoadBalancerConfigRequest(server string, configName string, body UpdateLoadBalancerConfigJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewUpdateLoadBalancerConfigRequestWithBody(server, configName, "application/json", bodyReader)
}

// NewUpdateLoadBalancerConfigRequestWithBody generates requests for UpdateLoadBalancerConfig with any type of body
func NewUpdateLoadBalancerConfigRequestWithBody(server string, configName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "config-name", runtime.ParamLocationPath, configName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/load-balancer-configs/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("PUT", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewListNamespacesRequest generates requests for ListNamespaces
func NewListNamespacesRequest(server string) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/namespaces")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewListBackupStoragesRequest generates requests for ListBackupStorages
func NewListBackupStoragesRequest(server string, namespace string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "namespace", runtime.ParamLocationPath, namespace)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/namespaces/%s/backup-storages", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewCreateBackupStorageRequest calls the generic CreateBackupStorage builder with application/json body
func NewCreateBackupStorageRequest(server string, namespace string, body CreateBackupStorageJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewCreateBackupStorageRequestWithBody(server, namespace, "application/json", bodyReader)
}

// NewCreateBackupStorageRequestWithBody generates requests for CreateBackupStorage with any type of body
func NewCreateBackupStorageRequestWithBody(server string, namespace string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "namespace", runtime.ParamLocationPath, namespace)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/namespaces/%s/backup-storages", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewDeleteBackupStorageRequest generates requests for DeleteBackupStorage
func NewDeleteBackupStorageRequest(server string, namespace string, name string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "namespace", runtime.ParamLocationPath, namespace)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "name", runtime.ParamLocationPath, name)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/namespaces/%s/backup-storages/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetBackupStorageRequest generates requests for GetBackupStorage
func NewGetBackupStorageRequest(server string, namespace string, name string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "namespace", runtime.ParamLocationPath, namespace)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "name", runtime.ParamLocationPath, name)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/namespaces/%s/backup-storages/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewUpdateBackupStorageRequest calls the generic UpdateBackupStorage builder with application/json body
func NewUpdateBackupStorageRequest(server string, namespace string, name string, body UpdateBackupStorageJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewUpdateBackupStorageRequestWithBody(server, namespace, name, "application/json", bodyReader)
}

// NewUpdateBackupStorageRequestWithBody generates requests for UpdateBackupStorage with any type of body
func NewUpdateBackupStorageRequestWithBody(server string, namespace string, name string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "namespace", runtime.ParamLocationPath, namespace)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "name", runtime.ParamLocationPath, name)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/namespaces/%s/backup-storages/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("PATCH", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewCreateDatabaseClusterBackupRequest calls the generic CreateDatabaseClusterBackup builder with application/json body
func NewCreateDatabaseClusterBackupRequest(server string, namespace string, body CreateDatabaseClusterBackupJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewCreateDatabaseClusterBackupRequestWithBody(server, namespace, "application/json", bodyReader)
}

// NewCreateDatabaseClusterBackupRequestWithBody generates requests for CreateDatabaseClusterBackup with any type of body
func NewCreateDatabaseClusterBackupRequestWithBody(server string, namespace string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "namespace", runtime.ParamLocationPath, namespace)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/namespaces/%s/database-cluster-backups", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewDeleteDatabaseClusterBackupRequest generates requests for DeleteDatabaseClusterBackup
func NewDeleteDatabaseClusterBackupRequest(server string, namespace string, name string, params *DeleteDatabaseClusterBackupParams) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "namespace", runtime.ParamLocationPath, namespace)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "name", runtime.ParamLocationPath, name)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/namespaces/%s/database-cluster-backups/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	if params != nil {
		queryValues := queryURL.Query()

		if params.CleanupBackupStorage != nil {

			if queryFrag, err := runtime.StyleParamWithLocation("form", true, "cleanupBackupStorage", runtime.ParamLocationQuery, *params.CleanupBackupStorage); err != nil {
				return nil, err
			} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
				return nil, err
			} else {
				for k, v := range parsed {
					for _, v2 := range v {
						queryValues.Add(k, v2)
					}
				}
			}

		}

		queryURL.RawQuery = queryValues.Encode()
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetDatabaseClusterBackupRequest generates requests for GetDatabaseClusterBackup
func NewGetDatabaseClusterBackupRequest(server string, namespace string, name string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "namespace", runtime.ParamLocationPath, namespace)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "name", runtime.ParamLocationPath, name)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/namespaces/%s/database-cluster-backups/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewCreateDatabaseClusterRestoreRequest calls the generic CreateDatabaseClusterRestore builder with application/json body
func NewCreateDatabaseClusterRestoreRequest(server string, namespace string, body CreateDatabaseClusterRestoreJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewCreateDatabaseClusterRestoreRequestWithBody(server, namespace, "application/json", bodyReader)
}

// NewCreateDatabaseClusterRestoreRequestWithBody generates requests for CreateDatabaseClusterRestore with any type of body
func NewCreateDatabaseClusterRestoreRequestWithBody(server string, namespace string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "namespace", runtime.ParamLocationPath, namespace)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/namespaces/%s/database-cluster-restores", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewDeleteDatabaseClusterRestoreRequest generates requests for DeleteDatabaseClusterRestore
func NewDeleteDatabaseClusterRestoreRequest(server string, namespace string, name string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "namespace", runtime.ParamLocationPath, namespace)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "name", runtime.ParamLocationPath, name)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/namespaces/%s/database-cluster-restores/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetDatabaseClusterRestoreRequest generates requests for GetDatabaseClusterRestore
func NewGetDatabaseClusterRestoreRequest(server string, namespace string, name string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "namespace", runtime.ParamLocationPath, namespace)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "name", runtime.ParamLocationPath, name)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/namespaces/%s/database-cluster-restores/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewUpdateDatabaseClusterRestoreRequest calls the generic UpdateDatabaseClusterRestore builder with application/json body
func NewUpdateDatabaseClusterRestoreRequest(server string, namespace string, name string, body UpdateDatabaseClusterRestoreJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewUpdateDatabaseClusterRestoreRequestWithBody(server, namespace, name, "application/json", bodyReader)
}

// NewUpdateDatabaseClusterRestoreRequestWithBody generates requests for UpdateDatabaseClusterRestore with any type of body
func NewUpdateDatabaseClusterRestoreRequestWithBody(server string, namespace string, name string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "namespace", runtime.ParamLocationPath, namespace)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "name", runtime.ParamLocationPath, name)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/namespaces/%s/database-cluster-restores/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("PUT", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewListDatabaseClustersRequest generates requests for ListDatabaseClusters
func NewListDatabaseClustersRequest(server string, namespace string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "namespace", runtime.ParamLocationPath, namespace)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/namespaces/%s/database-clusters", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewCreateDatabaseClusterRequest calls the generic CreateDatabaseCluster builder with application/json body
func NewCreateDatabaseClusterRequest(server string, namespace string, body CreateDatabaseClusterJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewCreateDatabaseClusterRequestWithBody(server, namespace, "application/json", bodyReader)
}

// NewCreateDatabaseClusterRequestWithBody generates requests for CreateDatabaseCluster with any type of body
func NewCreateDatabaseClusterRequestWithBody(server string, namespace string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "namespace", runtime.ParamLocationPath, namespace)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/namespaces/%s/database-clusters", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewListDatabaseClusterBackupsRequest generates requests for ListDatabaseClusterBackups
func NewListDatabaseClusterBackupsRequest(server string, namespace string, clusterName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "namespace", runtime.ParamLocationPath, namespace)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "cluster-name", runtime.ParamLocationPath, clusterName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/namespaces/%s/database-clusters/%s/backups", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewListDatabaseClusterRestoresRequest generates requests for ListDatabaseClusterRestores
func NewListDatabaseClusterRestoresRequest(server string, namespace string, clusterName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "namespace", runtime.ParamLocationPath, namespace)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "cluster-name", runtime.ParamLocationPath, clusterName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/namespaces/%s/database-clusters/%s/restores", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewListDataImportJobsRequest generates requests for ListDataImportJobs
func NewListDataImportJobsRequest(server string, namespace string, dbName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "namespace", runtime.ParamLocationPath, namespace)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "dbName", runtime.ParamLocationPath, dbName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/namespaces/%s/database-clusters/%s/data-import-jobs", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewCreateDatabaseClusterSecretRequest calls the generic CreateDatabaseClusterSecret builder with application/json body
func NewCreateDatabaseClusterSecretRequest(server string, namespace string, dbName string, params *CreateDatabaseClusterSecretParams, body CreateDatabaseClusterSecretJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewCreateDatabaseClusterSecretRequestWithBody(server, namespace, dbName, params, "application/json", bodyReader)
}

// NewCreateDatabaseClusterSecretRequestWithBody generates requests for CreateDatabaseClusterSecret with any type of body
func NewCreateDatabaseClusterSecretRequestWithBody(server string, namespace string, dbName string, params *CreateDatabaseClusterSecretParams, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "namespace", runtime.ParamLocationPath, namespace)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "dbName", runtime.ParamLocationPath, dbName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/namespaces/%s/database-clusters/%s/secret", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	if params != nil {
		queryValues := queryURL.Query()

		if params.SecretName != nil {

			if queryFrag, err := runtime.StyleParamWithLocation("form", true, "secretName", runtime.ParamLocationQuery, *params.SecretName); err != nil {
				return nil, err
			} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
				return nil, err
			} else {
				for k, v := range parsed {
					for _, v2 := range v {
						queryValues.Add(k, v2)
					}
				}
			}

		}

		queryURL.RawQuery = queryValues.Encode()
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewDeleteDatabaseClusterRequest generates requests for DeleteDatabaseCluster
func NewDeleteDatabaseClusterRequest(server string, namespace string, name string, params *DeleteDatabaseClusterParams) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "namespace", runtime.ParamLocationPath, namespace)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "name", runtime.ParamLocationPath, name)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/namespaces/%s/database-clusters/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	if params != nil {
		queryValues := queryURL.Query()

		if params.CleanupBackupStorage != nil {

			if queryFrag, err := runtime.StyleParamWithLocation("form", true, "cleanupBackupStorage", runtime.ParamLocationQuery, *params.CleanupBackupStorage); err != nil {
				return nil, err
			} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
				return nil, err
			} else {
				for k, v := range parsed {
					for _, v2 := range v {
						queryValues.Add(k, v2)
					}
				}
			}

		}

		queryURL.RawQuery = queryValues.Encode()
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetDatabaseClusterRequest generates requests for GetDatabaseCluster
func NewGetDatabaseClusterRequest(server string, namespace string, name string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "namespace", runtime.ParamLocationPath, namespace)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "name", runtime.ParamLocationPath, name)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/namespaces/%s/database-clusters/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewUpdateDatabaseClusterRequest calls the generic UpdateDatabaseCluster builder with application/json body
func NewUpdateDatabaseClusterRequest(server string, namespace string, name string, body UpdateDatabaseClusterJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewUpdateDatabaseClusterRequestWithBody(server, namespace, name, "application/json", bodyReader)
}

// NewUpdateDatabaseClusterRequestWithBody generates requests for UpdateDatabaseCluster with any type of body
func NewUpdateDatabaseClusterRequestWithBody(server string, namespace string, name string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "namespace", runtime.ParamLocationPath, namespace)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "name", runtime.ParamLocationPath, name)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/namespaces/%s/database-clusters/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("PUT", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewGetDatabaseClusterComponentsRequest generates requests for GetDatabaseClusterComponents
func NewGetDatabaseClusterComponentsRequest(server string, namespace string, name string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "namespace", runtime.ParamLocationPath, namespace)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "name", runtime.ParamLocationPath, name)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/namespaces/%s/database-clusters/%s/components", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetDatabaseClusterCredentialsRequest generates requests for GetDatabaseClusterCredentials
func NewGetDatabaseClusterCredentialsRequest(server string, namespace string, name string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "namespace", runtime.ParamLocationPath, namespace)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "name", runtime.ParamLocationPath, name)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/namespaces/%s/database-clusters/%s/credentials", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetDatabaseClusterPitrRequest generates requests for GetDatabaseClusterPitr
func NewGetDatabaseClusterPitrRequest(server string, namespace string, name string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "namespace", runtime.ParamLocationPath, namespace)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "name", runtime.ParamLocationPath, name)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/namespaces/%s/database-clusters/%s/pitr", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewListDatabaseEnginesRequest generates requests for ListDatabaseEngines
func NewListDatabaseEnginesRequest(server string, namespace string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "namespace", runtime.ParamLocationPath, namespace)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/namespaces/%s/database-engines", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetUpgradePlanRequest generates requests for GetUpgradePlan
func NewGetUpgradePlanRequest(server string, namespace string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "namespace", runtime.ParamLocationPath, namespace)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/namespaces/%s/database-engines/upgrade-plan", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewApproveUpgradePlanRequest calls the generic ApproveUpgradePlan builder with application/json body
func NewApproveUpgradePlanRequest(server string, namespace string, body ApproveUpgradePlanJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewApproveUpgradePlanRequestWithBody(server, namespace, "application/json", bodyReader)
}

// NewApproveUpgradePlanRequestWithBody generates requests for ApproveUpgradePlan with any type of body
func NewApproveUpgradePlanRequestWithBody(server string, namespace string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "namespace", runtime.ParamLocationPath, namespace)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/namespaces/%s/database-engines/upgrade-plan/approval", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewGetDatabaseEngineRequest generates requests for GetDatabaseEngine
func NewGetDatabaseEngineRequest(server string, namespace string, name string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "namespace", runtime.ParamLocationPath, namespace)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "name", runtime.ParamLocationPath, name)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/namespaces/%s/database-engines/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewUpdateDatabaseEngineRequest calls the generic UpdateDatabaseEngine builder with application/json body
func NewUpdateDatabaseEngineRequest(server string, namespace string, name string, body UpdateDatabaseEngineJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewUpdateDatabaseEngineRequestWithBody(server, namespace, name, "application/json", bodyReader)
}

// NewUpdateDatabaseEngineRequestWithBody generates requests for UpdateDatabaseEngine with any type of body
func NewUpdateDatabaseEngineRequestWithBody(server string, namespace string, name string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "namespace", runtime.ParamLocationPath, namespace)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "name", runtime.ParamLocationPath, name)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/namespaces/%s/database-engines/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("PUT", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewListSplitHorizonDNSConfigsRequest generates requests for ListSplitHorizonDNSConfigs
func NewListSplitHorizonDNSConfigsRequest(server string, namespace string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "namespace", runtime.ParamLocationPath, namespace)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/namespaces/%s/engine-features/split-horizon-dns-configs", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewCreateSplitHorizonDNSConfigRequest calls the generic CreateSplitHorizonDNSConfig builder with application/json body
func NewCreateSplitHorizonDNSConfigRequest(server string, namespace string, body CreateSplitHorizonDNSConfigJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewCreateSplitHorizonDNSConfigRequestWithBody(server, namespace, "application/json", bodyReader)
}

// NewCreateSplitHorizonDNSConfigRequestWithBody generates requests for CreateSplitHorizonDNSConfig with any type of body
func NewCreateSplitHorizonDNSConfigRequestWithBody(server string, namespace string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "namespace", runtime.ParamLocationPath, namespace)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/namespaces/%s/engine-features/split-horizon-dns-configs", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewDeleteSplitHorizonDNSConfigRequest generates requests for DeleteSplitHorizonDNSConfig
func NewDeleteSplitHorizonDNSConfigRequest(server string, namespace string, name string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "namespace", runtime.ParamLocationPath, namespace)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "name", runtime.ParamLocationPath, name)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/namespaces/%s/engine-features/split-horizon-dns-configs/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetSplitHorizonDNSConfigRequest generates requests for GetSplitHorizonDNSConfig
func NewGetSplitHorizonDNSConfigRequest(server string, namespace string, name string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "namespace", runtime.ParamLocationPath, namespace)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "name", runtime.ParamLocationPath, name)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/namespaces/%s/engine-features/split-horizon-dns-configs/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewUpdateSplitHorizonDNSConfigRequest calls the generic UpdateSplitHorizonDNSConfig builder with application/json body
func NewUpdateSplitHorizonDNSConfigRequest(server string, namespace string, name string, body UpdateSplitHorizonDNSConfigJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewUpdateSplitHorizonDNSConfigRequestWithBody(server, namespace, name, "application/json", bodyReader)
}

// NewUpdateSplitHorizonDNSConfigRequestWithBody generates requests for UpdateSplitHorizonDNSConfig with any type of body
func NewUpdateSplitHorizonDNSConfigRequestWithBody(server string, namespace string, name string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "namespace", runtime.ParamLocationPath, namespace)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "name", runtime.ParamLocationPath, name)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/namespaces/%s/engine-features/split-horizon-dns-configs/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("PATCH", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewListMonitoringInstancesRequest generates requests for ListMonitoringInstances
func NewListMonitoringInstancesRequest(server string, namespace string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "namespace", runtime.ParamLocationPath, namespace)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/namespaces/%s/monitoring-instances", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewCreateMonitoringInstanceRequest calls the generic CreateMonitoringInstance builder with application/json body
func NewCreateMonitoringInstanceRequest(server string, namespace string, body CreateMonitoringInstanceJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewCreateMonitoringInstanceRequestWithBody(server, namespace, "application/json", bodyReader)
}

// NewCreateMonitoringInstanceRequestWithBody generates requests for CreateMonitoringInstance with any type of body
func NewCreateMonitoringInstanceRequestWithBody(server string, namespace string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "namespace", runtime.ParamLocationPath, namespace)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/namespaces/%s/monitoring-instances", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewDeleteMonitoringInstanceRequest generates requests for DeleteMonitoringInstance
func NewDeleteMonitoringInstanceRequest(server string, namespace string, name string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "namespace", runtime.ParamLocationPath, namespace)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "name", runtime.ParamLocationPath, name)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/namespaces/%s/monitoring-instances/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetMonitoringInstanceRequest generates requests for GetMonitoringInstance
func NewGetMonitoringInstanceRequest(server string, namespace string, name string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "namespace", runtime.ParamLocationPath, namespace)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "name", runtime.ParamLocationPath, name)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/namespaces/%s/monitoring-instances/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewUpdateMonitoringInstanceRequest calls the generic UpdateMonitoringInstance builder with application/json body
func NewUpdateMonitoringInstanceRequest(server string, namespace string, name string, body UpdateMonitoringInstanceJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewUpdateMonitoringInstanceRequestWithBody(server, namespace, name, "application/json", bodyReader)
}

// NewUpdateMonitoringInstanceRequestWithBody generates requests for UpdateMonitoringInstance with any type of body
func NewUpdateMonitoringInstanceRequestWithBody(server string, namespace string, name string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "namespace", runtime.ParamLocationPath, namespace)
	if err != nil {
		return nil, err
	}

	var pathParam1 string

	pathParam1, err = runtime.StyleParamWithLocation("simple", false, "name", runtime.ParamLocationPath, name)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/namespaces/%s/monitoring-instances/%s", pathParam0, pathParam1)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("PATCH", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewGetUserPermissionsRequest generates requests for GetUserPermissions
func NewGetUserPermissionsRequest(server string) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/permissions")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewListPodSchedulingPolicyRequest generates requests for ListPodSchedulingPolicy
func NewListPodSchedulingPolicyRequest(server string, params *ListPodSchedulingPolicyParams) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/pod-scheduling-policies")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	if params != nil {
		queryValues := queryURL.Query()

		if params.EngineType != nil {

			if queryFrag, err := runtime.StyleParamWithLocation("form", true, "engineType", runtime.ParamLocationQuery, *params.EngineType); err != nil {
				return nil, err
			} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
				return nil, err
			} else {
				for k, v := range parsed {
					for _, v2 := range v {
						queryValues.Add(k, v2)
					}
				}
			}

		}

		if params.HasRules != nil {

			if queryFrag, err := runtime.StyleParamWithLocation("form", true, "hasRules", runtime.ParamLocationQuery, *params.HasRules); err != nil {
				return nil, err
			} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
				return nil, err
			} else {
				for k, v := range parsed {
					for _, v2 := range v {
						queryValues.Add(k, v2)
					}
				}
			}

		}

		queryURL.RawQuery = queryValues.Encode()
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewCreatePodSchedulingPolicyRequest calls the generic CreatePodSchedulingPolicy builder with application/json body
func NewCreatePodSchedulingPolicyRequest(server string, body CreatePodSchedulingPolicyJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewCreatePodSchedulingPolicyRequestWithBody(server, "application/json", bodyReader)
}

// NewCreatePodSchedulingPolicyRequestWithBody generates requests for CreatePodSchedulingPolicy with any type of body
func NewCreatePodSchedulingPolicyRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/pod-scheduling-policies")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewDeletePodSchedulingPolicyRequest generates requests for DeletePodSchedulingPolicy
func NewDeletePodSchedulingPolicyRequest(server string, policyName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "policy-name", runtime.ParamLocationPath, policyName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/pod-scheduling-policies/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetPodSchedulingPolicyRequest generates requests for GetPodSchedulingPolicy
func NewGetPodSchedulingPolicyRequest(server string, policyName string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "policy-name", runtime.ParamLocationPath, policyName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/pod-scheduling-policies/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewUpdatePodSchedulingPolicyRequest calls the generic UpdatePodSchedulingPolicy builder with application/json body
func NewUpdatePodSchedulingPolicyRequest(server string, policyName string, body UpdatePodSchedulingPolicyJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewUpdatePodSchedulingPolicyRequestWithBody(server, policyName, "application/json", bodyReader)
}

// NewUpdatePodSchedulingPolicyRequestWithBody generates requests for UpdatePodSchedulingPolicy with any type of body
func NewUpdatePodSchedulingPolicyRequestWithBody(server string, policyName string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "policy-name", runtime.ParamLocationPath, policyName)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/pod-scheduling-policies/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("PUT", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewGetKubernetesClusterResourcesRequest generates requests for GetKubernetesClusterResources
func NewGetKubernetesClusterResourcesRequest(server string) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/resources")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewDeleteSessionRequest generates requests for DeleteSession
func NewDeleteSessionRequest(server string) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/session")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("DELETE", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewCreateSessionRequest calls the generic CreateSession builder with application/json body
func NewCreateSessionRequest(server string, body CreateSessionJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewCreateSessionRequestWithBody(server, "application/json", bodyReader)
}

// NewCreateSessionRequestWithBody generates requests for CreateSession with any type of body
func NewCreateSessionRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/session")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewGetSettingsRequest generates requests for GetSettings
func NewGetSettingsRequest(server string) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/settings")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewVersionInfoRequest generates requests for VersionInfo
func NewVersionInfoRequest(server string) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/version")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

func (c *Client) applyEditors(ctx context.Context, req *http.Request, additionalEditors []RequestEditorFn) error {
	for _, r := range c.RequestEditors {
		if err := r(ctx, req); err != nil {
			return err
		}
	}
	for _, r := range additionalEditors {
		if err := r(ctx, req); err != nil {
			return err
		}
	}
	return nil
}

// ClientWithResponses builds on ClientInterface to offer response payloads
type ClientWithResponses struct {
	ClientInterface
}

// NewClientWithResponses creates a new ClientWithResponses, which wraps
// Client with return type handling
func NewClientWithResponses(server string, opts ...ClientOption) (*ClientWithResponses, error) {
	client, err := NewClient(server, opts...)
	if err != nil {
		return nil, err
	}
	return &ClientWithResponses{client}, nil
}

// WithBaseURL overrides the baseURL.
func WithBaseURL(baseURL string) ClientOption {
	return func(c *Client) error {
		newBaseURL, err := url.Parse(baseURL)
		if err != nil {
			return err
		}
		c.Server = newBaseURL.String()
		return nil
	}
}

// ClientWithResponsesInterface is the interface specification for the client with responses above.
type ClientWithResponsesInterface interface {
	// GetKubernetesClusterInfoWithResponse request
	GetKubernetesClusterInfoWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetKubernetesClusterInfoResponse, error)

	// ListDataImportersWithResponse request
	ListDataImportersWithResponse(ctx context.Context, params *ListDataImportersParams, reqEditors ...RequestEditorFn) (*ListDataImportersResponse, error)

	// ListLoadBalancerConfigWithResponse request
	ListLoadBalancerConfigWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*ListLoadBalancerConfigResponse, error)

	// CreateLoadBalancerConfigWithBodyWithResponse request with any body
	CreateLoadBalancerConfigWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateLoadBalancerConfigResponse, error)

	CreateLoadBalancerConfigWithResponse(ctx context.Context, body CreateLoadBalancerConfigJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateLoadBalancerConfigResponse, error)

	// DeleteLoadBalancerConfigWithResponse request
	DeleteLoadBalancerConfigWithResponse(ctx context.Context, configName string, reqEditors ...RequestEditorFn) (*DeleteLoadBalancerConfigResponse, error)

	// GetLoadBalancerConfigWithResponse request
	GetLoadBalancerConfigWithResponse(ctx context.Context, configName string, reqEditors ...RequestEditorFn) (*GetLoadBalancerConfigResponse, error)

	// UpdateLoadBalancerConfigWithBodyWithResponse request with any body
	UpdateLoadBalancerConfigWithBodyWithResponse(ctx context.Context, configName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateLoadBalancerConfigResponse, error)

	UpdateLoadBalancerConfigWithResponse(ctx context.Context, configName string, body UpdateLoadBalancerConfigJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateLoadBalancerConfigResponse, error)

	// ListNamespacesWithResponse request
	ListNamespacesWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*ListNamespacesResponse, error)

	// ListBackupStoragesWithResponse request
	ListBackupStoragesWithResponse(ctx context.Context, namespace string, reqEditors ...RequestEditorFn) (*ListBackupStoragesResponse, error)

	// CreateBackupStorageWithBodyWithResponse request with any body
	CreateBackupStorageWithBodyWithResponse(ctx context.Context, namespace string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateBackupStorageResponse, error)

	CreateBackupStorageWithResponse(ctx context.Context, namespace string, body CreateBackupStorageJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateBackupStorageResponse, error)

	// DeleteBackupStorageWithResponse request
	DeleteBackupStorageWithResponse(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*DeleteBackupStorageResponse, error)

	// GetBackupStorageWithResponse request
	GetBackupStorageWithResponse(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*GetBackupStorageResponse, error)

	// UpdateBackupStorageWithBodyWithResponse request with any body
	UpdateBackupStorageWithBodyWithResponse(ctx context.Context, namespace string, name string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateBackupStorageResponse, error)

	UpdateBackupStorageWithResponse(ctx context.Context, namespace string, name string, body UpdateBackupStorageJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateBackupStorageResponse, error)

	// CreateDatabaseClusterBackupWithBodyWithResponse request with any body
	CreateDatabaseClusterBackupWithBodyWithResponse(ctx context.Context, namespace string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateDatabaseClusterBackupResponse, error)

	CreateDatabaseClusterBackupWithResponse(ctx context.Context, namespace string, body CreateDatabaseClusterBackupJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateDatabaseClusterBackupResponse, error)

	// DeleteDatabaseClusterBackupWithResponse request
	DeleteDatabaseClusterBackupWithResponse(ctx context.Context, namespace string, name string, params *DeleteDatabaseClusterBackupParams, reqEditors ...RequestEditorFn) (*DeleteDatabaseClusterBackupResponse, error)

	// GetDatabaseClusterBackupWithResponse request
	GetDatabaseClusterBackupWithResponse(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*GetDatabaseClusterBackupResponse, error)

	// CreateDatabaseClusterRestoreWithBodyWithResponse request with any body
	CreateDatabaseClusterRestoreWithBodyWithResponse(ctx context.Context, namespace string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateDatabaseClusterRestoreResponse, error)

	CreateDatabaseClusterRestoreWithResponse(ctx context.Context, namespace string, body CreateDatabaseClusterRestoreJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateDatabaseClusterRestoreResponse, error)

	// DeleteDatabaseClusterRestoreWithResponse request
	DeleteDatabaseClusterRestoreWithResponse(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*DeleteDatabaseClusterRestoreResponse, error)

	// GetDatabaseClusterRestoreWithResponse request
	GetDatabaseClusterRestoreWithResponse(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*GetDatabaseClusterRestoreResponse, error)

	// UpdateDatabaseClusterRestoreWithBodyWithResponse request with any body
	UpdateDatabaseClusterRestoreWithBodyWithResponse(ctx context.Context, namespace string, name string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateDatabaseClusterRestoreResponse, error)

	UpdateDatabaseClusterRestoreWithResponse(ctx context.Context, namespace string, name string, body UpdateDatabaseClusterRestoreJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateDatabaseClusterRestoreResponse, error)

	// ListDatabaseClustersWithResponse request
	ListDatabaseClustersWithResponse(ctx context.Context, namespace string, reqEditors ...RequestEditorFn) (*ListDatabaseClustersResponse, error)

	// CreateDatabaseClusterWithBodyWithResponse request with any body
	CreateDatabaseClusterWithBodyWithResponse(ctx context.Context, namespace string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateDatabaseClusterResponse, error)

	CreateDatabaseClusterWithResponse(ctx context.Context, namespace string, body CreateDatabaseClusterJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateDatabaseClusterResponse, error)

	// ListDatabaseClusterBackupsWithResponse request
	ListDatabaseClusterBackupsWithResponse(ctx context.Context, namespace string, clusterName string, reqEditors ...RequestEditorFn) (*ListDatabaseClusterBackupsResponse, error)

	// ListDatabaseClusterRestoresWithResponse request
	ListDatabaseClusterRestoresWithResponse(ctx context.Context, namespace string, clusterName string, reqEditors ...RequestEditorFn) (*ListDatabaseClusterRestoresResponse, error)

	// ListDataImportJobsWithResponse request
	ListDataImportJobsWithResponse(ctx context.Context, namespace string, dbName string, reqEditors ...RequestEditorFn) (*ListDataImportJobsResponse, error)

	// CreateDatabaseClusterSecretWithBodyWithResponse request with any body
	CreateDatabaseClusterSecretWithBodyWithResponse(ctx context.Context, namespace string, dbName string, params *CreateDatabaseClusterSecretParams, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateDatabaseClusterSecretResponse, error)

	CreateDatabaseClusterSecretWithResponse(ctx context.Context, namespace string, dbName string, params *CreateDatabaseClusterSecretParams, body CreateDatabaseClusterSecretJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateDatabaseClusterSecretResponse, error)

	// DeleteDatabaseClusterWithResponse request
	DeleteDatabaseClusterWithResponse(ctx context.Context, namespace string, name string, params *DeleteDatabaseClusterParams, reqEditors ...RequestEditorFn) (*DeleteDatabaseClusterResponse, error)

	// GetDatabaseClusterWithResponse request
	GetDatabaseClusterWithResponse(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*GetDatabaseClusterResponse, error)

	// UpdateDatabaseClusterWithBodyWithResponse request with any body
	UpdateDatabaseClusterWithBodyWithResponse(ctx context.Context, namespace string, name string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateDatabaseClusterResponse, error)

	UpdateDatabaseClusterWithResponse(ctx context.Context, namespace string, name string, body UpdateDatabaseClusterJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateDatabaseClusterResponse, error)

	// GetDatabaseClusterComponentsWithResponse request
	GetDatabaseClusterComponentsWithResponse(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*GetDatabaseClusterComponentsResponse, error)

	// GetDatabaseClusterCredentialsWithResponse request
	GetDatabaseClusterCredentialsWithResponse(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*GetDatabaseClusterCredentialsResponse, error)

	// GetDatabaseClusterPitrWithResponse request
	GetDatabaseClusterPitrWithResponse(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*GetDatabaseClusterPitrResponse, error)

	// ListDatabaseEnginesWithResponse request
	ListDatabaseEnginesWithResponse(ctx context.Context, namespace string, reqEditors ...RequestEditorFn) (*ListDatabaseEnginesResponse, error)

	// GetUpgradePlanWithResponse request
	GetUpgradePlanWithResponse(ctx context.Context, namespace string, reqEditors ...RequestEditorFn) (*GetUpgradePlanResponse, error)

	// ApproveUpgradePlanWithBodyWithResponse request with any body
	ApproveUpgradePlanWithBodyWithResponse(ctx context.Context, namespace string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*ApproveUpgradePlanResponse, error)

	ApproveUpgradePlanWithResponse(ctx context.Context, namespace string, body ApproveUpgradePlanJSONRequestBody, reqEditors ...RequestEditorFn) (*ApproveUpgradePlanResponse, error)

	// GetDatabaseEngineWithResponse request
	GetDatabaseEngineWithResponse(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*GetDatabaseEngineResponse, error)

	// UpdateDatabaseEngineWithBodyWithResponse request with any body
	UpdateDatabaseEngineWithBodyWithResponse(ctx context.Context, namespace string, name string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateDatabaseEngineResponse, error)

	UpdateDatabaseEngineWithResponse(ctx context.Context, namespace string, name string, body UpdateDatabaseEngineJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateDatabaseEngineResponse, error)

	// ListSplitHorizonDNSConfigsWithResponse request
	ListSplitHorizonDNSConfigsWithResponse(ctx context.Context, namespace string, reqEditors ...RequestEditorFn) (*ListSplitHorizonDNSConfigsResponse, error)

	// CreateSplitHorizonDNSConfigWithBodyWithResponse request with any body
	CreateSplitHorizonDNSConfigWithBodyWithResponse(ctx context.Context, namespace string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateSplitHorizonDNSConfigResponse, error)

	CreateSplitHorizonDNSConfigWithResponse(ctx context.Context, namespace string, body CreateSplitHorizonDNSConfigJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateSplitHorizonDNSConfigResponse, error)

	// DeleteSplitHorizonDNSConfigWithResponse request
	DeleteSplitHorizonDNSConfigWithResponse(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*DeleteSplitHorizonDNSConfigResponse, error)

	// GetSplitHorizonDNSConfigWithResponse request
	GetSplitHorizonDNSConfigWithResponse(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*GetSplitHorizonDNSConfigResponse, error)

	// UpdateSplitHorizonDNSConfigWithBodyWithResponse request with any body
	UpdateSplitHorizonDNSConfigWithBodyWithResponse(ctx context.Context, namespace string, name string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateSplitHorizonDNSConfigResponse, error)

	UpdateSplitHorizonDNSConfigWithResponse(ctx context.Context, namespace string, name string, body UpdateSplitHorizonDNSConfigJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateSplitHorizonDNSConfigResponse, error)

	// ListMonitoringInstancesWithResponse request
	ListMonitoringInstancesWithResponse(ctx context.Context, namespace string, reqEditors ...RequestEditorFn) (*ListMonitoringInstancesResponse, error)

	// CreateMonitoringInstanceWithBodyWithResponse request with any body
	CreateMonitoringInstanceWithBodyWithResponse(ctx context.Context, namespace string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateMonitoringInstanceResponse, error)

	CreateMonitoringInstanceWithResponse(ctx context.Context, namespace string, body CreateMonitoringInstanceJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateMonitoringInstanceResponse, error)

	// DeleteMonitoringInstanceWithResponse request
	DeleteMonitoringInstanceWithResponse(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*DeleteMonitoringInstanceResponse, error)

	// GetMonitoringInstanceWithResponse request
	GetMonitoringInstanceWithResponse(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*GetMonitoringInstanceResponse, error)

	// UpdateMonitoringInstanceWithBodyWithResponse request with any body
	UpdateMonitoringInstanceWithBodyWithResponse(ctx context.Context, namespace string, name string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateMonitoringInstanceResponse, error)

	UpdateMonitoringInstanceWithResponse(ctx context.Context, namespace string, name string, body UpdateMonitoringInstanceJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateMonitoringInstanceResponse, error)

	// GetUserPermissionsWithResponse request
	GetUserPermissionsWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetUserPermissionsResponse, error)

	// ListPodSchedulingPolicyWithResponse request
	ListPodSchedulingPolicyWithResponse(ctx context.Context, params *ListPodSchedulingPolicyParams, reqEditors ...RequestEditorFn) (*ListPodSchedulingPolicyResponse, error)

	// CreatePodSchedulingPolicyWithBodyWithResponse request with any body
	CreatePodSchedulingPolicyWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreatePodSchedulingPolicyResponse, error)

	CreatePodSchedulingPolicyWithResponse(ctx context.Context, body CreatePodSchedulingPolicyJSONRequestBody, reqEditors ...RequestEditorFn) (*CreatePodSchedulingPolicyResponse, error)

	// DeletePodSchedulingPolicyWithResponse request
	DeletePodSchedulingPolicyWithResponse(ctx context.Context, policyName string, reqEditors ...RequestEditorFn) (*DeletePodSchedulingPolicyResponse, error)

	// GetPodSchedulingPolicyWithResponse request
	GetPodSchedulingPolicyWithResponse(ctx context.Context, policyName string, reqEditors ...RequestEditorFn) (*GetPodSchedulingPolicyResponse, error)

	// UpdatePodSchedulingPolicyWithBodyWithResponse request with any body
	UpdatePodSchedulingPolicyWithBodyWithResponse(ctx context.Context, policyName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdatePodSchedulingPolicyResponse, error)

	UpdatePodSchedulingPolicyWithResponse(ctx context.Context, policyName string, body UpdatePodSchedulingPolicyJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdatePodSchedulingPolicyResponse, error)

	// GetKubernetesClusterResourcesWithResponse request
	GetKubernetesClusterResourcesWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetKubernetesClusterResourcesResponse, error)

	// DeleteSessionWithResponse request
	DeleteSessionWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*DeleteSessionResponse, error)

	// CreateSessionWithBodyWithResponse request with any body
	CreateSessionWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateSessionResponse, error)

	CreateSessionWithResponse(ctx context.Context, body CreateSessionJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateSessionResponse, error)

	// GetSettingsWithResponse request
	GetSettingsWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetSettingsResponse, error)

	// VersionInfoWithResponse request
	VersionInfoWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*VersionInfoResponse, error)
}

type GetKubernetesClusterInfoResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *KubernetesClusterInfo
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetKubernetesClusterInfoResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetKubernetesClusterInfoResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListDataImportersResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *DataImporterList
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r ListDataImportersResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListDataImportersResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListLoadBalancerConfigResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *LoadBalancerConfigList
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r ListLoadBalancerConfigResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListLoadBalancerConfigResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type CreateLoadBalancerConfigResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *LoadBalancerConfig
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r CreateLoadBalancerConfigResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r CreateLoadBalancerConfigResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type DeleteLoadBalancerConfigResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *IoK8sApimachineryPkgApisMetaV1StatusV2
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r DeleteLoadBalancerConfigResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r DeleteLoadBalancerConfigResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetLoadBalancerConfigResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *LoadBalancerConfig
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetLoadBalancerConfigResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetLoadBalancerConfigResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type UpdateLoadBalancerConfigResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *LoadBalancerConfig
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r UpdateLoadBalancerConfigResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r UpdateLoadBalancerConfigResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListNamespacesResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *NamespaceList
}

// Status returns HTTPResponse.Status
func (r ListNamespacesResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListNamespacesResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListBackupStoragesResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *BackupStoragesList
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r ListBackupStoragesResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListBackupStoragesResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type CreateBackupStorageResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *BackupStorage
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r CreateBackupStorageResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r CreateBackupStorageResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type DeleteBackupStorageResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r DeleteBackupStorageResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r DeleteBackupStorageResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetBackupStorageResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *BackupStorage
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetBackupStorageResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetBackupStorageResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type UpdateBackupStorageResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *BackupStorage
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r UpdateBackupStorageResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r UpdateBackupStorageResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type CreateDatabaseClusterBackupResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *DatabaseClusterBackup
	JSON201      *DatabaseClusterBackup
	JSON202      *DatabaseClusterBackup
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r CreateDatabaseClusterBackupResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r CreateDatabaseClusterBackupResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type DeleteDatabaseClusterBackupResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *IoK8sApimachineryPkgApisMetaV1StatusV2
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r DeleteDatabaseClusterBackupResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r DeleteDatabaseClusterBackupResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetDatabaseClusterBackupResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *DatabaseClusterBackup
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetDatabaseClusterBackupResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetDatabaseClusterBackupResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type CreateDatabaseClusterRestoreResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *DatabaseClusterRestore
	JSON201      *DatabaseClusterRestore
	JSON202      *DatabaseClusterRestore
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r CreateDatabaseClusterRestoreResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r CreateDatabaseClusterRestoreResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type DeleteDatabaseClusterRestoreResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *IoK8sApimachineryPkgApisMetaV1StatusV2
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r DeleteDatabaseClusterRestoreResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r DeleteDatabaseClusterRestoreResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetDatabaseClusterRestoreResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *DatabaseClusterRestore
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetDatabaseClusterRestoreResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetDatabaseClusterRestoreResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type UpdateDatabaseClusterRestoreResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *DatabaseClusterRestore
	JSON201      *DatabaseClusterRestore
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r UpdateDatabaseClusterRestoreResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r UpdateDatabaseClusterRestoreResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListDatabaseClustersResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *DatabaseClusterList
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r ListDatabaseClustersResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListDatabaseClustersResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type CreateDatabaseClusterResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *DatabaseCluster
	JSON201      *DatabaseCluster
	JSON202      *DatabaseCluster
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r CreateDatabaseClusterResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r CreateDatabaseClusterResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListDatabaseClusterBackupsResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *DatabaseClusterBackupList
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r ListDatabaseClusterBackupsResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListDatabaseClusterBackupsResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListDatabaseClusterRestoresResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *DatabaseClusterRestoreList
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r ListDatabaseClusterRestoresResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListDatabaseClusterRestoresResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListDataImportJobsResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *DataImportJobList
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r ListDataImportJobsResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListDataImportJobsResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type CreateDatabaseClusterSecretResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *Secret
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r CreateDatabaseClusterSecretResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r CreateDatabaseClusterSecretResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type DeleteDatabaseClusterResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *IoK8sApimachineryPkgApisMetaV1StatusV2
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r DeleteDatabaseClusterResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r DeleteDatabaseClusterResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetDatabaseClusterResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *DatabaseCluster
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetDatabaseClusterResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetDatabaseClusterResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type UpdateDatabaseClusterResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *DatabaseCluster
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r UpdateDatabaseClusterResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r UpdateDatabaseClusterResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetDatabaseClusterComponentsResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *DatabaseClusterComponents
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetDatabaseClusterComponentsResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetDatabaseClusterComponentsResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetDatabaseClusterCredentialsResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *DatabaseClusterCredential
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetDatabaseClusterCredentialsResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetDatabaseClusterCredentialsResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetDatabaseClusterPitrResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *DatabaseClusterPitr
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetDatabaseClusterPitrResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetDatabaseClusterPitrResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListDatabaseEnginesResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *DatabaseEngineList
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r ListDatabaseEnginesResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListDatabaseEnginesResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetUpgradePlanResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *UpgradePlan
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetUpgradePlanResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetUpgradePlanResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ApproveUpgradePlanResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r ApproveUpgradePlanResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ApproveUpgradePlanResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetDatabaseEngineResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *DatabaseEngine
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetDatabaseEngineResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetDatabaseEngineResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type UpdateDatabaseEngineResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *DatabaseEngine
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r UpdateDatabaseEngineResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r UpdateDatabaseEngineResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListSplitHorizonDNSConfigsResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *SplitHorizonDNSConfigList
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r ListSplitHorizonDNSConfigsResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListSplitHorizonDNSConfigsResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type CreateSplitHorizonDNSConfigResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *SplitHorizonDNSConfig
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r CreateSplitHorizonDNSConfigResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r CreateSplitHorizonDNSConfigResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type DeleteSplitHorizonDNSConfigResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r DeleteSplitHorizonDNSConfigResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r DeleteSplitHorizonDNSConfigResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetSplitHorizonDNSConfigResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *SplitHorizonDNSConfig
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetSplitHorizonDNSConfigResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetSplitHorizonDNSConfigResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type UpdateSplitHorizonDNSConfigResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *SplitHorizonDNSConfig
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r UpdateSplitHorizonDNSConfigResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r UpdateSplitHorizonDNSConfigResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListMonitoringInstancesResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *MonitoringInstancesList
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r ListMonitoringInstancesResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListMonitoringInstancesResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type CreateMonitoringInstanceResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *MonitoringInstance
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r CreateMonitoringInstanceResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r CreateMonitoringInstanceResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type DeleteMonitoringInstanceResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r DeleteMonitoringInstanceResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r DeleteMonitoringInstanceResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetMonitoringInstanceResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *MonitoringInstance
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetMonitoringInstanceResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetMonitoringInstanceResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type UpdateMonitoringInstanceResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *MonitoringInstance
	JSON400      *Error
	JSON404      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r UpdateMonitoringInstanceResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r UpdateMonitoringInstanceResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetUserPermissionsResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *UserPermissions
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetUserPermissionsResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetUserPermissionsResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type ListPodSchedulingPolicyResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *PodSchedulingPolicyList
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r ListPodSchedulingPolicyResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r ListPodSchedulingPolicyResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type CreatePodSchedulingPolicyResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *PodSchedulingPolicy
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r CreatePodSchedulingPolicyResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r CreatePodSchedulingPolicyResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type DeletePodSchedulingPolicyResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *IoK8sApimachineryPkgApisMetaV1StatusV2
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r DeletePodSchedulingPolicyResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r DeletePodSchedulingPolicyResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetPodSchedulingPolicyResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *PodSchedulingPolicy
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetPodSchedulingPolicyResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetPodSchedulingPolicyResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type UpdatePodSchedulingPolicyResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *PodSchedulingPolicy
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r UpdatePodSchedulingPolicyResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r UpdatePodSchedulingPolicyResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetKubernetesClusterResourcesResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *KubernetesClusterResources
	JSON400      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r GetKubernetesClusterResourcesResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetKubernetesClusterResourcesResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type DeleteSessionResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON429      *Error
	JSON500      *Error
}

// Status returns HTTPResponse.Status
func (r DeleteSessionResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r DeleteSessionResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type CreateSessionResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *struct {
		Token *string `json:"token,omitempty"`
	}
	JSON400 *Error
	JSON429 *Error
	JSON500 *Error
}

// Status returns HTTPResponse.Status
func (r CreateSessionResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r CreateSessionResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetSettingsResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *Settings
}

// Status returns HTTPResponse.Status
func (r GetSettingsResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetSettingsResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type VersionInfoResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *Version
}

// Status returns HTTPResponse.Status
func (r VersionInfoResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r VersionInfoResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

// GetKubernetesClusterInfoWithResponse request returning *GetKubernetesClusterInfoResponse
func (c *ClientWithResponses) GetKubernetesClusterInfoWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetKubernetesClusterInfoResponse, error) {
	rsp, err := c.GetKubernetesClusterInfo(ctx, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetKubernetesClusterInfoResponse(rsp)
}

// ListDataImportersWithResponse request returning *ListDataImportersResponse
func (c *ClientWithResponses) ListDataImportersWithResponse(ctx context.Context, params *ListDataImportersParams, reqEditors ...RequestEditorFn) (*ListDataImportersResponse, error) {
	rsp, err := c.ListDataImporters(ctx, params, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListDataImportersResponse(rsp)
}

// ListLoadBalancerConfigWithResponse request returning *ListLoadBalancerConfigResponse
func (c *ClientWithResponses) ListLoadBalancerConfigWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*ListLoadBalancerConfigResponse, error) {
	rsp, err := c.ListLoadBalancerConfig(ctx, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListLoadBalancerConfigResponse(rsp)
}

// CreateLoadBalancerConfigWithBodyWithResponse request with arbitrary body returning *CreateLoadBalancerConfigResponse
func (c *ClientWithResponses) CreateLoadBalancerConfigWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateLoadBalancerConfigResponse, error) {
	rsp, err := c.CreateLoadBalancerConfigWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateLoadBalancerConfigResponse(rsp)
}

func (c *ClientWithResponses) CreateLoadBalancerConfigWithResponse(ctx context.Context, body CreateLoadBalancerConfigJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateLoadBalancerConfigResponse, error) {
	rsp, err := c.CreateLoadBalancerConfig(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateLoadBalancerConfigResponse(rsp)
}

// DeleteLoadBalancerConfigWithResponse request returning *DeleteLoadBalancerConfigResponse
func (c *ClientWithResponses) DeleteLoadBalancerConfigWithResponse(ctx context.Context, configName string, reqEditors ...RequestEditorFn) (*DeleteLoadBalancerConfigResponse, error) {
	rsp, err := c.DeleteLoadBalancerConfig(ctx, configName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseDeleteLoadBalancerConfigResponse(rsp)
}

// GetLoadBalancerConfigWithResponse request returning *GetLoadBalancerConfigResponse
func (c *ClientWithResponses) GetLoadBalancerConfigWithResponse(ctx context.Context, configName string, reqEditors ...RequestEditorFn) (*GetLoadBalancerConfigResponse, error) {
	rsp, err := c.GetLoadBalancerConfig(ctx, configName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetLoadBalancerConfigResponse(rsp)
}

// UpdateLoadBalancerConfigWithBodyWithResponse request with arbitrary body returning *UpdateLoadBalancerConfigResponse
func (c *ClientWithResponses) UpdateLoadBalancerConfigWithBodyWithResponse(ctx context.Context, configName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateLoadBalancerConfigResponse, error) {
	rsp, err := c.UpdateLoadBalancerConfigWithBody(ctx, configName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateLoadBalancerConfigResponse(rsp)
}

func (c *ClientWithResponses) UpdateLoadBalancerConfigWithResponse(ctx context.Context, configName string, body UpdateLoadBalancerConfigJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateLoadBalancerConfigResponse, error) {
	rsp, err := c.UpdateLoadBalancerConfig(ctx, configName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateLoadBalancerConfigResponse(rsp)
}

// ListNamespacesWithResponse request returning *ListNamespacesResponse
func (c *ClientWithResponses) ListNamespacesWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*ListNamespacesResponse, error) {
	rsp, err := c.ListNamespaces(ctx, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListNamespacesResponse(rsp)
}

// ListBackupStoragesWithResponse request returning *ListBackupStoragesResponse
func (c *ClientWithResponses) ListBackupStoragesWithResponse(ctx context.Context, namespace string, reqEditors ...RequestEditorFn) (*ListBackupStoragesResponse, error) {
	rsp, err := c.ListBackupStorages(ctx, namespace, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListBackupStoragesResponse(rsp)
}

// CreateBackupStorageWithBodyWithResponse request with arbitrary body returning *CreateBackupStorageResponse
func (c *ClientWithResponses) CreateBackupStorageWithBodyWithResponse(ctx context.Context, namespace string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateBackupStorageResponse, error) {
	rsp, err := c.CreateBackupStorageWithBody(ctx, namespace, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateBackupStorageResponse(rsp)
}

func (c *ClientWithResponses) CreateBackupStorageWithResponse(ctx context.Context, namespace string, body CreateBackupStorageJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateBackupStorageResponse, error) {
	rsp, err := c.CreateBackupStorage(ctx, namespace, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateBackupStorageResponse(rsp)
}

// DeleteBackupStorageWithResponse request returning *DeleteBackupStorageResponse
func (c *ClientWithResponses) DeleteBackupStorageWithResponse(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*DeleteBackupStorageResponse, error) {
	rsp, err := c.DeleteBackupStorage(ctx, namespace, name, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseDeleteBackupStorageResponse(rsp)
}

// GetBackupStorageWithResponse request returning *GetBackupStorageResponse
func (c *ClientWithResponses) GetBackupStorageWithResponse(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*GetBackupStorageResponse, error) {
	rsp, err := c.GetBackupStorage(ctx, namespace, name, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetBackupStorageResponse(rsp)
}

// UpdateBackupStorageWithBodyWithResponse request with arbitrary body returning *UpdateBackupStorageResponse
func (c *ClientWithResponses) UpdateBackupStorageWithBodyWithResponse(ctx context.Context, namespace string, name string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateBackupStorageResponse, error) {
	rsp, err := c.UpdateBackupStorageWithBody(ctx, namespace, name, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateBackupStorageResponse(rsp)
}

func (c *ClientWithResponses) UpdateBackupStorageWithResponse(ctx context.Context, namespace string, name string, body UpdateBackupStorageJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateBackupStorageResponse, error) {
	rsp, err := c.UpdateBackupStorage(ctx, namespace, name, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateBackupStorageResponse(rsp)
}

// CreateDatabaseClusterBackupWithBodyWithResponse request with arbitrary body returning *CreateDatabaseClusterBackupResponse
func (c *ClientWithResponses) CreateDatabaseClusterBackupWithBodyWithResponse(ctx context.Context, namespace string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateDatabaseClusterBackupResponse, error) {
	rsp, err := c.CreateDatabaseClusterBackupWithBody(ctx, namespace, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateDatabaseClusterBackupResponse(rsp)
}

func (c *ClientWithResponses) CreateDatabaseClusterBackupWithResponse(ctx context.Context, namespace string, body CreateDatabaseClusterBackupJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateDatabaseClusterBackupResponse, error) {
	rsp, err := c.CreateDatabaseClusterBackup(ctx, namespace, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateDatabaseClusterBackupResponse(rsp)
}

// DeleteDatabaseClusterBackupWithResponse request returning *DeleteDatabaseClusterBackupResponse
func (c *ClientWithResponses) DeleteDatabaseClusterBackupWithResponse(ctx context.Context, namespace string, name string, params *DeleteDatabaseClusterBackupParams, reqEditors ...RequestEditorFn) (*DeleteDatabaseClusterBackupResponse, error) {
	rsp, err := c.DeleteDatabaseClusterBackup(ctx, namespace, name, params, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseDeleteDatabaseClusterBackupResponse(rsp)
}

// GetDatabaseClusterBackupWithResponse request returning *GetDatabaseClusterBackupResponse
func (c *ClientWithResponses) GetDatabaseClusterBackupWithResponse(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*GetDatabaseClusterBackupResponse, error) {
	rsp, err := c.GetDatabaseClusterBackup(ctx, namespace, name, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetDatabaseClusterBackupResponse(rsp)
}

// CreateDatabaseClusterRestoreWithBodyWithResponse request with arbitrary body returning *CreateDatabaseClusterRestoreResponse
func (c *ClientWithResponses) CreateDatabaseClusterRestoreWithBodyWithResponse(ctx context.Context, namespace string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateDatabaseClusterRestoreResponse, error) {
	rsp, err := c.CreateDatabaseClusterRestoreWithBody(ctx, namespace, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateDatabaseClusterRestoreResponse(rsp)
}

func (c *ClientWithResponses) CreateDatabaseClusterRestoreWithResponse(ctx context.Context, namespace string, body CreateDatabaseClusterRestoreJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateDatabaseClusterRestoreResponse, error) {
	rsp, err := c.CreateDatabaseClusterRestore(ctx, namespace, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateDatabaseClusterRestoreResponse(rsp)
}

// DeleteDatabaseClusterRestoreWithResponse request returning *DeleteDatabaseClusterRestoreResponse
func (c *ClientWithResponses) DeleteDatabaseClusterRestoreWithResponse(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*DeleteDatabaseClusterRestoreResponse, error) {
	rsp, err := c.DeleteDatabaseClusterRestore(ctx, namespace, name, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseDeleteDatabaseClusterRestoreResponse(rsp)
}

// GetDatabaseClusterRestoreWithResponse request returning *GetDatabaseClusterRestoreResponse
func (c *ClientWithResponses) GetDatabaseClusterRestoreWithResponse(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*GetDatabaseClusterRestoreResponse, error) {
	rsp, err := c.GetDatabaseClusterRestore(ctx, namespace, name, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetDatabaseClusterRestoreResponse(rsp)
}

// UpdateDatabaseClusterRestoreWithBodyWithResponse request with arbitrary body returning *UpdateDatabaseClusterRestoreResponse
func (c *ClientWithResponses) UpdateDatabaseClusterRestoreWithBodyWithResponse(ctx context.Context, namespace string, name string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateDatabaseClusterRestoreResponse, error) {
	rsp, err := c.UpdateDatabaseClusterRestoreWithBody(ctx, namespace, name, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateDatabaseClusterRestoreResponse(rsp)
}

func (c *ClientWithResponses) UpdateDatabaseClusterRestoreWithResponse(ctx context.Context, namespace string, name string, body UpdateDatabaseClusterRestoreJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateDatabaseClusterRestoreResponse, error) {
	rsp, err := c.UpdateDatabaseClusterRestore(ctx, namespace, name, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateDatabaseClusterRestoreResponse(rsp)
}

// ListDatabaseClustersWithResponse request returning *ListDatabaseClustersResponse
func (c *ClientWithResponses) ListDatabaseClustersWithResponse(ctx context.Context, namespace string, reqEditors ...RequestEditorFn) (*ListDatabaseClustersResponse, error) {
	rsp, err := c.ListDatabaseClusters(ctx, namespace, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListDatabaseClustersResponse(rsp)
}

// CreateDatabaseClusterWithBodyWithResponse request with arbitrary body returning *CreateDatabaseClusterResponse
func (c *ClientWithResponses) CreateDatabaseClusterWithBodyWithResponse(ctx context.Context, namespace string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateDatabaseClusterResponse, error) {
	rsp, err := c.CreateDatabaseClusterWithBody(ctx, namespace, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateDatabaseClusterResponse(rsp)
}

func (c *ClientWithResponses) CreateDatabaseClusterWithResponse(ctx context.Context, namespace string, body CreateDatabaseClusterJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateDatabaseClusterResponse, error) {
	rsp, err := c.CreateDatabaseCluster(ctx, namespace, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateDatabaseClusterResponse(rsp)
}

// ListDatabaseClusterBackupsWithResponse request returning *ListDatabaseClusterBackupsResponse
func (c *ClientWithResponses) ListDatabaseClusterBackupsWithResponse(ctx context.Context, namespace string, clusterName string, reqEditors ...RequestEditorFn) (*ListDatabaseClusterBackupsResponse, error) {
	rsp, err := c.ListDatabaseClusterBackups(ctx, namespace, clusterName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListDatabaseClusterBackupsResponse(rsp)
}

// ListDatabaseClusterRestoresWithResponse request returning *ListDatabaseClusterRestoresResponse
func (c *ClientWithResponses) ListDatabaseClusterRestoresWithResponse(ctx context.Context, namespace string, clusterName string, reqEditors ...RequestEditorFn) (*ListDatabaseClusterRestoresResponse, error) {
	rsp, err := c.ListDatabaseClusterRestores(ctx, namespace, clusterName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListDatabaseClusterRestoresResponse(rsp)
}

// ListDataImportJobsWithResponse request returning *ListDataImportJobsResponse
func (c *ClientWithResponses) ListDataImportJobsWithResponse(ctx context.Context, namespace string, dbName string, reqEditors ...RequestEditorFn) (*ListDataImportJobsResponse, error) {
	rsp, err := c.ListDataImportJobs(ctx, namespace, dbName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListDataImportJobsResponse(rsp)
}

// CreateDatabaseClusterSecretWithBodyWithResponse request with arbitrary body returning *CreateDatabaseClusterSecretResponse
func (c *ClientWithResponses) CreateDatabaseClusterSecretWithBodyWithResponse(ctx context.Context, namespace string, dbName string, params *CreateDatabaseClusterSecretParams, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateDatabaseClusterSecretResponse, error) {
	rsp, err := c.CreateDatabaseClusterSecretWithBody(ctx, namespace, dbName, params, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateDatabaseClusterSecretResponse(rsp)
}

func (c *ClientWithResponses) CreateDatabaseClusterSecretWithResponse(ctx context.Context, namespace string, dbName string, params *CreateDatabaseClusterSecretParams, body CreateDatabaseClusterSecretJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateDatabaseClusterSecretResponse, error) {
	rsp, err := c.CreateDatabaseClusterSecret(ctx, namespace, dbName, params, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateDatabaseClusterSecretResponse(rsp)
}

// DeleteDatabaseClusterWithResponse request returning *DeleteDatabaseClusterResponse
func (c *ClientWithResponses) DeleteDatabaseClusterWithResponse(ctx context.Context, namespace string, name string, params *DeleteDatabaseClusterParams, reqEditors ...RequestEditorFn) (*DeleteDatabaseClusterResponse, error) {
	rsp, err := c.DeleteDatabaseCluster(ctx, namespace, name, params, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseDeleteDatabaseClusterResponse(rsp)
}

// GetDatabaseClusterWithResponse request returning *GetDatabaseClusterResponse
func (c *ClientWithResponses) GetDatabaseClusterWithResponse(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*GetDatabaseClusterResponse, error) {
	rsp, err := c.GetDatabaseCluster(ctx, namespace, name, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetDatabaseClusterResponse(rsp)
}

// UpdateDatabaseClusterWithBodyWithResponse request with arbitrary body returning *UpdateDatabaseClusterResponse
func (c *ClientWithResponses) UpdateDatabaseClusterWithBodyWithResponse(ctx context.Context, namespace string, name string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateDatabaseClusterResponse, error) {
	rsp, err := c.UpdateDatabaseClusterWithBody(ctx, namespace, name, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateDatabaseClusterResponse(rsp)
}

func (c *ClientWithResponses) UpdateDatabaseClusterWithResponse(ctx context.Context, namespace string, name string, body UpdateDatabaseClusterJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateDatabaseClusterResponse, error) {
	rsp, err := c.UpdateDatabaseCluster(ctx, namespace, name, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateDatabaseClusterResponse(rsp)
}

// GetDatabaseClusterComponentsWithResponse request returning *GetDatabaseClusterComponentsResponse
func (c *ClientWithResponses) GetDatabaseClusterComponentsWithResponse(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*GetDatabaseClusterComponentsResponse, error) {
	rsp, err := c.GetDatabaseClusterComponents(ctx, namespace, name, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetDatabaseClusterComponentsResponse(rsp)
}

// GetDatabaseClusterCredentialsWithResponse request returning *GetDatabaseClusterCredentialsResponse
func (c *ClientWithResponses) GetDatabaseClusterCredentialsWithResponse(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*GetDatabaseClusterCredentialsResponse, error) {
	rsp, err := c.GetDatabaseClusterCredentials(ctx, namespace, name, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetDatabaseClusterCredentialsResponse(rsp)
}

// GetDatabaseClusterPitrWithResponse request returning *GetDatabaseClusterPitrResponse
func (c *ClientWithResponses) GetDatabaseClusterPitrWithResponse(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*GetDatabaseClusterPitrResponse, error) {
	rsp, err := c.GetDatabaseClusterPitr(ctx, namespace, name, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetDatabaseClusterPitrResponse(rsp)
}

// ListDatabaseEnginesWithResponse request returning *ListDatabaseEnginesResponse
func (c *ClientWithResponses) ListDatabaseEnginesWithResponse(ctx context.Context, namespace string, reqEditors ...RequestEditorFn) (*ListDatabaseEnginesResponse, error) {
	rsp, err := c.ListDatabaseEngines(ctx, namespace, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListDatabaseEnginesResponse(rsp)
}

// GetUpgradePlanWithResponse request returning *GetUpgradePlanResponse
func (c *ClientWithResponses) GetUpgradePlanWithResponse(ctx context.Context, namespace string, reqEditors ...RequestEditorFn) (*GetUpgradePlanResponse, error) {
	rsp, err := c.GetUpgradePlan(ctx, namespace, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetUpgradePlanResponse(rsp)
}

// ApproveUpgradePlanWithBodyWithResponse request with arbitrary body returning *ApproveUpgradePlanResponse
func (c *ClientWithResponses) ApproveUpgradePlanWithBodyWithResponse(ctx context.Context, namespace string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*ApproveUpgradePlanResponse, error) {
	rsp, err := c.ApproveUpgradePlanWithBody(ctx, namespace, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseApproveUpgradePlanResponse(rsp)
}

func (c *ClientWithResponses) ApproveUpgradePlanWithResponse(ctx context.Context, namespace string, body ApproveUpgradePlanJSONRequestBody, reqEditors ...RequestEditorFn) (*ApproveUpgradePlanResponse, error) {
	rsp, err := c.ApproveUpgradePlan(ctx, namespace, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseApproveUpgradePlanResponse(rsp)
}

// GetDatabaseEngineWithResponse request returning *GetDatabaseEngineResponse
func (c *ClientWithResponses) GetDatabaseEngineWithResponse(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*GetDatabaseEngineResponse, error) {
	rsp, err := c.GetDatabaseEngine(ctx, namespace, name, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetDatabaseEngineResponse(rsp)
}

// UpdateDatabaseEngineWithBodyWithResponse request with arbitrary body returning *UpdateDatabaseEngineResponse
func (c *ClientWithResponses) UpdateDatabaseEngineWithBodyWithResponse(ctx context.Context, namespace string, name string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateDatabaseEngineResponse, error) {
	rsp, err := c.UpdateDatabaseEngineWithBody(ctx, namespace, name, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateDatabaseEngineResponse(rsp)
}

func (c *ClientWithResponses) UpdateDatabaseEngineWithResponse(ctx context.Context, namespace string, name string, body UpdateDatabaseEngineJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateDatabaseEngineResponse, error) {
	rsp, err := c.UpdateDatabaseEngine(ctx, namespace, name, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateDatabaseEngineResponse(rsp)
}

// ListSplitHorizonDNSConfigsWithResponse request returning *ListSplitHorizonDNSConfigsResponse
func (c *ClientWithResponses) ListSplitHorizonDNSConfigsWithResponse(ctx context.Context, namespace string, reqEditors ...RequestEditorFn) (*ListSplitHorizonDNSConfigsResponse, error) {
	rsp, err := c.ListSplitHorizonDNSConfigs(ctx, namespace, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListSplitHorizonDNSConfigsResponse(rsp)
}

// CreateSplitHorizonDNSConfigWithBodyWithResponse request with arbitrary body returning *CreateSplitHorizonDNSConfigResponse
func (c *ClientWithResponses) CreateSplitHorizonDNSConfigWithBodyWithResponse(ctx context.Context, namespace string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateSplitHorizonDNSConfigResponse, error) {
	rsp, err := c.CreateSplitHorizonDNSConfigWithBody(ctx, namespace, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateSplitHorizonDNSConfigResponse(rsp)
}

func (c *ClientWithResponses) CreateSplitHorizonDNSConfigWithResponse(ctx context.Context, namespace string, body CreateSplitHorizonDNSConfigJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateSplitHorizonDNSConfigResponse, error) {
	rsp, err := c.CreateSplitHorizonDNSConfig(ctx, namespace, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateSplitHorizonDNSConfigResponse(rsp)
}

// DeleteSplitHorizonDNSConfigWithResponse request returning *DeleteSplitHorizonDNSConfigResponse
func (c *ClientWithResponses) DeleteSplitHorizonDNSConfigWithResponse(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*DeleteSplitHorizonDNSConfigResponse, error) {
	rsp, err := c.DeleteSplitHorizonDNSConfig(ctx, namespace, name, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseDeleteSplitHorizonDNSConfigResponse(rsp)
}

// GetSplitHorizonDNSConfigWithResponse request returning *GetSplitHorizonDNSConfigResponse
func (c *ClientWithResponses) GetSplitHorizonDNSConfigWithResponse(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*GetSplitHorizonDNSConfigResponse, error) {
	rsp, err := c.GetSplitHorizonDNSConfig(ctx, namespace, name, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetSplitHorizonDNSConfigResponse(rsp)
}

// UpdateSplitHorizonDNSConfigWithBodyWithResponse request with arbitrary body returning *UpdateSplitHorizonDNSConfigResponse
func (c *ClientWithResponses) UpdateSplitHorizonDNSConfigWithBodyWithResponse(ctx context.Context, namespace string, name string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateSplitHorizonDNSConfigResponse, error) {
	rsp, err := c.UpdateSplitHorizonDNSConfigWithBody(ctx, namespace, name, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateSplitHorizonDNSConfigResponse(rsp)
}

func (c *ClientWithResponses) UpdateSplitHorizonDNSConfigWithResponse(ctx context.Context, namespace string, name string, body UpdateSplitHorizonDNSConfigJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateSplitHorizonDNSConfigResponse, error) {
	rsp, err := c.UpdateSplitHorizonDNSConfig(ctx, namespace, name, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateSplitHorizonDNSConfigResponse(rsp)
}

// ListMonitoringInstancesWithResponse request returning *ListMonitoringInstancesResponse
func (c *ClientWithResponses) ListMonitoringInstancesWithResponse(ctx context.Context, namespace string, reqEditors ...RequestEditorFn) (*ListMonitoringInstancesResponse, error) {
	rsp, err := c.ListMonitoringInstances(ctx, namespace, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListMonitoringInstancesResponse(rsp)
}

// CreateMonitoringInstanceWithBodyWithResponse request with arbitrary body returning *CreateMonitoringInstanceResponse
func (c *ClientWithResponses) CreateMonitoringInstanceWithBodyWithResponse(ctx context.Context, namespace string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateMonitoringInstanceResponse, error) {
	rsp, err := c.CreateMonitoringInstanceWithBody(ctx, namespace, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateMonitoringInstanceResponse(rsp)
}

func (c *ClientWithResponses) CreateMonitoringInstanceWithResponse(ctx context.Context, namespace string, body CreateMonitoringInstanceJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateMonitoringInstanceResponse, error) {
	rsp, err := c.CreateMonitoringInstance(ctx, namespace, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateMonitoringInstanceResponse(rsp)
}

// DeleteMonitoringInstanceWithResponse request returning *DeleteMonitoringInstanceResponse
func (c *ClientWithResponses) DeleteMonitoringInstanceWithResponse(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*DeleteMonitoringInstanceResponse, error) {
	rsp, err := c.DeleteMonitoringInstance(ctx, namespace, name, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseDeleteMonitoringInstanceResponse(rsp)
}

// GetMonitoringInstanceWithResponse request returning *GetMonitoringInstanceResponse
func (c *ClientWithResponses) GetMonitoringInstanceWithResponse(ctx context.Context, namespace string, name string, reqEditors ...RequestEditorFn) (*GetMonitoringInstanceResponse, error) {
	rsp, err := c.GetMonitoringInstance(ctx, namespace, name, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetMonitoringInstanceResponse(rsp)
}

// UpdateMonitoringInstanceWithBodyWithResponse request with arbitrary body returning *UpdateMonitoringInstanceResponse
func (c *ClientWithResponses) UpdateMonitoringInstanceWithBodyWithResponse(ctx context.Context, namespace string, name string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdateMonitoringInstanceResponse, error) {
	rsp, err := c.UpdateMonitoringInstanceWithBody(ctx, namespace, name, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateMonitoringInstanceResponse(rsp)
}

func (c *ClientWithResponses) UpdateMonitoringInstanceWithResponse(ctx context.Context, namespace string, name string, body UpdateMonitoringInstanceJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdateMonitoringInstanceResponse, error) {
	rsp, err := c.UpdateMonitoringInstance(ctx, namespace, name, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdateMonitoringInstanceResponse(rsp)
}

// GetUserPermissionsWithResponse request returning *GetUserPermissionsResponse
func (c *ClientWithResponses) GetUserPermissionsWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetUserPermissionsResponse, error) {
	rsp, err := c.GetUserPermissions(ctx, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetUserPermissionsResponse(rsp)
}

// ListPodSchedulingPolicyWithResponse request returning *ListPodSchedulingPolicyResponse
func (c *ClientWithResponses) ListPodSchedulingPolicyWithResponse(ctx context.Context, params *ListPodSchedulingPolicyParams, reqEditors ...RequestEditorFn) (*ListPodSchedulingPolicyResponse, error) {
	rsp, err := c.ListPodSchedulingPolicy(ctx, params, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseListPodSchedulingPolicyResponse(rsp)
}

// CreatePodSchedulingPolicyWithBodyWithResponse request with arbitrary body returning *CreatePodSchedulingPolicyResponse
func (c *ClientWithResponses) CreatePodSchedulingPolicyWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreatePodSchedulingPolicyResponse, error) {
	rsp, err := c.CreatePodSchedulingPolicyWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreatePodSchedulingPolicyResponse(rsp)
}

func (c *ClientWithResponses) CreatePodSchedulingPolicyWithResponse(ctx context.Context, body CreatePodSchedulingPolicyJSONRequestBody, reqEditors ...RequestEditorFn) (*CreatePodSchedulingPolicyResponse, error) {
	rsp, err := c.CreatePodSchedulingPolicy(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreatePodSchedulingPolicyResponse(rsp)
}

// DeletePodSchedulingPolicyWithResponse request returning *DeletePodSchedulingPolicyResponse
func (c *ClientWithResponses) DeletePodSchedulingPolicyWithResponse(ctx context.Context, policyName string, reqEditors ...RequestEditorFn) (*DeletePodSchedulingPolicyResponse, error) {
	rsp, err := c.DeletePodSchedulingPolicy(ctx, policyName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseDeletePodSchedulingPolicyResponse(rsp)
}

// GetPodSchedulingPolicyWithResponse request returning *GetPodSchedulingPolicyResponse
func (c *ClientWithResponses) GetPodSchedulingPolicyWithResponse(ctx context.Context, policyName string, reqEditors ...RequestEditorFn) (*GetPodSchedulingPolicyResponse, error) {
	rsp, err := c.GetPodSchedulingPolicy(ctx, policyName, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetPodSchedulingPolicyResponse(rsp)
}

// UpdatePodSchedulingPolicyWithBodyWithResponse request with arbitrary body returning *UpdatePodSchedulingPolicyResponse
func (c *ClientWithResponses) UpdatePodSchedulingPolicyWithBodyWithResponse(ctx context.Context, policyName string, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*UpdatePodSchedulingPolicyResponse, error) {
	rsp, err := c.UpdatePodSchedulingPolicyWithBody(ctx, policyName, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdatePodSchedulingPolicyResponse(rsp)
}

func (c *ClientWithResponses) UpdatePodSchedulingPolicyWithResponse(ctx context.Context, policyName string, body UpdatePodSchedulingPolicyJSONRequestBody, reqEditors ...RequestEditorFn) (*UpdatePodSchedulingPolicyResponse, error) {
	rsp, err := c.UpdatePodSchedulingPolicy(ctx, policyName, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseUpdatePodSchedulingPolicyResponse(rsp)
}

// GetKubernetesClusterResourcesWithResponse request returning *GetKubernetesClusterResourcesResponse
func (c *ClientWithResponses) GetKubernetesClusterResourcesWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetKubernetesClusterResourcesResponse, error) {
	rsp, err := c.GetKubernetesClusterResources(ctx, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetKubernetesClusterResourcesResponse(rsp)
}

// DeleteSessionWithResponse request returning *DeleteSessionResponse
func (c *ClientWithResponses) DeleteSessionWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*DeleteSessionResponse, error) {
	rsp, err := c.DeleteSession(ctx, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseDeleteSessionResponse(rsp)
}

// CreateSessionWithBodyWithResponse request with arbitrary body returning *CreateSessionResponse
func (c *ClientWithResponses) CreateSessionWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*CreateSessionResponse, error) {
	rsp, err := c.CreateSessionWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateSessionResponse(rsp)
}

func (c *ClientWithResponses) CreateSessionWithResponse(ctx context.Context, body CreateSessionJSONRequestBody, reqEditors ...RequestEditorFn) (*CreateSessionResponse, error) {
	rsp, err := c.CreateSession(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseCreateSessionResponse(rsp)
}

// GetSettingsWithResponse request returning *GetSettingsResponse
func (c *ClientWithResponses) GetSettingsWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetSettingsResponse, error) {
	rsp, err := c.GetSettings(ctx, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetSettingsResponse(rsp)
}

// VersionInfoWithResponse request returning *VersionInfoResponse
func (c *ClientWithResponses) VersionInfoWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*VersionInfoResponse, error) {
	rsp, err := c.VersionInfo(ctx, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseVersionInfoResponse(rsp)
}

// ParseGetKubernetesClusterInfoResponse parses an HTTP response from a GetKubernetesClusterInfoWithResponse call
func ParseGetKubernetesClusterInfoResponse(rsp *http.Response) (*GetKubernetesClusterInfoResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetKubernetesClusterInfoResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest KubernetesClusterInfo
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListDataImportersResponse parses an HTTP response from a ListDataImportersWithResponse call
func ParseListDataImportersResponse(rsp *http.Response) (*ListDataImportersResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListDataImportersResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest DataImporterList
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListLoadBalancerConfigResponse parses an HTTP response from a ListLoadBalancerConfigWithResponse call
func ParseListLoadBalancerConfigResponse(rsp *http.Response) (*ListLoadBalancerConfigResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListLoadBalancerConfigResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest LoadBalancerConfigList
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseCreateLoadBalancerConfigResponse parses an HTTP response from a CreateLoadBalancerConfigWithResponse call
func ParseCreateLoadBalancerConfigResponse(rsp *http.Response) (*CreateLoadBalancerConfigResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &CreateLoadBalancerConfigResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest LoadBalancerConfig
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseDeleteLoadBalancerConfigResponse parses an HTTP response from a DeleteLoadBalancerConfigWithResponse call
func ParseDeleteLoadBalancerConfigResponse(rsp *http.Response) (*DeleteLoadBalancerConfigResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &DeleteLoadBalancerConfigResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest IoK8sApimachineryPkgApisMetaV1StatusV2
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetLoadBalancerConfigResponse parses an HTTP response from a GetLoadBalancerConfigWithResponse call
func ParseGetLoadBalancerConfigResponse(rsp *http.Response) (*GetLoadBalancerConfigResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetLoadBalancerConfigResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest LoadBalancerConfig
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseUpdateLoadBalancerConfigResponse parses an HTTP response from a UpdateLoadBalancerConfigWithResponse call
func ParseUpdateLoadBalancerConfigResponse(rsp *http.Response) (*UpdateLoadBalancerConfigResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &UpdateLoadBalancerConfigResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest LoadBalancerConfig
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListNamespacesResponse parses an HTTP response from a ListNamespacesWithResponse call
func ParseListNamespacesResponse(rsp *http.Response) (*ListNamespacesResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListNamespacesResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest NamespaceList
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	}

	return response, nil
}

// ParseListBackupStoragesResponse parses an HTTP response from a ListBackupStoragesWithResponse call
func ParseListBackupStoragesResponse(rsp *http.Response) (*ListBackupStoragesResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListBackupStoragesResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest BackupStoragesList
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseCreateBackupStorageResponse parses an HTTP response from a CreateBackupStorageWithResponse call
func ParseCreateBackupStorageResponse(rsp *http.Response) (*CreateBackupStorageResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &CreateBackupStorageResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest BackupStorage
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseDeleteBackupStorageResponse parses an HTTP response from a DeleteBackupStorageWithResponse call
func ParseDeleteBackupStorageResponse(rsp *http.Response) (*DeleteBackupStorageResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &DeleteBackupStorageResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetBackupStorageResponse parses an HTTP response from a GetBackupStorageWithResponse call
func ParseGetBackupStorageResponse(rsp *http.Response) (*GetBackupStorageResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetBackupStorageResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest BackupStorage
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseUpdateBackupStorageResponse parses an HTTP response from a UpdateBackupStorageWithResponse call
func ParseUpdateBackupStorageResponse(rsp *http.Response) (*UpdateBackupStorageResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &UpdateBackupStorageResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest BackupStorage
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseCreateDatabaseClusterBackupResponse parses an HTTP response from a CreateDatabaseClusterBackupWithResponse call
func ParseCreateDatabaseClusterBackupResponse(rsp *http.Response) (*CreateDatabaseClusterBackupResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &CreateDatabaseClusterBackupResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest DatabaseClusterBackup
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest DatabaseClusterBackup
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 202:
		var dest DatabaseClusterBackup
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON202 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseDeleteDatabaseClusterBackupResponse parses an HTTP response from a DeleteDatabaseClusterBackupWithResponse call
func ParseDeleteDatabaseClusterBackupResponse(rsp *http.Response) (*DeleteDatabaseClusterBackupResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &DeleteDatabaseClusterBackupResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest IoK8sApimachineryPkgApisMetaV1StatusV2
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetDatabaseClusterBackupResponse parses an HTTP response from a GetDatabaseClusterBackupWithResponse call
func ParseGetDatabaseClusterBackupResponse(rsp *http.Response) (*GetDatabaseClusterBackupResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetDatabaseClusterBackupResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest DatabaseClusterBackup
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseCreateDatabaseClusterRestoreResponse parses an HTTP response from a CreateDatabaseClusterRestoreWithResponse call
func ParseCreateDatabaseClusterRestoreResponse(rsp *http.Response) (*CreateDatabaseClusterRestoreResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &CreateDatabaseClusterRestoreResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest DatabaseClusterRestore
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest DatabaseClusterRestore
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 202:
		var dest DatabaseClusterRestore
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON202 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseDeleteDatabaseClusterRestoreResponse parses an HTTP response from a DeleteDatabaseClusterRestoreWithResponse call
func ParseDeleteDatabaseClusterRestoreResponse(rsp *http.Response) (*DeleteDatabaseClusterRestoreResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &DeleteDatabaseClusterRestoreResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest IoK8sApimachineryPkgApisMetaV1StatusV2
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetDatabaseClusterRestoreResponse parses an HTTP response from a GetDatabaseClusterRestoreWithResponse call
func ParseGetDatabaseClusterRestoreResponse(rsp *http.Response) (*GetDatabaseClusterRestoreResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetDatabaseClusterRestoreResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest DatabaseClusterRestore
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseUpdateDatabaseClusterRestoreResponse parses an HTTP response from a UpdateDatabaseClusterRestoreWithResponse call
func ParseUpdateDatabaseClusterRestoreResponse(rsp *http.Response) (*UpdateDatabaseClusterRestoreResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &UpdateDatabaseClusterRestoreResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest DatabaseClusterRestore
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest DatabaseClusterRestore
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListDatabaseClustersResponse parses an HTTP response from a ListDatabaseClustersWithResponse call
func ParseListDatabaseClustersResponse(rsp *http.Response) (*ListDatabaseClustersResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListDatabaseClustersResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest DatabaseClusterList
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseCreateDatabaseClusterResponse parses an HTTP response from a CreateDatabaseClusterWithResponse call
func ParseCreateDatabaseClusterResponse(rsp *http.Response) (*CreateDatabaseClusterResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &CreateDatabaseClusterResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest DatabaseCluster
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 201:
		var dest DatabaseCluster
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON201 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 202:
		var dest DatabaseCluster
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON202 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListDatabaseClusterBackupsResponse parses an HTTP response from a ListDatabaseClusterBackupsWithResponse call
func ParseListDatabaseClusterBackupsResponse(rsp *http.Response) (*ListDatabaseClusterBackupsResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListDatabaseClusterBackupsResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest DatabaseClusterBackupList
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListDatabaseClusterRestoresResponse parses an HTTP response from a ListDatabaseClusterRestoresWithResponse call
func ParseListDatabaseClusterRestoresResponse(rsp *http.Response) (*ListDatabaseClusterRestoresResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListDatabaseClusterRestoresResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest DatabaseClusterRestoreList
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListDataImportJobsResponse parses an HTTP response from a ListDataImportJobsWithResponse call
func ParseListDataImportJobsResponse(rsp *http.Response) (*ListDataImportJobsResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListDataImportJobsResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest DataImportJobList
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseCreateDatabaseClusterSecretResponse parses an HTTP response from a CreateDatabaseClusterSecretWithResponse call
func ParseCreateDatabaseClusterSecretResponse(rsp *http.Response) (*CreateDatabaseClusterSecretResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &CreateDatabaseClusterSecretResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest Secret
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseDeleteDatabaseClusterResponse parses an HTTP response from a DeleteDatabaseClusterWithResponse call
func ParseDeleteDatabaseClusterResponse(rsp *http.Response) (*DeleteDatabaseClusterResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &DeleteDatabaseClusterResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest IoK8sApimachineryPkgApisMetaV1StatusV2
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetDatabaseClusterResponse parses an HTTP response from a GetDatabaseClusterWithResponse call
func ParseGetDatabaseClusterResponse(rsp *http.Response) (*GetDatabaseClusterResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetDatabaseClusterResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest DatabaseCluster
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseUpdateDatabaseClusterResponse parses an HTTP response from a UpdateDatabaseClusterWithResponse call
func ParseUpdateDatabaseClusterResponse(rsp *http.Response) (*UpdateDatabaseClusterResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &UpdateDatabaseClusterResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest DatabaseCluster
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetDatabaseClusterComponentsResponse parses an HTTP response from a GetDatabaseClusterComponentsWithResponse call
func ParseGetDatabaseClusterComponentsResponse(rsp *http.Response) (*GetDatabaseClusterComponentsResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetDatabaseClusterComponentsResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest DatabaseClusterComponents
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetDatabaseClusterCredentialsResponse parses an HTTP response from a GetDatabaseClusterCredentialsWithResponse call
func ParseGetDatabaseClusterCredentialsResponse(rsp *http.Response) (*GetDatabaseClusterCredentialsResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetDatabaseClusterCredentialsResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest DatabaseClusterCredential
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetDatabaseClusterPitrResponse parses an HTTP response from a GetDatabaseClusterPitrWithResponse call
func ParseGetDatabaseClusterPitrResponse(rsp *http.Response) (*GetDatabaseClusterPitrResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetDatabaseClusterPitrResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest DatabaseClusterPitr
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListDatabaseEnginesResponse parses an HTTP response from a ListDatabaseEnginesWithResponse call
func ParseListDatabaseEnginesResponse(rsp *http.Response) (*ListDatabaseEnginesResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListDatabaseEnginesResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest DatabaseEngineList
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetUpgradePlanResponse parses an HTTP response from a GetUpgradePlanWithResponse call
func ParseGetUpgradePlanResponse(rsp *http.Response) (*GetUpgradePlanResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetUpgradePlanResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest UpgradePlan
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseApproveUpgradePlanResponse parses an HTTP response from a ApproveUpgradePlanWithResponse call
func ParseApproveUpgradePlanResponse(rsp *http.Response) (*ApproveUpgradePlanResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ApproveUpgradePlanResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetDatabaseEngineResponse parses an HTTP response from a GetDatabaseEngineWithResponse call
func ParseGetDatabaseEngineResponse(rsp *http.Response) (*GetDatabaseEngineResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetDatabaseEngineResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest DatabaseEngine
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseUpdateDatabaseEngineResponse parses an HTTP response from a UpdateDatabaseEngineWithResponse call
func ParseUpdateDatabaseEngineResponse(rsp *http.Response) (*UpdateDatabaseEngineResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &UpdateDatabaseEngineResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest DatabaseEngine
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListSplitHorizonDNSConfigsResponse parses an HTTP response from a ListSplitHorizonDNSConfigsWithResponse call
func ParseListSplitHorizonDNSConfigsResponse(rsp *http.Response) (*ListSplitHorizonDNSConfigsResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListSplitHorizonDNSConfigsResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest SplitHorizonDNSConfigList
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseCreateSplitHorizonDNSConfigResponse parses an HTTP response from a CreateSplitHorizonDNSConfigWithResponse call
func ParseCreateSplitHorizonDNSConfigResponse(rsp *http.Response) (*CreateSplitHorizonDNSConfigResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &CreateSplitHorizonDNSConfigResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest SplitHorizonDNSConfig
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseDeleteSplitHorizonDNSConfigResponse parses an HTTP response from a DeleteSplitHorizonDNSConfigWithResponse call
func ParseDeleteSplitHorizonDNSConfigResponse(rsp *http.Response) (*DeleteSplitHorizonDNSConfigResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &DeleteSplitHorizonDNSConfigResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetSplitHorizonDNSConfigResponse parses an HTTP response from a GetSplitHorizonDNSConfigWithResponse call
func ParseGetSplitHorizonDNSConfigResponse(rsp *http.Response) (*GetSplitHorizonDNSConfigResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetSplitHorizonDNSConfigResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest SplitHorizonDNSConfig
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseUpdateSplitHorizonDNSConfigResponse parses an HTTP response from a UpdateSplitHorizonDNSConfigWithResponse call
func ParseUpdateSplitHorizonDNSConfigResponse(rsp *http.Response) (*UpdateSplitHorizonDNSConfigResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &UpdateSplitHorizonDNSConfigResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest SplitHorizonDNSConfig
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListMonitoringInstancesResponse parses an HTTP response from a ListMonitoringInstancesWithResponse call
func ParseListMonitoringInstancesResponse(rsp *http.Response) (*ListMonitoringInstancesResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListMonitoringInstancesResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest MonitoringInstancesList
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseCreateMonitoringInstanceResponse parses an HTTP response from a CreateMonitoringInstanceWithResponse call
func ParseCreateMonitoringInstanceResponse(rsp *http.Response) (*CreateMonitoringInstanceResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &CreateMonitoringInstanceResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest MonitoringInstance
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseDeleteMonitoringInstanceResponse parses an HTTP response from a DeleteMonitoringInstanceWithResponse call
func ParseDeleteMonitoringInstanceResponse(rsp *http.Response) (*DeleteMonitoringInstanceResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &DeleteMonitoringInstanceResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetMonitoringInstanceResponse parses an HTTP response from a GetMonitoringInstanceWithResponse call
func ParseGetMonitoringInstanceResponse(rsp *http.Response) (*GetMonitoringInstanceResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetMonitoringInstanceResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest MonitoringInstance
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseUpdateMonitoringInstanceResponse parses an HTTP response from a UpdateMonitoringInstanceWithResponse call
func ParseUpdateMonitoringInstanceResponse(rsp *http.Response) (*UpdateMonitoringInstanceResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &UpdateMonitoringInstanceResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest MonitoringInstance
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetUserPermissionsResponse parses an HTTP response from a GetUserPermissionsWithResponse call
func ParseGetUserPermissionsResponse(rsp *http.Response) (*GetUserPermissionsResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetUserPermissionsResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest UserPermissions
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseListPodSchedulingPolicyResponse parses an HTTP response from a ListPodSchedulingPolicyWithResponse call
func ParseListPodSchedulingPolicyResponse(rsp *http.Response) (*ListPodSchedulingPolicyResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &ListPodSchedulingPolicyResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest PodSchedulingPolicyList
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseCreatePodSchedulingPolicyResponse parses an HTTP response from a CreatePodSchedulingPolicyWithResponse call
func ParseCreatePodSchedulingPolicyResponse(rsp *http.Response) (*CreatePodSchedulingPolicyResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &CreatePodSchedulingPolicyResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest PodSchedulingPolicy
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseDeletePodSchedulingPolicyResponse parses an HTTP response from a DeletePodSchedulingPolicyWithResponse call
func ParseDeletePodSchedulingPolicyResponse(rsp *http.Response) (*DeletePodSchedulingPolicyResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &DeletePodSchedulingPolicyResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest IoK8sApimachineryPkgApisMetaV1StatusV2
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetPodSchedulingPolicyResponse parses an HTTP response from a GetPodSchedulingPolicyWithResponse call
func ParseGetPodSchedulingPolicyResponse(rsp *http.Response) (*GetPodSchedulingPolicyResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetPodSchedulingPolicyResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest PodSchedulingPolicy
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseUpdatePodSchedulingPolicyResponse parses an HTTP response from a UpdatePodSchedulingPolicyWithResponse call
func ParseUpdatePodSchedulingPolicyResponse(rsp *http.Response) (*UpdatePodSchedulingPolicyResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &UpdatePodSchedulingPolicyResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest PodSchedulingPolicy
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetKubernetesClusterResourcesResponse parses an HTTP response from a GetKubernetesClusterResourcesWithResponse call
func ParseGetKubernetesClusterResourcesResponse(rsp *http.Response) (*GetKubernetesClusterResourcesResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetKubernetesClusterResourcesResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest KubernetesClusterResources
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseDeleteSessionResponse parses an HTTP response from a DeleteSessionWithResponse call
func ParseDeleteSessionResponse(rsp *http.Response) (*DeleteSessionResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &DeleteSessionResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 429:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON429 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseCreateSessionResponse parses an HTTP response from a CreateSessionWithResponse call
func ParseCreateSessionResponse(rsp *http.Response) (*CreateSessionResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &CreateSessionResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest struct {
			Token *string `json:"token,omitempty"`
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 429:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON429 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest Error
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetSettingsResponse parses an HTTP response from a GetSettingsWithResponse call
func ParseGetSettingsResponse(rsp *http.Response) (*GetSettingsResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetSettingsResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest Settings
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	}

	return response, nil
}

// ParseVersionInfoResponse parses an HTTP response from a VersionInfoWithResponse call
func ParseVersionInfoResponse(rsp *http.Response) (*VersionInfoResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &VersionInfoResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest Version
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	}

	return response, nil
}

// Base64 encoded, gzipped, json marshaled Swagger object
var swaggerSpec = []string{

	"H4sIAAAAAAAC/+y9i3cbuZE3+q/gY/YcWxOSsmcmuRt9Z0+uLDkTZfzQleTM/XbojcFukETUDXQaaMmc",
	"if/376AA9BNNNvWwJU/tOZux2GgAXUAV6lcv/DqKZJpJwYRWo4NfRypasZTCP1/Q6LLIzrXM6ZKZH2gc",
	"c82loMlpLjOWa87U6GBBE8XGo5ipKOeZeT46cO8SZV8mXCxknlJ4OB5ltbd/HdEkkdcsfkNTpjIa2R9j",
	"luUsoprFowOdF53+X3GliVwQUb5FXD9ES1IoRvSKKzJvTGM0HnHNUhhArzM2OhgpnXOxHH0a+x9ontO1",
	"+XteRJdMm1kFmzemE3i+kHnETqlenet1wuwnLWiR6JJg7pW5lAmjwrwj+gYrv7L7dDz6OFnKiflxoi55",
	"NpGZXaJJJrnQLLf0+zQe5WwZnOzwHux7v46YKNLRwc8j9d1oPKK/FDkbvR93Z13kSfBrrljOF+uLV+cN",
	"qthVbhMF5v2vgudmI/xsKdRYG/dKNb6c/5NF2ozT2L/K7BgzYLkD/iNni9HB6Hf7FQPsu92/39z6gd1x",
	"lDOqWaPZKc2p7fnmfJKZPphmueqySRQxpX5k6yBNHwUTNUe/WDESJbKIy6+3rfcjKTTlguVE1Fb4czFf",
	"c5KHhgw5idmCC2ZmaoaAeRnC6RWriTj48/jNuX1sBR5ZaZ2pg/39y2LOcsE0U1Mu92MZKfOdEcu02pdX",
	"LL/i7Hr/WuaXXCwn11yvJnYjq31Ynf3fxUJNEjpnyQR+GI1H7CNNswTofa0mMbsKker2XK9YlDPdt/Ee",
	"pkyomKU+/w2y4phqepJmMtd/k/PuNmg8JlzZlQdhYRYa/oypphza/FPOFTk8PZl2mTjjf2e5civS2mqn",
	"J+6Z2252lCv7m9l8djzYd1yR3HC3YkLDsWp+poLYL5rOxDnLzZtErWSRxCSS4orlmuQskkvBfym7U4bV",
	"zTgJ1UxpAmsvaEKuaFKwMaEinomUrknOTM+kELUuoI2azsRrmdtD/qDc8Euup5f/Cbs9kmlaCK7XwNo5",
	"nxda5mo/Zlcs2Vd8OaF5tOKaRbrI2T7N+ASmK8x3qWka/y5nShZ5BLu+s3UuuYi71PyRi9gsFPU8C3Ot",
	"iGZ+Mp999vL8gvj+LWEtDaumqkZOQwkuFiy3TRe5TKEbJmLgG/gjSjgTmqhinnJtFupfBVPaUHo6E0dU",
	"CKnJnJEii41sns7EiSBHNGXJEVXs/qlpKKgmhmxBeqZMU7OXa3xa8YnKWGQeNLd1JMWCL7uLcAS/N7az",
	"bVrkdtPWeYdY5iH/lPPpTFysmGLECiVFaM6IGZoveOQ3bMWTLCdzZha0UCw2O5akhdIwlMxTouVM1PjV",
	"y3IvsGvdPFFkaoaZ2llOZcaEYcvvzuHV6agtOYwUrST7BDZMfsUmhbgU8lpMFpwlsSpFaVwbK3woHrda",
	"eFlTI5DZe/Z09tSzv09Di2n3dXecc7vfvSSzf7kTDcbSstZtc7UzqlfdHs1x6/szLfwyxTxnkZb5uuqy",
	"GsXwDyw2t6w1Z4SWb1Oy4AkjMie06mVMYpYxEZvllqJLmzAVvgtQ4DviFA075/Pv6igltDOn/TrZSUAC",
	"HZYPj61apdwWXnvZc/4dsT2QS7YmJ8eEi4QLIwFOtCFllssrHpstbeTYdc41m0iRGAmUFZrA5oKJWgbn",
	"TETm5Z9WTDjxBC24IorpsemCzVdSXtqulG1j5aJjhnM4Kz2rsZjM1+RDlLPYiA+aKPvcbMwPM2EYjaWZ",
	"IUZtOL+c5dhG2hklqWI5dzR2lske4V1KvoDf/eaqK1/n3zmlMdhfcOIBKdVqVue7nC1Ybujqt7PVJvzW",
	"qa1kbTArvjwxvSwy7aHxJVsr8uHwp/N/HB4dvTw//8ePL//PP06OP4Dkgt/PXx6dvbyoPf4Q/D5/6Lw7",
	"e9X9qpfVQzgHRXVGmZ/koqXXB0fYrkg3B/1Lo73beV5cGb6eKHjw7uyVodLJghSi3Gxjy3B2AL8vFYGB",
	"arOr6eyVctucxhn8Xq3h0ilI27eMXd7DOtZqiY1mg37OdhulxuC/ce7epOI3afx337K2gZhQRc7Ixavz",
	"/fPzVwQ64xHI6qEbyQwV2kctPBGWGl3Q8CkAIzTNl0wfJYXqPeEv2k16RY3tjES2aYCmrYl3tIvy+A9N",
	"LISClKa6UCH9zgBNzeJDHVLyyof+UzRPGbm2G7Wj3JGyN6IK4I5FkSRr8332+B0dmE9hE9NLaCP9U87D",
	"pP2bfdBLUDO4XlGYZl6IUnq3zvjOgAlV+u0cNLv4ByaYVV67478KtvPTMb0Q6R6TZfW8rnbVdOA6PbjQ",
	"f/y+mpoBaUuWW21dKWeebU7mtX3gR3ftNgzWlYWa5j1rfu4fDVtx19PwJTYbkQWH1eUXRUWeA8yCHwd/",
	"16dBjNwA/N50uMEmAKY0e8w6+AgbraFhJs7cBnjxI1eAQVsTVl/OZkDu0GRAtlgMyJc0GJTmy0Gm4KZl",
	"KGDj/Az2B3JX5gfStT6QhvGBPFjbw2YuZflmLF2yByU5KxSdJ8wsDNVsuQYly7JgxZECAKjpYk4VO6rO",
	"YDTooUHvKzTo9bPOecaixgb2hrhqmzaMaF0mcRrsKctTrszeVwEtstOmaTa0jyfXPGYkqzXyCrDBMl1j",
	"kLcj1t+gObOGQi29FsYIJW4CZzJhIeMPy70+UZ4aLfuXTHi0PisSRlYyiVXDmgTKgG0/ByGUQWuSFwkb",
	"k3mhSSyZBVPeUlB7fSboXBaaXK8sZ5u3CM2yBLCZJDIn1yserSpHXqhZUHj9kMsiU0HZZR+FrC7+YUDH",
	"KRl7SsjJgqRFonmWwCtkaTus2XINVKNiTWgEVHJ8ZSDx0vSoiRRmUGu+ZaJIYbHiahSDOU0HZffkmicJ",
	"mBGtI3NKZqPZqMb6zgid16YECsts9E2zHU2S2qynw92eLZuw0fomvoGWKY/A2yjFmfuId2evAgvwptnA",
	"ST4GCmRGcwNPSZEnyq4BtW5Kdzas6BXzhgdz6JNvLNUdTeyGA1MDtfQwAGxMFtwcE0qzzEP5jOrVTJxz",
	"g6GEFJNSrMKUTJdmx5a7DoB33ThgxzA7MIIT1/BVjc9UBdFiK3kbbPiCg5l3OhOGqxSJqCCM6xXLoU8w",
	"KJsVqnbDU1VEK/NRs1EmYzUbGdaYOaOOmo32zN/tD4GvbLxrZOxstDcmQCgQ7lKv7noL+DmAzz5kw6o9",
	"9tDC+WgNu+sKUMAC2I0Q4ntCDgWYctawgVJGhWvNrli+1itzdPLS939f37nhG9329t9TLajVi9rf8+Sb",
	"J21OreTOHc/+iuXzwMz/bn5uztr+ZNmx3J6vXlmlxE3PKDHKS0xvMnOfGPwuGP5uv6llNbIfGLIGtYHO",
	"Fi9feQ5U4S8tb5/3vAWP1+7x1PK+dQd+22zgjyr3M7n6rqFhB8bbwXkXgh9xEx0cSWEgBXeRdF2NKty2",
	"1HMM+KSaz3nC9dorNqndCiImWc7gN+Wsu9S5FuaMKKq5MsfpTMzXXdhC5mxhTjzYak2dxsjUudOHrrle",
	"Ea6nBCy8zrAdcj7OBPtoqKUqn2xztqCt+DfNRFobQTAWu31QmQC9FcRsAWimxjPhhXKp5pU92tUZV1Ng",
	"YslFayQ1NhJfwplRvlntMm9O71KsPJhUgGrWvmznaXQvo3Jc0YQb7b/0Kdd6mwmvz2jQRqPa4rulyXIZ",
	"MQZeTViGyq1b0aPLIZ4qf3E7tStf689rHFoKLUvF1m5iuu4cr5MFnOMz8ZJGK+vSMH397fztG+u0ddsC",
	"1GzoEiCU8s5c0Ao2dvwXmRMX1jQms5F1xtuFnRr28ye6fWAWxTqyp5Xt2/vulUwZfPdstIP8DPN5M9ys",
	"xdjVX6WzvvZTn+jpxrRxlSV03RMWUD20NF8VKTVqDI1BsfIRZwPH+qecnwdx39/sgzIuoI30ekFRx1+Q",
	"0hCIP7IPShOu+1NLkhc9zvzhwYY8DRrCT9KaGRzaDF2U0F7INoHYPvR6L4AVkSoiVUSqiFQRqSJSRaTa",
	"0ARUkcFJGL8E1TFAlfNWi9JJ70jE3M/lVm0esG4AteGUtR1frDNGlKaGmP6sLmdXQRI33JSc8eXKMPI1",
	"4fqJE0vZx8iG42QqjedT8ld5bdhhTLj2+C1TY5It4Xgwh4wFPHYhgwrgdp23CgXZ0Q+3zVluW9zWV85y",
	"9JQ/XE+5DU1BR/mDcpTX4PZW85QXh+fdFBfTynnjMMkFfeK/LZ94jUU6bvGYKcD1ZTza9uARo8a+E4ou",
	"2FHdahlgm56WDsB464ALki2VFoBaRkWIIF21ZRslhVhwDcyd5TIuLLQtYHVm4rhMHj0gvcMDhnUrXak1",
	"DpMtCrM4JGcJo8rqu90QbhuEHoj5t8HpTg75UPW6PapDTiYMdItDqhg8sJyySOjS0gqAnu1Z1b93Sk5h",
	"xhC0Hs+trdG2mxp5EhuM9/P7qRvPdAabVCaE0WhFfBuiWEZzqpmBliJud5VxnYf6OD25OAvTyrwRMOec",
	"XJxVBrX66jj9yfKsWRSeMhCOBkx1yDevJzOHzZAv2k1CNpdGI3K9Yrk18vh5uk+2ORLNxt4CbbdruZGU",
	"6b2yGDlTQIC9AhkSN9gSZqJB+hdZIml8Yg6PK5qch4TEu3YTIop0znJDHMUiaXDAnOlr5iJl51wkcqmI",
	"7VoFQnxbIMh/UTB822/OAN7xj5pI0PNV+WIvnHEL5bd2iy/9z439N/1MW+zozFstS2E8Ez4tO5FlksBD",
	"3W8+N9FQcDQ8Nb2PON2u6tng2p6RRzLjYTtHo0HZf7mJ3YpH9rGWJGcGtbWC1b/7NhisXk6td3+WgiyX",
	"YsOXtJiiu6+qpRj7BPGyt+0WhD5n73lPNuVx+awWZwpo1alc5oydS6mVzmlmtDJKBLv2UW19fNIz2ova",
	"0zYjOg3PLAtk5YDy9pn4ELQQ8OlqCdqoO1s/D+vtlpXq6LXgCdsvc0unN9poMPD7nh1j8fAme4h3tLcC",
	"kK2RWRD20UGVxgqHXG6Ygo0p2A8jBXsm3oI7Za5kUmhm+7C+i5pzZ0peMQqdgAs4pzwxfzzZfwKtvAeh",
	"S9PWirvIC+uR/fnXKiMKqFQKGipaE5J5jTBA0PEoh8NppFiymKZURyumnj75n/0/P/35f/bf//7pPvxn",
	"75u9/T//x5O90af3mFuOueWYW36D3PLBPFybR8XKNtrKjFXxLFfvzl49NZzrGBNz1zF3/beWu+6kXJ94",
	"arJ1uQeDue31bntU3MH55++3KG397L8h0M+QhadpoQ3Oa57d5L/+i8gkPmfJwsqCeO6ggwUhPYrfi06j",
	"0Llw/MLjNi/lunCri062mu5gWSZcTBpWuqay3lES4mCa9HEtS/rdxRGxcanSdwr+LXOIGP7OtAVtKdUH",
	"ZDb69tmzP06ePZ88+/bi+R8Onn1/8OwP/20DKHsrv5XsYGfTZgjwgPsscfNvCJuwXzeFHWkLx7mXrYcm",
	"UDtuWN62daT3eePrqnzN777FrrwFWrk+Q+HHYcWh1zl2dOZ9Y7zpUnDuMb8Dj878seRjhWeiEDHLExDi",
	"PjA5IFvYFTM7ddKMXbaVHh349mM56F3rbCbevL14eUDeZYZX4bSwR4Gh1ZpkEjxrStMksXqugRMJo7FF",
	"EmZgmpde/WgDls8ZBGIF7VP2Sdcw5ehfvhowSKVc8NTstuch49Sg6B/qjNmlMy3h4P4yZx0Y/5vTsEsA",
	"54w559pv+bg0gwEU2KpaOy8rAAqI9dsFCMbOrDtRNu/b/Hd0+s4Ty/yznEI9Yt9aMTTLzQv/83Q2+/2/",
	"J3t/fvr052eTP73//dPZbAr/+mbvz3v/Lv/6/d7e06c///j6h4vTl+/53r9/FkV6af/699Of2cv3w/vZ",
	"2/vzf7TPBCMNZT5x3+Xhe8pSma9vTZTX0E1VGwP+etSkCcfwlKWb23U0XM3ShujyJvPNR06UUBXM36Wq",
	"5MqyJ/ixZSrJjIBRmglNrmRSpNCMB09NxX9ht17rc/5LZWUx//Zusd55PJYFrytfQKp+y/avG05lt/zQ",
	"sDqPs4+RIYVUepkz9a/E/KHSeN49mndU5mrpHCQq4wSiFRVLEIGb9LhCsdzqsyqsw71rNgj6R4Io20Yl",
	"2zd7EED40G4d2Y6Yvvk2g3JVVLm3NK3t8S+M6iJnvYGG/nk9LLPjDa5l5i18+3Zsj/uCgM0RVr+rw56/",
	"Pn7RCAbdMIht3DeCyhKu/ypz/osUx0JZ/Sq8zuf1pm/Oq6btFack2JQcnXlLSvDxHbsnhimvqRTcuk4C",
	"5ZzKZ+WpVf2yWWJXDTdR9HWgVZeY7b4qOrbfv3sPzyAFzTs6mqqWC3jx27D6ilCxCsrT8AHHUwWe84oo",
	"qhEEPq47NkDW+Uf25fFM2KBrn9ADKUC8CrO2WnbNSGEN7cqZ2WfieC1oyiP/uYeJd297ViNLqlm7lzpQ",
	"npITGzUM5hqX7ecsNXYOm4Kaz+rfU0+SlMIIDm10KkFOZXxuvr7ROhCvu8GvDZsHLPCNDdgYJpPxNEDl",
	"Mg3nVMZl+EmdFob0QIaUXvoQ73K70CvKE0OomeBC8ZgRWlue8LaEyLdw9iVTTdtytJKKWQ8A9TFznjNq",
	"KSawCS14gHSIcT0BoozHg1YE/DZxbeZjG/99zRWbCVhmh1iKRNcCK2Hs7S5P0VcscGs0f0qzySVbq3ov",
	"vTH/Kc2g1B4Ao/5LFHbWBR8JrmlfzADwsErDA6FFPxr0SmgqCwELGck0K3Qtla10rQXDKzddQdA4QfZT",
	"KuiSlblHalIJh/1RYCv44M/f+rqd+SDY1spZu8PGlfMsZ5m+7IgrIlOunZGuLosg/cPZ3gBjuU3DF2WN",
	"S/YxS3jEdbKupTHORCkdwC4jCE+zBMAuLP7En2Fge55WU3G6OvsYMRa70T7vRhumRWXUCPiQdxzO3EYE",
	"ltIyq1ujwmGXMnbhSVwsbfJsWIU6DTcMgZBA004cWw7xembZaybnTMaWzd25T6NcKrXVopbl8mPAI3Rq",
	"fi4t0PBHwxY6JXXzFRWEZuYIzznVbCYCL1RZrZAFV9X6WPIrJrzmTw5nIpJpasONSUSdeUAxXRkWy/O6",
	"FhsLSlAZElMmjrZqTfTFWw8z5Nqv2mrHZR8zqUKWZvi92Zltu0VN5y6k68wA4YDudXJaf95OWDs59SEk",
	"uX3+9Ojk+MysHYy2N4OChuZ48GSDwI/G+mpQlsAxVleb+9XBxpTqGPDk1MDAnCllM58bc4EscK5XstAQ",
	"B6dTqi4HpKmNR4mk8QuaUBFBBZVeLPMq2K7Nh6Y3MnfN3OIY8em27jCfh08l2ej3cOtv3h77lL0yBwVK",
	"XpSdePNLrd/y6QCnyI62GNieUzu9aZi6dRtNwmjOYmJkudkxrYAZsOj813+RJ37uT8i//03+14qqp86I",
	"0zPEnmm3uQn0C/09Nf2pTZ3NimfPvv2j/V+yoSX5X6ZPFy1wE5eDZe4v7XFozAIdDuhw+HIOh+22ZrtZ",
	"W6bmVIqlNB++olZPcfqKszov57IwnDvIKTweqRXN46AN7dw9Kb0B/u9m2oK1UkI8S48KYRPl+hQJ+7Rd",
	"ySM8GFG2sdN8VKDE01C5VEcX1TR2Fkst+F+OHzZNb0l38KosXzRpUKUBBTVuaKd6FrBZWqeWXmNfut3n",
	"Nta3nkTget8aBOMCEDbfrrA5sRCaNT6yvDVgh9zCSPMrdt7nATysP2677SxOEiXmeAqmf7AY7gVDGqSw",
	"mF8FWcI9a4bElp9UvVwG2HS/rUf/LDuv+o6Zpjyxx6MUjFCj51RBB907AzhkMZd1L7qUTKjSFzkVCka6",
	"4CGFs9umcesDhPS40Hs3YV229hVlJLhgYe0BlwNM9zFrLsN5XrtkoRbxUXXr3Gi2ppG3A5gTH4LhQcU3",
	"mMt7vZrXNhg6WNTlugGwDEFCYDoefH1D76UUaXUphathRsoaZuUzEQOYFMtyMauCghXZ2jHrZeEY7e36",
	"Kf34iomlXo0Ovvv2//njfwYmKgfc6tFt0xbtU59NPK3d6lEm4VaLc01tSKDZ3DEpMviIv8jcRs2IiI2N",
	"oAz2xpXfu8maPP/WFkaCse2WmVZs9PPH91MZvIXkT+PWhLgihrByASFiMwHhRDmzLONgdfCaDT/h4CUl",
	"pbh9FlZ6qQqR2f5er1GY5XKZ0zSlmkeEQzjjgrO8vkGsYgwvekND+XVPlGO++pY5hURnloOwKdNZamy5",
	"zpjdU1b+GujGIl2WAbCpLYwKc1i7Mb2tYmwDT69XDMqvQF0D91Juiz7ymBn8RMmyoDkVmrEYQk6tB80G",
	"e1acTqt8eb+rG24dM0uHzGDrt/b882fffg+LUf7Q0Cx/Ppz8N5388v6p+8ezyZ/+MT54/03tz/dWFQze",
	"zhI6yJz08rLWE3XsiqORi7xgY/IXCL4m72x+Tj0E0DwfjUfQYDQeuRbBe2TDmqaPL6zt8FrRAQKcRhZS",
	"Tl2NyWkk0/2qKEFLZjz/Y1MV/9mS5f3TnyfuX9/4n/b+DCr0pgZ73+yD+l2S9/3Pk4rUU6OI157t/cdW",
	"x0zgXKokb8ln5WptiDDoFPrdIUSxPMe7MYpVUdnWcVXGFAbrYNbvW9mWoeVvfALXmeqmpf2tduOTL5Lg",
	"EqCqaz7qtlPHYC52G5xncDxuiUNWPSH57gALVQ21J5sLpFdQ2I40GajIlM4ZTUs9DILtswRyPdhH3ZO3",
	"sUu0iNM1t0Rv2Gl9rliRzmjDg0Y2x4nUyNv42Y3c7TqWqTmKbt1rj/baiDyBoUqlv9GTnYYf56n7czIr",
	"nj37jpGTU3NeZRkXy72+TwjsP9uJL/MTGE7QlPW4EvgV1ezkNOROcI8quA8/1OzB1R6CYcIjFPOER8EB",
	"3JOyf/h7p+4/DRCAK6mCF90JwaBIist7cqec+xFSn6xqHaCnumFUUGi6Znrh2Im/uid+dr5lrQyHFybO",
	"DJ0zGq3Cxu4hV8uxjzqnjeTGSlfv+NR207v7b9JLpYIiT0Ytrd+j54+iUi0LIMkBV+qFM7ZPnai3uRq5",
	"HkLSASURDPxZh4w7NF53Lc7QGnyAQ3uPZJoyEbO4PLlDg3VbeS3bWSDcXZT+kK8qDFWn+tFZTXd1ZZ9s",
	"Nai+tC9elfgEhaF2LSMVBpnYPsqMBBF7SynkHNoxnPK8kEkir82rOTP7LHJZ61DfshCaJ7VRqtk5BFF+",
	"vx/sYCYmkCNTZkpEtZJWy5zGLPZN2tkkfr5PG/Gu7te9WkepjLmt2t8M1iqEUT5KWG7nTBO7+CWFdL2i",
	"WeATppsiqvtDpLXUNKk7OQZvtj5Y4JSM0sjUAAl9MmL4NY01Bn/RU0wq2GxYjTtXwwIr3WGlu99qpTtX",
	"uGXXenf2tennLj7zWYvOlHmlWzJK698gc76E+uXtgJU+lXtADZrmPG7hfPD02t0F0bfc5W3PG26ODt8i",
	"/E85B5Np2cNwA7Rb4GA9BtoaUGmaZh3Mban8RNm94o7TYYPHTGkuaO91If6hnwRA/25xouCGW9LQHQg/",
	"0ExVFlLvbssZGB7NKyRm2pox3ZaHzONELlXQ/8bFOzWgYsKJaVYPqANLS6k38vJks7nRpVjmql4sqJY9",
	"XYtzA1HcIURtjvaAO4M36TxhYcfMq0CryjUDR6RzzlDduAzJiBIgkpvbnV5d7Vnnha+SYfTYrYwPa//+",
	"5npRf2XuYNMbl+huyDQvjrFY98Mr1t3VnLFq9wOu2n3kV/HIB0mDqTWYUhPIUnF2hlAlGkjMrxf7b6K6",
	"3B2lGxxBA4xsfV8TOM+q/UpyllB/VULdlNoJy3Fh4zdlgABxA8wwmLyNrLW7pm7l/hoSDrqUkGMzsXPv",
	"XYbQ57bblkVluktWRYuRcuzOGnnzaQ4dOCfc6KDMMj7Y3y8Uyw9sHu7/+/zZs2nt/w/+8H3d8lAv/ajU",
	"tczjZqe5lDrU2ozg13Fb6wH7eNCpemfnKR6kD/wgxSP0IR+hp8EyTD2ll1pHT6vYPM0TzpQ+dtp+JUm+",
	"ffbtd5Pn306+e37x7XcHf/jTwR/+9N+D0UMY37UwlUd2Gdc5gLgWxqML7dffVagyMFrTSyY2QKlmaazO",
	"zGyjO/3cAQt25tDXNgHr2g2z6TpIh0ZdNOr+Zo26jmF2tuq696ahUnS3q49uuXLzzQF3VRHd7JYVtZmK",
	"iml/WWPNRwlZl516gFMspf5lSql/zvqNgzZHfctN76/io5E0dF27ldtHTJlJhz64NTXTLGM5FGGvmzOn",
	"WEpym+q4k2+nLkJdrETQvWNxn2AshkMdokVcCdqwxbuHe2rS9g69P/5QuIH7p/dcaPh/hinBj8H9UAuO",
	"GuoCqFG3kSxdkrR1At5FRIQbc5CRotb2bmz/Xs9Gm8XDtll4kIWmi4dounjZU9K4+XwL8vX3GSPiRcT7",
	"W0O8lkEA6VrSm3/ZakpbExlcQS3HAk0Ju7VciXVj/Agl0MJ3MZhnzZMVmIzXr2+8ojmXhXI3INh6dbbA",
	"na2pc/zCSYDyUnKfxFKPyo60Igm/ZMQTshQRL21NcPLuxDDdsuAxKyuiqpngwkA7uJqnDOyWuYF5/k4G",
	"uHPE9cbzDZ4K02O4ZKsvygpdleURbYEmF2Ttc0F9oI7aXKmwpG/N4qC4WCasNu0ACqp3Eojd8X/VMlgn",
	"ZQZrrXV5Y0djrM6O2e1mv42dfbrRrXbhPLoHfHd9Cwf15rRtQzxOKOyCdF72yQhfeLEuJYJFgo2unxcN",
	"KV6VbfRnqnL5uI2Y8kqJ6zNBbaq91w27g74qyVMXFbUryIIzmM6Epwh52Xrm17T18rj6wRYAMbtJykQR",
	"ntKlNScFkGPONY+sszkQo2be/CtVq6Aohqenzo41OIG1pEw3L64Ztt5PnGGM2TOsek0zK1lSmm3fBhtu",
	"v8Cd8NveCWW9v95ynLhBftMbpPuDITLuGNwxA3dMaGSfLPfOZsgFcjqbDZrQp0mFMvHOpdt1l9DdNXSa",
	"UHHGFoHqlI3n9tM7dy7WGnmI7f1oXuftzGQmZuInRmIJ5TfqqXdQHvWqLGFa79y6xpJ1hc5/rELmfBEQ",
	"W3pgziJq72Rq9WFwPk2U9DNxyrKfoPKuv5rXT8QOMBrmWdErRgrBhbbTjaRQ7F8FlHD348/Zil5xWeS+",
	"chAl88IVHXdQ0VafoYIUhrN1IYyiXBUMNSv49tXrKRBJFculQZdVzSGPNw9PT/Yt5lxRESddOqsxuV7x",
	"aGVrynovFiWK5ZypmZALEq1YdGmLsii6YMm6pAxNkg102VSL3rugOu6nNzUo5vaR7twpyBYLBrW1knVZ",
	"09nSKy5g0xlt/RrKmBl+o5rPecL1mnA1E87a4DxDtqiL3QC2yL6zsYHvCwprlFWPrB3JRwaZniBJOmK5",
	"4a9kTa5zCfVjdizXLK9YfsXZ9f61zC+5WE7MsBPLKGof6Ln/O/jPaOfipCnNfPV3qmXKo21+lWxFQxV3",
	"nTA5NU/bpZnglU0iJSS+Db491MP9Vdbh12tCvag/9ri+zKSWbpM3JlhPpLbJxgNlv++hNpkuGe3dzS1Z",
	"3LRt7SC2w8n/KL5RfKP4/s2J7wckCjvW+B69vLIEhr3yTjvmglBy+Z9qQ5n93Tz0dtzNnvmqze088t5G",
	"i474h+mIdz5edMA/JAf8yzyXAX8V/AxVMs3x271trVeBDY1RKREuFuNELOTG7CofXGOoGLi8DB5ehNPD",
	"yhtB4bLONyD2YagsZ5HNlw9daf7KiZbmrZ72+rPyPrPKjeEO66qiHlxh4NIFfh4ts29H49Ey+270fryL",
	"L7U2czacwc5rrwU9Yo3izzXqhWj1fsgCnvUX9Q+sYl2W9HiVAtmOWfGaJwmvU84W7Kkn/I0ORoUtcvVp",
	"PIq5ujx3tX+GvWFr1L9YazZ4mCHphyV5Dsvv+zQeRTSjEdfrr/Rbj/zndXacfzCurXdom3VvNBly60lP",
	"UJBpSHxL4ppiZBBGBv1WIoO6nLI9D6b7ToBdhL/jaKPHJFQxps5YVS/kkq0ndidklNsKt7akHTVwoGrn",
	"maJ+pdFoEBypwyKHnX/1EdgQdt29nbBLvSFhFEMIeIeR36y80UmVl61Ssa4FeffVlVH67YDylK+C7XYu",
	"URmmytYqlcOgZrfzMNwMt7sR5AxdqoW486HhzoA6gdjzIWHP6jZtbz900ajuCqpNi9t99wVV7CeuV5Af",
	"FLicqna3uHujbtUfBULuxqMiT0YugPF9cMIvgs6a7WMFA3DfeNPvToi1NBiXN+MaLi9t82l3LqNdMKkP",
	"nvR5Z1madrPN6rhAXfJsIjOrE0xgX7O8vGqssGVRmjc23LSzK5bzxfri1XkwGNE+8mXutSRMqCJn5OLV",
	"+f75+SsCb/s7QAPH5LAt29h2t9y+cMvakOvDDyE0uLyJ3cmoehitt2M4Q8Xxm3P72G7Cu7Orx0JNEjpn",
	"ycRb2GsVb9J0Uttzd7Pm5Xbv7t6hnXQX9gbSYsDWsHUYT2lOU3V3km286+unr18P/ELrVbwDsWiG7Fg5",
	"jOTo/Egz/iNbN6tt0IxfsvWd7Zhw5aTy11vIMhfqX5t5nHJx4x6HmFtOX7/uktsAu6Hy6h0oDnezKe91",
	"M1oNp7EZgx+kvLo/SCkM6ByBQ688iTt9bz0v354cH/UZr7xb2bTxt6LkW25MturgSUBHhV7gHl93LbVr",
	"ehxUnZUqWP7u7FVPP+VsLG93jeqRzELmXnjZPRyuVnRs0u4b6/MsxwyZCgNXiw+6qrzHWHgqY1I1Ja4t",
	"WgvRWvhbsRYGeGW7uTDwUoBhFpDst+4TioeN53bBm9fHei71PZUXyZKYuTgvIoVbRIhjMB8duLDJVWD8",
	"VxL6fnh2/v+Vl96Uo4UnU3uhsrYFjECsJ7O5mdG8ZbDjFz5QPJNxYBAhY+bp2JfSN2eKmHY1MlYSLy+S",
	"2mVUmYwD1IN4opzFx4XZZ9XCnyyFLH9++ZFFRdiYeGFgiX2L5S5gCvqEHEj3AD7Q/GCm6lyvimquFmub",
	"D1rOnn00zO0yzuwlh9YAWrusEIKauAaej1ZSKjYT1FIBer7iEoSmvbwvJ6lh29LaV/Zvy79Ur3E1E2D8",
	"LGlS1r0XrLoNbgnqtDJiJDW9XjO+XGk1JnxqZER5uXnVccqYVjYuzMG42hLV7s8mT728mwknm8ZlKFd7",
	"fYIkGxOmo+neeCaMklRoZsRskRr6cQ2WXJCuuSyW9mNY4ob2h5cNJ4OMxtiw4EzMRvYLZyN/IpkenaEa",
	"PjKlOloxVSXYqkxa/oUnL6v5/W/TZibMW0/VXkXTFV+uPEn9rfHNpdiQL3voQ9GqdasRWLM8LWcIa2Ch",
	"rh2cp0bR4tqtInk2E0/NOto8ULOpJjLbm5JDIopyZ28aQchyANeRsoGTZV89LMhEFDQJAIUVS6A4FYw1",
	"JlQpGXEIFS1J2CS8/ZzuWO0FCY3ojePNkRsbdb6Gp3BP6Zwlm7KZD/v7cWpA+W0NM71VYcaEkku2Hrsc",
	"2zK2zkgNql2dS7vzLtkaWjndp/Ppl2wdll7wCfB6eTdUOSdQxBloCMHLwNx0glecl2mypu8nrh60IfqK",
	"Q+Euai9qXFTa2t9pwuNa8KhhhRMxJm+kNv95+ZErI2iOJVNvpIY/p+QHbanzKnyrou08yDWgttvwmEoT",
	"U1N7/3ItjhFigY0gtfOwEru8H9b04eu4CSkmPni024mdP9Snq33Bpv76+/pBm35e6XHtstqZqL0NEcdl",
	"4ryTc4243jmzSnWWw0Ue4JYkzk3lo2tth1apT2jEYhKDHLbqK9VsySOSstwma0Wr6XC41IpJNVzXDkpt",
	"ASprPin33Nb7UAeMMLYS4S9G6t9eGMDhgcIAhQEKg8coDG4UNm81je6W+skqVG1VBcSNx/hNncWIhnPH",
	"axeg5zg3R07FkpHnk+fPnk2H3OfXolRNvyqnezeys083H4qd3FYuNfmGWO1BPyAHhDSoQhOqZ6KuifKU",
	"jT3Ws/vamTQ8EIuJ9PdGG3JPZ+JGc4gYVcwli6RMz4TBczJ1hUE9W5hJMP/15CmbLqc+F6W8A3PPzlet",
	"lWapNWgZxObuh9f5Glx8V0zogibJmrArHunyE8HMw7WFwGEAXd9RKiSa7RIaFT981hmV22FF+CcswNuz",
	"zZDEwgUDBQGZdHsMAAY7RoP+cgHy0IKiwzfHYJQyrS5kJhO5XNe/zmbnGETj3jbYb+6OFUOxNy1yIDxA",
	"jQA1AtQIEB6gMEBhgMLgPuDBLT+jq8G9330WoRCKTMZDXCtGyez3rFiVNpKTREZQXd5sA/NK4x4DGbMx",
	"+UUKZq3zZvOArmxT6DMZP1V7e+iZQc/M3XtmVlTZBbairN9RU2MHw2b34qcxa+qWBIIiKqrbecXE2gxY",
	"fNqcjVMcbLJmHLOYZCyf2FWUZMGh0kR7IsRNPuAvbnS+GRI2+P+2zhdQHrw0C2pToF38q2D5msAdFeWx",
	"XwZaOKMIVySCsmEyVhbEg8PKoM6xfdymoV97mLOQ5rm6CQBst7CKmdcD7RcEFcEAvK1Q7SadsL/PWyiF",
	"rjbJrZVC81J5KfM96IblfPN7UxLhoxt64i66odPFbMLNo9ESBytsM/H44dsrMMLcIq2v1kujDN+vhrOA",
	"zJ9skp8RmU6Lrj9z6lCtm5lIbUk/Q4ArmhhmtmZBd+6Z7tuixmjkUllGLcvezAzhZqOxPbHqm2M2OhHm",
	"AXXnQ2M/lGICaj3P7DaejbYJqW35L4PqhJVkCNdXf9147mUcUMQcR6WYAbXNShh3vtujnifJTMyZvTXR",
	"gBQJ5ZZ47FL57Dd26pUnUl4WmaeSD6CbCW40Fm/OtfY8Q2y3EC7F0/4O/QG/uLPxQ+PI+2BU3w8gMQV5",
	"Ci/ufZiJ6iusEicL2FxlXl5NgSk/kGz4Pqvp2fpe1dSfWM38KRWa75Vn+pQAjUFgx1I80XZYv2N9BzNR",
	"fXwFCK0ebsnpsj5dNKPZ2CBorLUWcIA7KRYyn/M4ZlA0qBxsLr1vpFp4s28b9JvOxGGi5LjdMCojF802",
	"uV4x0XyPcGW+TDF9twJsPEq52rqb202+yg0tpMY9HdzTneXfsK07bb/czi4TknbS163O107gK9VBcPzU",
	"VEFLSfjVMAU8iD2WK0St6nCtN7uv2tDbXlXgILECfby6T7H2NjSezgT4pyr1VMRtj1X1Cuj2KaPCHKne",
	"xPFEVU1mI7OEPgqv7PTpr5/2GpF3VZ8IPBB4IPBA4IHA43MCD9HKRK9Tun7AOOOuzdGhmkeVm68s71qr",
	"oXZnJ1v90Oo51+qHX+eI9sda7yFWHnOdV7edb3esXWgXvvFj2M/ovAhV/dDSxWCUPafm7ZnvNNpR46HQ",
	"fFK1KA2UoGT62CsrpVqKlPNYlIb9inZm97O8MQmuyix1qkheCOGydayxfyYsv1jF0S20PaVgRnBUVSSo",
	"2aWptvlyLmRGCqckw/VKC8tq5R6Aj+Ll+NOZeAnLXu/alxK2NRQG3MpUW5mQJOwLd7veOdytZYcew31l",
	"dxHu1rJvY8zbQ4l5q6HdevDbTNjoN3Kr4LeZ+MnAI+0rMZO0SDTPKn+2Gpelj5QP2VCtPWmGo9EKoGHD",
	"e0Bz5wBXwHrWpQZKvY2J81qOdR3yjYr1cXWrXWkEUOSpETjJ2gHxBt80JJVTnflVWUjd3iVYyqunam/P",
	"H0xtQToTt5GkYyPXdpOEpCkIa5K3koSz4tmz76Ka4IEf2HapOBN2S3nfZY2alVRELxSCQQSDCAYRDCIY",
	"RC8UeqHQC4VeKPRCoRcKvVAIPBB4IPBA4IHAA71Q6IVCL9Qj8kLdOnXLZUAJzQdnQdXXtC8Vil5JHpOs",
	"0Lq8ifRrS4dqkAFzogbnRPXRDROjMDEKXVKIDBEZIjJEZIguKXRJofkeXVLokkKXFLqk0CWFwAOBBwIP",
	"BB4IPNAlhS4pdElhYtRXnxjVcJR8yeyo3SeCKVKYIoUpUuiPQliIsBBhIcJC9EehPwr9UeiPQn8U+qPQ",
	"H4X+KAQeCDwQeCDwQOCB/ij0R6E/6mGnSAWTpnL5MbATTs3P/pQvfSaRFAu+LCwwIB4XHL8gtnkWNOwa",
	"cg7JyQKy9+dj+dEyGePVUni11N1nUPWnTLUP5XvJmSpRTLVudbdn3ZECa2Cv2LWD8zRLeMS1W0XybCae",
	"grMOXDNmU01ktmc0FTiDto9Q3eFLXEdmVCWrvnpYEC6l3noN5m3Tq/BWX7zIEy/yxIs88VZfFAYoDFAY",
	"3P5W375gv592DvZrX/A7JncU7FfpV1gA/aEUQBeNoD5iY/pm4lZBfUEA3bwyemMhg/BZByF7Fiva6D2z",
	"AG/PtvghWkatTo8BwBAwJ7oYuLRmV7RWugtn8qh/HTH7ExCNN0YSVczdsWIo9qZFDoQHqBGgRoAaAcID",
	"FAYoDFAY3Ac8uOVndDW497vPoq/k3dByd1sq3ZU+tq+zyh16Zh6vZwZr22FtO8wlwpA+DOnDkD4M6cNc",
	"IswlwlwizCXCXCLMJcJcIswlQuCBwAOBBwIPzCXCXCLMJcJcIqxthzFvWNEOK9phRTv0QiEYRDCIYBDB",
	"IHqh0AuFXij0QqEXCr1Q6IVCLxQCDwQeCDwQeCDwQC8UeqHQC/VYK9rZDCih+eAsqMYdQD2pUPRK8phk",
	"hXbpLF9hOlSDDJgTNTgnqo9umBiFiVHokkJkiMgQkSEiQ3RJoUsKzffokkKXFLqk0CWFLikEHgg8EHgg",
	"8EDggS4pdEmhSwoTo776xKiGo+RLZkftPhFMkcIUKUyRQn8UwkKEhQgLERaiPwr9UeiPQn8U+qPQH4X+",
	"KPRHIfBA4IHAA4EHAg/0R6E/Cv1RDztFasgv41Gm0nje3Run56+PX/hzv/SiRFIs+LKwUIF4pGDbHr8g",
	"UVIozfKAZmFfPGf5FQuoAEe1pwPHPH5B7FvEvZYFzcxmcYdkiMEm6M8O86NmMsaLrvCiq7vP5+pP4Gqr",
	"CPeSwVViqmrd6k7YulsH1sBe+GsH52mW8Ihrt4rk2Uw8BdchOIrMpprIbM/oTXAibh+hulGYuI7MqEpW",
	"ffWwIFyRvfVSztsme+Edw3itKF4riteK4h3DKAxQGKAwuP0dw32hhz/tHHrYvm54TO4o9LDSr7Ac+0Mp",
	"xy4aIYbERhjOxK1CDIMAunmB9cayCuGzDgIILVa0sYRmAd6ebfGKtExsnR4DgCFg3HQReWnNymlthhfO",
	"AFP/OmL2JyAabxolqpi7Y8VQ7E2LHAgPUCNAjQA1AoQHKAxQGKAwuA94cMvP6Gpw73efRV8BvqHF97bU",
	"3Ss9fl9nzT30zDxezwxW2sNKe5jZhAGGGGCIAYYYYIiZTZjZhJlNmNmEmU2Y2YSZTZjZhMADgQcCDwQe",
	"mNmEmU2Y2YSZTVhpD2PesL4e1tfD+nrohUIwiGAQwSCCQfRCoRcKvVDohUIvFHqh0AuFXigEHgg8EHgg",
	"8EDggV4o9EKhF+qx1tezGVBC88FZUI0biXpSoeiV5DHJCu3SWb7CdKgGGTAnanBOVB/dMDEKE6PQJYXI",
	"EJEhIkNEhuiSQpcUmu/RJYUuKXRJoUsKXVIIPBB4IPBA4IHAA11S6JJClxQmRn31iVENR8mXzI7afSKY",
	"IoUpUpgihf4ohIUICxEWIixEfxT6o9Afhf4o9EehPwr9UeiPQuCBwAOBBwIPBB7oj0J/FPqjHnaKVChp",
	"ioklF4F7+l/C7/6cL70mkRQLviwsNCAeGRy/IK59FrTtGooOScsCyvenZPnhMhnj7VJ4u9TdJ1H1Z021",
	"z+V7SZsqgUy1bnXPZ92XAmtgb9m1g/M0S3jEtVtF8mwmnoK/DrwzZlNNZLZnlBU4hraPUF3jS1xHZlQl",
	"q756WBDupd56E+ZtM6zwYl+8yxPv8sS7PPFiXxQGKAxQGNz+Yt++eL+fdo73a9/xOyZ3FO9X6VdYA/2h",
	"1EAXjbg+YsP6ZuJWcX1BAN28NXpjLYPwWQdRexYr2gA+swBvz7a4Ilp2rU6PAcAQsCi6MLi0Zlq0hroL",
	"Z/Wofx0x+xMQjbdHElXM3bFiKPamRQ6EB6gRoEaAGgHCAxQGKAxQGNwHPLjlZ3Q1uPe7z6Kv6t3Qindb",
	"it2Vbravs9AdemYer2cGy9theTtMJ8KoPozqw6g+jOrDdCJMJ8J0IkwnwnQiTCfCdCJMJ0LggcADgQcC",
	"D0wnwnQiTCfCdCIsb4cxb1jUDovaYVE79EIhGEQwiGAQwSB6odALhV4o9EKhFwq9UOiFQi8UAg8EHgg8",
	"EHgg8EAvFHqh0Av1WIva2QwoofngLKjGNUA9qVD0SvKYZIV26SxfYTpUgwyYEzU4J6qPbpgYhYlR6JJC",
	"ZIjIEJEhIkN0SaFLCs336JJClxS6pNAlhS4pBB4IPBB4IPBA4IEuKXRJoUsKE6O++sSohqPkS2ZH7T4R",
	"TJHCFClMkUJ/FMJChIUICxEWoj8K/VHoj0J/FPqj0B+F/ij0RyHwQOCBwAOBBwIP9EehPwr9UQ87RSqY",
	"NJXLj4GdcGp+9qd86TOJpFjwZWGBAfG44PgFsc2zoGHXkHNIThaQvT8fy4+WyRivlsKrpe4+g6o/Zap9",
	"KN9LzlSJYqp1q7s9644UWAN7xa4dnKdZwiOu3SqSZzPxFJx14Joxm2oisz2jqcAZtH2E6g5f4joyoypZ",
	"9dXDgnAp9dZrMG+bXoW3+uJFnniRJ17kibf6ojBAYYDC4Pa3+vYF+/20c7Bf+4LfMbmjYL9Kv8IC6A+l",
	"ALpoBPURG9M3E7cK6gsC6OaV0RsLGYTPOgjZs1jRRu+ZBXh7tsUP0TJqdXoMAIaAOdHFwKU1u6K10l04",
	"k0f964jZn4BovDGSqGLujhVDsTctciA8QI0ANQLUCBAeoDBAYYDC4D7gwS0/o6vBvd99Fn0l74aWu9tS",
	"6a70sX2dVe7QM/N4PTNY2w5r22EuEYb0YUgfhvRhSB/mEmEuEeYSYS4R5hJhLhHmEmEuEQIPBB4IPBB4",
	"YC4R5hJhLhHmEmFtO4x5w4p2WNEOK9qhFwrBIIJBBIMIBtELhV4o9EKhFwq9UOiFQi8UeqEQeCDwQOCB",
	"wAOBB3qh0AuFXqjHWtHOZkAJzQdnQTXuAOpJhaJXksckK7RLZ/kK06EaZMCcqME5UX10w8QoTIxClxQi",
	"Q0SGiAwRGaJLCl1SaL5HlxS6pNAlhS4pdEkh8EDggcADgQcCD3RJoUsKXVKYGPXVJ0Y1HCVfMjtq94lg",
	"ihSmSGGKFPqjEBYiLERYiLAQ/VHoj0J/FPqj0B+F/ij0R6E/CoEHAg8EHgg8EHigPwr9UeiPetgpUkN+",
	"GY+yj1F3Z5z+/0f+zC89KJEUC74sLEwgHiWYlscvSJQUSrM8oFMwseSCdYd4Cb8PHOX4BXHts6A12azh",
	"kEQwWOv+JDA/XCZjvM8K77O6+7St/jyttiZwL4laJXSq1q3ua617b2AN7L2+dnCeZgmPuHarSJ7NxFPw",
	"EII/yGyqicz2jHoEB9/2EaqLg4nryIyqZNVXDwvCTdhb7968bU4XXiWMt4fi7aF4eyheJYzCAIUBCoPb",
	"XyXcF2H4084Rhu1bhcfkjiIMK/0Kq64/lKrrohFJSGwg4UzcKpIwCKCb91RvrJ4QPusgTtBiRRsyaBbg",
	"7dkW50fLktbpMQAYAjZMF3iX1oyZ1jR44ews9a8jZn8CovEWUKKKuTtWDMXetMiB8AA1AtQIUCNAeIDC",
	"AIUBCoP7gAe3/IyuBvd+91n01dkbWmNvS3m90rH3dZbWQ8/M4/XMYEE9LKiHCUwYR4hxhBhHiHGEmMCE",
	"CUyYwIQJTJjAhAlMmMCECUwIPBB4IPBA4IEJTJjAhAlMmMCEBfUw5g3L6GEZPSyjh14oBIMIBhEMIhhE",
	"LxR6odALhV4o9EKhFwq9UOiFQuCBwAOBBwIPBB7ohUIvFHqhHmsZPZsBJTQfnAXVuHioJxWKXkkek6zQ",
	"Lp3lK0yHapABc6IG50T10Q0TozAxCl1SiAwRGSIyRGSILil0SaH5Hl1S6JJClxS6pNAlhcADgQcCDwQe",
	"CDzQJYUuKXRJYWLUV58Y1XCUfMnsqN0ngilSmCKFKVLoj0JYiLAQYSHCQvRHoT8K/VHoj0J/FPqj0B+F",
	"/igEHgg8EHgg8EDggf4o9EehP+php0gFk6Zy+TGwE07Nz/6UL30mkRQLviwsMCAeFxy/ILZ5FjTsGnIO",
	"yckCsvfnY/nRMhnj1VJ4tdTdZ1D1p0y1D+V7yZkqUUy1bnW3Z92RAmtgr9i1g/M0S3jEtVtF8mwmnoKz",
	"DlwzZlNNZLZnNBU4g7aPUN3hS1xHZlQlq756WBAupd56DeZt06vwVl+8yBMv8sSLPPFWXxQGKAxQGNz+",
	"Vt++YL+fdg72a1/wOyZ3FOxX6VdYAP2hFEAXjaA+YmP6ZuJWQX1BAN28MnpjIYPwWQchexYr2ug9swBv",
	"z7b4IVpGrU6PAcAQMCe6GLi0Zle0VroLZ/Kofx0x+xMQjTdGElXM3bFiKPamRQ6EB6gRoEaAGgHCAxQG",
	"KAxQGNwHPLjlZ3Q1uPe7z6Kv5N3QcndbKt2VPravs8odemYer2cGa9thbTvMJcKQPgzpw5A+DOnDXCLM",
	"JcJcIswlwlwizCXCXCLMJULggcADgQcCD8wlwlwizCXCXCKsbYcxb1jRDivaYUU79EIhGEQwiGAQwSB6",
	"odALhV4o9EKhFwq9UOiFQi8UAg8EHgg8EHgg8EAvFHqh0Av1WCva2QwoofngLKjGHUA9qVD0SvKYZIV2",
	"6SxfYTpUgwyYEzU4J6qPbpgYhYlR6JJCZIjIEJEhIkN0SaFLCs336JJClxS6pNAlhS4pBB4IPBB4IPBA",
	"4IEuKXRJoUsKE6O++sSohqPkS2ZH7T4RTJHCFClMkUJ/FMJChIUICxEWoj8K/VHoj0J/FPqj0B+F/ij0",
	"RyHwQOCBwAOBBwIP9EehPwr9UQ87Repmv4xHTCy5YBfwc3vLvCyfgU5g/isX5PgFsS81jPIJj9ZGsTb7",
	"qmJMQxkmihQ8Wh8jo4NIpZc5U/9KzB8qjec1gvRQrzbHEPGMNCmc8AFoYf7JxTvFRgcLmijWOQBOZVy5",
	"vE5h7ufQidt/LjVprlh+xWIQV/Dpgfe6epUbuTYbmER7DiemmT1+FgldujwpEfMINDiX/+MIy5XFn/M1",
	"7NnjFyRKCqVZXtt6cykTRoWhSEKVfutm/wMTDu11F/hVsJ1XACETJ2eROb6W1dOSLBY7WqdAiCx1l+cf",
	"vw+7PAfs0EDvr7gKOG97GjpdznbYUqq9A61KYauQdD2VDJaBh7RomvG/s1wFyXt4euKeNfbVlf2N2RFS",
	"WuaGlTqxI/SimveUnBui58qL70iKK5bD+sil4L+UvSl/HiY2lQ68fIImVmxa9SGla5IzoEchaj14/fa1",
	"BPfgQh6QldaZOtjfX3I9vfxPNeVyP5JpWpiTYN/QMefzwijj+zG7Ysm+4ssJzaMV1yzSRc72acYnMFkB",
	"uv00jX9Xup1Cinl5IJb/+I+cLUYHo9+ZgTMpjBaz7751P7DmHXn6aTy65CLurs+PXMQOc9X0+2oZvL/y",
	"7OX5Rekrs0vldlOFYqoFMsTlAlI1Qd9wFiLCRGw9yxBEkHDDVqqYp1wr4lISQckhR6V5wnqV46lBF0c0",
	"ZckRVezel8cQT00MyYILlDJNY6ppTWnZxL7nLMpZgFvt72Qlk9goYPCH6Ra2PYlYbjgUDh13nbXUNCHz",
	"NSSfLuoasFMyjs3LVo/26ChhCo5/QV7Tj3bAc/4Ls70gL987L/tt0ofTyhPCLEiwg2aggVnhhuyu7Zsp",
	"eUkjqwTC8oOh00p2mmQrKoqU5Twi0YrmNNIsV2PyZPJkTJ7844nReZ9Mn9iNpljOaQI0NPOrvPHVFgWZ",
	"MaeK/fF7wkQkY1ASzKTHXelB8znXOc3X5GkmleLzZA1mAPvCnu3RSh6jEE+JT2UHzOLXTEuZqClnejGV",
	"+XJ/pdNkP19E3//x+//8nWKRodDk+1GA/3iaFprOk4B+d+IfjY26oRhgVp2bncWEKnKvO8MMlZZ5Zftz",
	"3Bu1RRV5CgDUiUcvKrximMoYYMAeWD/Mm41BTccuNqfZnlANeo/mKdAH9CqL/ARPwjoQivz7EfktKa6p",
	"iGkeO+o8UeWa3/ucy0kFIYGZ+vEW8bNF3FSdWKDnbRhrs0kMB8+5MGzdkAzCbywjO6bkBNTPLJdXPHZX",
	"MZPrnGs2AT7hIiu02/NGnbafyJmI2JQcJs5/VVlx654j7iPh4urgM8jW9D4Gx4H5py1nsK40W38ugKir",
	"vrA0QAl2xXIiC21mBr6RnFEIJiu39eHpyXTUi2LbW+Sdc5wtaMQTDlAqy+Uyp2kKVqAVFTEo2XLRlOeB",
	"/VPBYrOFYhkps3silmn4x4IvC4tS9m1P+7+z/wX8rIIwPaCwQEGQgDXr5RXLzTG8TOScJkZ22YZtPULy",
	"ODqC2WxTX9+eHB+5lm3QW+skBHrPs4Trv8qc/yLF8ZvzargWf4aaeYB3blUW7wNUpu3Kto2FsvRUfrW/",
	"jKo0E3eoK83EFmVpJr6ktvQZTqyKnLc9smaie2bNROPQundq3hyojEdGlIfYhUWNTRszZRiyMgGF+a7N",
	"HkY3PJYp5eINTdl5sVjwj93RXgRaed40PZAYHoLRlCj72DCrN8aIZb0FOMxtfZxTW8bojGUJj+g5M3x0",
	"omuWX1A4eRwYACx2H2maGYXR/2sayXQ0HqVcvGJiqVejg+/Go4xqw2Gjg9H/PP2ZTn45nPz3s8mfJu9/",
	"P5tN937vfnn/67fjT/8RWh2dhIrLvDr3BDD/bIj0ppyaOEFFjt+02nWFlQGTfAGGte6QR9XDxtC1n835",
	"C06aG0+ATqM8gIGPDs3oZliz3HENTUR0mrGULHjCAPEw4dbwptpEGU5exr9zA7v12HTB5ispL21XyrZx",
	"0RkNbb8RSf9hav6c6kRN7Rlr9vAH61hhaaa578nHBlw0hgblvwEpmlpFtVEiOg26qo8OyWnOr8wCOZN8",
	"l4iTS7ZGQoZs6m5LluQNGtbL6fSZb8wzzzUgRJpg2WF1f0TdAV9VoildT3SiJnakrZ9b+5T3IatzvW1Q",
	"eFuBdTfuh0G+hmEHzZ06G6JSO3zAzoYgXW7ubmhsEqMTDFa2w06I3qY3ckM0OSIWyq0RGi8fmiMizK7o",
	"inhQrojQGr2DDzulOU03xBQFperW/nYD2pbEYbyNgGIroEAt/+vU8lG5vwflPigetczpkh0lVKmQpb96",
	"SuKy2jIEqRhhx7Q5cQxBKYmgEcTNwkvwsw25OjU6hzIr9XeZFEbIOF9PvBY05RHkRcPaWdVkOhMzUR/b",
	"GcGFFJMymCz+310E4ka2U6FRJPMyI1pHQFwuyFv4+NdM06lZmIBWlSTy2s705ceMirB+FWplhOO1Itcr",
	"BqWiA3MyL5EreIsw81ocVrAfmfcltLXsofiCRpdF5hbzRieu7aEkZLXxugsXRUwpFwnZkTYucO9NK3Q1",
	"yxlEIo4OwCHZBjDtcFXlAwDNriqU08fmjTkOD/H8NB7Ni+iyD3BfgKomi7j8ett636EIlsPEtnrRA9NY",
	"yDxip1SvzvXa+om7mzBny77XrWDrI3WRJ8Hfr1jOF+uLV+eh8cJ7aJnTmNny6o1zt8hzI0/60A9Qzrap",
	"ou0d9gmRSwTp/6YmXMqo9pBdk+ZLtnkygn3UfgLtLmEr2S+1ZvZhTitHnNOEih1Z6m2ZTeGHzUwnnXrb",
	"DCpKHEKkwXBY5OZ1QdVlaMO7IXfur9vXFqIcZuZMoUlPXLSQE5l5JOXtHxCXwJdLJ73LFfJ04hCY7IVB",
	"Y6k6cwACdHZuypQyMiLEH9t3oRG/oNU780xoN7pl88O3AiaZqxJC1WWp9gZ69RG8OaPxejQeCanP3D9z",
	"pjQFVcNRxcYMh2N6u8RRLD/KWWzOFZqoLoEyqtS1zOOwZFEs91QaONgpy1NepYI1B2OCzhMWh+Vf1nyz",
	"axzYKtw7+7UZ4mzHDlmfemWJ90d7UWJO+w7jLookOZJpynV3luPRx8lSgnN8oi55NpGZlRoTMA+w3B6E",
	"n6BPM503QXIP7+aq+pSbddGuklSbVtX7uP7RIYpyCXoQzXhKo5U5O9fT7HJpflBTo9lMr55PzXFvNMOA",
	"JdM9qanBZaSTvYRjLfSKaR5VFVZsUNqKXrEx4SJKCuC8pExYu6I5l4Ui1prsRBEkIJXWnpSuoQOb4wMX",
	"cCzIr5UKOyZ+Yp8C4FQKzUURECn+CfTvcmKdQdhwGPxNScJTrol0mZ9FOme5GR62P8mZLnLBYmvUq+zK",
	"tcTB/IrlcJEF3BgCpKJXlCdm29tglDIfWGb0XwUr7YPzKveaKwUP7O0rzlLlzYw1o5ZZAms2Bo0MTKta",
	"mmnmnF3ZCy/gEHYJhuVMKrofWarY9DkXS2gUCJu26io6zRlxIX3Mk8x9adNzab47WlGxZHF5aQqEpVKy",
	"YNck5aIw5ILFNSLPp0r7pffGW4sLPbVtdE6hyttrypW0pCyzr0G+RjTxlGqg1gXPwfKuMikUG5NCQNTs",
	"WhZ2PjmLGC9JqeUlE9aQSAVheQ5JTnCKBWF9zlLrADrRLD2ShQjYR7ptSpdSuc9UMVdmuc0z2HJu9rAc",
	"LpnHFRaz3FXL+II2/gPLvEv3q91CXof2ZQNk7mjtM15tsa327i9n7ielSCEuhbwWZZae7cYvRcIWmhQC",
	"WErERKZc6ypP00eeuvID9YnC6qZZwjQjTxmH/T9nETWog2tvKohWhbiEUKrqKZCgTOlVrtFe9T2uvJiQ",
	"dl+2v8l+SGmUuNGXeHu0TGJQpqggV8+nz/9AYllFgVZWENj7RuoLs4zmI5zGE94p3zCleQrmy28sD/Jf",
	"mAsjl0lig2On5Ajs3KXfwoybMxCkfX3b2nAgI3L3B/tIIz3I2wS6UZ17Q/A9t7xLtWPSBWeqJkaeqJrX",
	"pI4XKrO/dSRZE4r32kXuS7UksUHHKRfMCgsn3ixnO4k0JX8HeeCD5jVcwgR2MyeJa12atbYSihSiDM81",
	"kLe8vAhmPiWnMisSWlYUYMQWxZsSozqCJe7ebRSRFBb3ResJdCGTCRXxpBTn0ToksxRLFq+4CCjM/on1",
	"1Lw7e9V20JTrMuj7Z2Imjl+enr08Orx4eUx+LIMbLZcpLTNiTnG6pFX/zjYoyPPpt8/MDoYyhk1xwxWA",
	"OGFPzTlsbnnF/GvP/WvTYeBykLpkndpHRuYEDVX+oTfMOk3ArL7hJLO16VwWGvLuM+76IwvKkyJvKE0R",
	"VUzZ/VzVRDQnkbUMMhEZ7mXuGquWNmzoE0blLoLWS5rSxUa1Pb+p1ULMGsBoY8MhBn/E9vovRf52/vZN",
	"W/S9BhccnEgkllZYZlLpBf9oRFAV2SQYpClTbXc6M7qfgQr2o35huZxwEbOPhmHJX+xVWkYPoVnGaF2n",
	"kCKy2LRWvwAmr3zhSncR14peGXK2aDglb53qDfvzpXXYqIOZIGQGqHQ2IpPaZit/dILUm1qqC9fMi3CY",
	"/Pzs/XRAD1YlsZNnQudQ2cl1MRuFHYElkG6X21gVKRUTA11Bwas99mttz0nvejdEmBJSs8M7JdQxOkjG",
	"CahChEJsdCMwoq76UBV0xhPHRTtP6mTR8Dq4yjnuDAcVoMlOpX5952x+zDTlifrH1bd9vO5aNMoyVVYp",
	"UnGl5bDXh//Hn7VeXFpFWksvMOqvB6RGTcMz3HwG1K+YmpLzOrIq4yCuzegV05X6jWK6UhngaLRFjDzz",
	"uDpItpQt1dHKhYva9HWfKw3O07J3C4+c/kGVKlInX6hYV638foPFNXIPPKtjo4MUwuhPbpCQA9JweVi6",
	"HVkJ4GqEWIHkwZhbqtCVeJZonphWFk/JG5v73nhqpZFfK9snuOnMuI1KB5vsezsfNQFDC9TFClPBlsyq",
	"SN2W9iESOERe/9bp8PBtqCHGRXwHg5K3wl0+mrnwKEvzmC8WLK+iOxyoYXE1xI9cxF86WEP0ujXAb3dr",
	"+pCn1xWisWLHlm6B7i1G9L5Gn2G31yO5db4+XGiWn7NIms8J1b8u/bw2cU3zFI5dZV8hc7aQ7m7Ncr1q",
	"ARPWFhFPyblZUae+2Hgdaz2px+aA/NH0ksGhngAi0IxQQDZk4my3UpUd6ebpVfa5ktckkdYNek25LmdJ",
	"L8t0xVb3g4qXj0cFD2z+dyfH7dWc9i5Tud59S9Xev+F8oEKxfLIseMz2S0yVq98VPFZ3fgxuOP/sp1lT",
	"jTuwIdiAJkmjiJ5rYS1a3vqEwX33HdwXyTgEU4rl0krOv15cnPq1MW2r+FMrecbkGeFlCutAHnEH7R2e",
	"gTU9DEML7zi08BaIwhvxvanGy//ptiDGW2+L0mlxKwByvVq3Zu7iZczHzUZ/sXrgbOQ+9BbIhBx6TT1K",
	"aO7qgwnLfo6KwH7zwghMZs2c8orludEyebi2Xz0iPyCZGx53bhUro3UckNnovIC4EYNF8/qX3vt2NNoE",
	"GKfc5AccVTb0osi5XkOAqT0qXjCas/yw0CvzF2wecGXCz1W35htGn0wf4DXs0Op3xHRhHQe2VOxhktQ5",
	"mHjv4+Hpia8wRz6Yl2TurB8HxE6mvBHhkgl7F8IHsgLgbBU6HzxqnQtckCyhXEw0+6jBBmHLf5hnTimQ",
	"c2etn6+d/+MDs7OJdOKaGomlPzhlAv6w56J9CmaYnBtwx0sPkopyxoRz5HMNAaunLI+koOXXWm6sORsP",
	"Rs+nz6bPXNlLQTM+Ohh9N302NWdARvUKVmXfedMnntrLUE0UMDoYei79bN1rFlB6I18jjswwTOm+cizq",
	"8zXgS8p9fhKPDkY/MF3ZGY9suxPrN/YAGib87bNn3m3IrNMGqnrZzbD/TydYHDW2SK7wgLD52ucvcN+i",
	"SCruNIT9/g4n89JoyKHB3wnVM/wfPsfwJ16DcoYP5hqOR6pIU5qvRwcjRz7v6Nd0qUYHP48q+o7emxf2",
	"zXEy4Wkmc4iN27rdnBs6SVwRA/+m30+Vmr1pa5mz55hqelIObBigjNA7+Lk9/l+4wRrtMedroooM/oqr",
	"aBRfcg7qAR1GkPIPDp40pRPFzDimfeLqvXLTP5RQHnnkOSp7tTEqZnrVmg2P41A2SA4UvtGn9/fIN3Vi",
	"QrYRsszOLANBm80dVuMcKH3hSTx6/2k8+jhxJ8nEq8ITt31aTGX4LJE0nsxpQkXE8onL49iF3UwHxHfg",
	"c7t257pXksYvXC9louC9bcvuaLg5b7E5g3ugtkcNuYmnN/ElQT7ZUpobdlkEflwjJAW7Do4S2k5H8FbP",
	"hgLl74WM1/e4l0K0NApg6ANKJzg4Oe0Hx6N6iJiLO/uMvIB8cAO9BlYuuMRDGKFfZocFdK/o3v/V/gNe",
	"/2R5K2GabeAy28CF14S2aOv6QUY+mM4/hHjvGPoK8t5GPaoeFBzkc3JkcdNCFiJ2XqTXzuzws/e+vvdd",
	"dCfgzYNesTKwptKrajTr8F5dxWoD2vtUnXY04iLP7syzdrPemGcH4t/bstQPTCM/4Tn3QHjmB6ZvzDBZ",
	"sYlhrA0drq65JcfYVL3fFtM8bL3W+UdQr310/G556bPqtc3bWDafsta/Wb/vqpbamlJBl1ZgONt3n/Wh",
	"lkV7jzuyHGU3Y0NjPV67bxL1GftlsDWJbGzZFvLX3m/SfP/X8t+f9m0i8MRZ63eyCzVziCEgoEv3Rjq1",
	"GiKf7SU7TsJ285S7UrX8mgejiDQ/Gg1PtzA8tTZZjRVcmr2j8u7GpmbP4MP75hsfSfzNNxBL/OHDB/Of",
	"X83/EDIr3eCz0YH/sQo4PiCzkfrOs9JsNG42cPcpmVaOZcsmn8Z+AKMDtTo3G9d33ui0SsS3j+3fzxtt",
	"ygoDton98x/29q6qVZkc78aBPzutbHa9+4JiEjGhc5pMns9G9a/4VNLtRgSkvxQ5u0caQv8byViWKthI",
	"STfDf9AIAvn/Yb9gA01b7evEbROux97ZkCoPTZLevXYa+GhXjqNHSW1+4Zc3uzbXCw+Am1pcOzt3wwnQ",
	"rw61FZ3hOpF9trultbUf++Btj4V1Z27fldF34vHxg9LUvg9FRSIvDbCE7sJLA62foW0e8c4+9w7jJb9i",
	"wv4GWyHAAD8wjbv/s+MUPKFuZivdhaXgRuMBFtIdjg/yViTr1gWmLv3Lp4lVVx/0GFKR2+5Zl+0vLTdM",
	"l4UFUbusNWq6j9AG+9k1XR+5OPGRv/ZdW3dqF2NKuyCX/5TO3cr1g78X6R673lwoqf36XeRSnfkfumwI",
	"f2yPXOij8xcHu4O/ok8UfPvs+eefzJErI+IEhJ3Ht59/HjZWmMUoEzvov2fHd4TjgMDYoKS7gXS8qUGg",
	"j3l7VDtIpdgiLy2se5jycrxLXUhHix0d8MEP3+yDv706erKw1bZtvZpSIWUxKTJ3z2Eu07Z22orzjxJG",
	"RZG1Ne/ONKpqsxiJ9hXYX3aSZgMNMPcgVn5gGmXKPcqU9w9ZE0OWrYw7D0n7MD3LnN0BOHM93Q06O7Od",
	"/Ubgmf/aofjMk/qhAbQN3/EFENqG2XxeiLZhIojRhmO0vJQJXkx6wu4oJ0uZdxNBeWc4zTPxXQO1hyI6",
	"d9OqHDVup1adNeTiY9CrECN9KYy0WZrcFCXdAVN3YRJy9ONFSjdQiZBzN0ClzWw7LFXovjjXOtyQeT8D",
	"8z4OSPYl8pe+Eki2KBKUhR1f/sPCRDvXV6pPXXUNRa0bxcI1lmq7ST0M89DnYWRM+LllGaTG5mtVQoJn",
	"jtC7J/10uHK3nR00gP5GLJ+Dz9eHZup8IAfqsJM0Wd+zhRNNm7cybW6TRsPP8d3O7/1f/fEPNs39WqDe",
	"TY9158tSO7uBAuf7CzedRwWdbgeZtpR6qK3Ww3YNo7Zyh9qK56kv4SDuyIi6w/jGQsJ34m7N7zy/hREm",
	"IEfO/JRRkDwiQeJWDSXJXUqSvGKFL2Ew2P81nr8BMVKrKTv5p5zftFQzMe/23uB9F3LE1sj9m5kiig+/",
	"GeZvHprgKJdpV3nxYOs1V1ub3jFgaPDdzdjXFqLYKWjMvnJrXh1qQDm3M9yBZwNEvpu9P/7yksLfbGmv",
	"BPOXtdgVadhU4EYTIbW/zy4eE0pyKmKZuuvEXE7gEopGuazAYNF56N0R67Pbmdzy95iX7NMvb1TqnyWq",
	"N4MsKR2xYisB7CYvdxOBdxT+dddhX6idYDIOBpo9vECzbaraTSPN7jTCDIXHY4glQ668myCyrc7fgQWn",
	"75Ing7FjyJYPPErsZu7rBxAWhqLkzmKwvpzz1jpkqs/c4XbFK5pzCVeM+pd7Q0HvVNE4qiaLsu0RqBy1",
	"9UKJcTcR7FGdBb6s5MgZ3BNPk11ER+2te3G8BIRGbZ4oNR6D1CgXDKXGXUmNBg/ckdiY1Hu9iQTJuM53",
	"EB2nkgs94WJywVNGchbJK5bDbfryM4mSUzNhlCGPQIbASqH0uJH02MJrn1vvYO7W6ZtEjLl3bxVOWt16",
	"/fVni9hvxaCpuwiaYuW+6bCLJfNQbvEd7cAs+0W2zGnMJllCxVDOyZiIuVg64sqcuE5Us056PRtlJg7j",
	"mNvggGQ9JlwTmigZuCHLd04j05rAtfFEr6gmgrHYmbYyli9knrKYzMScLWTO4JymC3MW2dlAHxWR/Vz9",
	"XFhsJnv1fPp8+gymwxVIrzRlIrbjFIoR7b/c6A2d753OxMWKEZnE5bDMtFaE5ozELMtZBDkSZnI+osF6",
	"+/zw306fhTWKd7a7U7MuX7NEqX8nipIbncN+52V2r3gp8tZtV/W55Mc+zbJcXtFkQMBWKTICx3DJaFuS",
	"Nx8BIx8CRdiDY+b7KBNffuKh3waBPX1mh4ZlqAR1A5G0N8FQBwYKjt3cDHaXbyL7Z5UkVcTTrrEKbuZ3",
	"g+CdyvU4wDvzk30sqNtRFw/625nrynXfhBhuUKXm9pzUDDD4jTPT/QUG9PPRw44LQP6/q7CAQSLgbo5q",
	"22SyYFQXOVP7Kku4nqxkzn+RYhILVV6QvYPp7Rw6+avthBy/OXcXcxMulKYistYE2rElBE1w0Jnr6/jN",
	"+ZGbzq73jG6d0/SxoOogQdBcdwtz3fb9Oq0xY5D+u5d82b4he/OUwjN4BBxxD0k6QVL05exs++JgOs/n",
	"vbNs8AchZw9K7+ld84XMyen56+MXw3i7/7i1R+iAE/QujuGbJg9t3/o73gN8Yxl0F+Lnju9t/NK6weO5",
	"N/h7O9f7HX77XhVS22CGh5i+M2g3bRc4Ay1ld8jYPzCNXP1oNP5HpBOg1Nhi/LsjkbHLNc53KDes+eKr",
	"Ex3tb3n8uMgu1OYbnnfESF/kXmeUh1+xPHTG0DsSifcL21IpuJaGkyelqWgXQ2n1/o1Mo6/L10/K0Xe1",
	"At3znfX3JAECX44W0FtYQEMbscZfFbl3t3MGurbxPaEn/nBxu0yRD2ZXfXCHjWJ6OhMvqGIxkTZ6yD9f",
	"MWI2G4s0v2Lkkq3JNdcrYnm4sGSHKEPV6Ou8iFaEqjHhC9vVAcnS9MPYdCjIB/Nv6Kz+pi9rZEegzTH6",
	"jbbdLfvQePXutZDuN1tabFZBXvfviy9XZymwfChsbmqUDXB+v7TpP8KDx++Ox/VNDaoh4bWjCfVmEsEL",
	"gzANPw8+er3L2GghvfPhQxLyQdtEW5tV0E0MP9DyeSsO/IHp27Hf698S++ExirwdtlzudJLvYp+8FXdb",
	"GwKer19a2x9icEy3aftfxMSIcurrkVPOonjfoCNjecqV4lIMsAGGkiPL18tKBoViuU2Q5IpERZ4zoZM1",
	"SeRyCclJYEj55uVHmmYJO/hmJg6VKlJbbnQhk0Rem689e3F4RDKZ8Gg9hjhv060iH2jCIx/5PZfzDwcz",
	"8eHDh5nIxiSXCTuI2dW4MkGqMckZjcfkm1aLdrjpmHwzJt/s9zbzid+NdnM539hkOSYw3apHN1kjQgxB",
	"IXPLUrX1+W3Cuu/2X/vrTBAyG9VazUYH5GfzK/H/Mf83G8F7s9G4/ltFntYDQ6vWT9/MRvbP9+OBvbdJ",
	"2+2w+ff+LYbwNN9hDPOf9zPxyVHyUMTbSF/fZsMJP5fz+5t1MEFXsfy0xs73mSPbGgqNSjfLkzWSMmss",
	"mZfsh4VeMaHdxMisePbs2z8S86vM+S/2c2wF70zGEzOjuEiMeAeRyXfz6GQyJlUXxHfhk10viznLBRiR",
	"fHGWnsoTpzI+L/s5BeG9TXs9bqX6GLXPnh6nMiZVb8R2Z84Ut2LzhBEt+8rw2+4ujBJZ1yqZKFJD3+xj",
	"ZGam0ng+sr6BZc7Uv5LR+/F21ffMSmx/CIYnCt+woopQTRJGlSbPSV4krG/CK6rOigQ8GF+oVnZg9dA/",
	"dQv/VA9b1bg8uHN291aFBlr3O3XCXHof4Co0Ug+iCn7Dl/egDPwC5IdBLpTgIg/ih35o03f+bTgb93+1",
	"I09u5kUJb9U+O0/vRRY3OCzrpp4w0+9WNS0whc2V02p0ezDWWbzi4TP5Q27OvQOdI7dmrB+YRq7Cg++B",
	"wbyb883QGxluzTjO5v1b452HrvF+icoIyPh3ab//3Bqvb7tTZXOa0YjrtS1ZeEV5AraVsivPmz8OsgP9",
	"wHTVsLrT2M3qHjfuhlFx/+6O2Kqbk8ul85u2orSzQSoGBsxBSIqLK5pwe3K9tDscfv/bTxdEy0sm+hHT",
	"uRvmVpFW3/7p/gl8ISVJqVgTqjVLM60e1NLWqf5KLmWhdzY8bzVQcaWK0j5VLi34UxK5XFp/pr1O0IiW",
	"2pRc6cMyYBmM5GmhNFlRdynhh0QuufgAgmvOE643GLvqe+Yeigyq5jUNPUc9fEOzlP3dHuhZbr5dO7s/",
	"0DoYxOF/sVrGY4oO+M2yLYuKnOv16ODn9xuYmIsbOY8U05qL5Q6+f3uBsn3LKwZ+LhBakCQ2pyCYqe2H",
	"u9e7hd0Ygzf3BirXJuyJ+wNcAJ3YivKWilcs98ffcCK6l9o0NM3sJgjJtL/bl05sNft7o6EbZjcSlkTz",
	"b/fTrEnxX0cvGM1ZbjaoWQCDzSwJLOIs8mR0MNq/ej4yT1yfbRob+q31yhwsOUugNq6WbbX1yJfvL+Fj",
	"TZXp+vn6+2zfH1DrsXO1wI36rWr3t7v1FetuMVtyxpSWeb1798vturV3/tZ6tT/s1OmLdrpQoyviLxQe",
	"2mUV+FR1VYuaGtoNbUpUAEoNcVp2PkT2dketM0ieukHmstC98rUascFct9hs5G2t0q7ru/ppaMdl8IBR",
	"9WiSSEMIsSTHL8rij5m0aWlCxvUtGIbCn95/+r8BAAD//66hIIIOtAUA",
}

// GetSwagger returns the content of the embedded swagger specification file
// or error if failed to decode
func decodeSpec() ([]byte, error) {
	zipped, err := base64.StdEncoding.DecodeString(strings.Join(swaggerSpec, ""))
	if err != nil {
		return nil, fmt.Errorf("error base64 decoding spec: %w", err)
	}
	zr, err := gzip.NewReader(bytes.NewReader(zipped))
	if err != nil {
		return nil, fmt.Errorf("error decompressing spec: %w", err)
	}
	var buf bytes.Buffer
	_, err = buf.ReadFrom(zr)
	if err != nil {
		return nil, fmt.Errorf("error decompressing spec: %w", err)
	}

	return buf.Bytes(), nil
}

var rawSpec = decodeSpecCached()

// a naive cached of a decoded swagger spec
func decodeSpecCached() func() ([]byte, error) {
	data, err := decodeSpec()
	return func() ([]byte, error) {
		return data, err
	}
}

// Constructs a synthetic filesystem for resolving external references when loading openapi specifications.
func PathToRawSpec(pathToFile string) map[string]func() ([]byte, error) {
	res := make(map[string]func() ([]byte, error))
	if len(pathToFile) > 0 {
		res[pathToFile] = rawSpec
	}

	return res
}

// GetSwagger returns the Swagger specification corresponding to the generated code
// in this file. The external references of Swagger specification are resolved.
// The logic of resolving external references is tightly connected to "import-mapping" feature.
// Externally referenced files must be embedded in the corresponding golang packages.
// Urls can be supported but this task was out of the scope.
func GetSwagger() (swagger *openapi3.T, err error) {
	resolvePath := PathToRawSpec("")

	loader := openapi3.NewLoader()
	loader.IsExternalRefsAllowed = true
	loader.ReadFromURIFunc = func(loader *openapi3.Loader, url *url.URL) ([]byte, error) {
		pathToFile := url.String()
		pathToFile = path.Clean(pathToFile)
		getSpec, ok := resolvePath[pathToFile]
		if !ok {
			err1 := fmt.Errorf("path not found: %s", pathToFile)
			return nil, err1
		}
		return getSpec()
	}
	var specData []byte
	specData, err = rawSpec()
	if err != nil {
		return
	}
	swagger, err = loader.LoadFromData(specData)
	if err != nil {
		return
	}
	return
}
